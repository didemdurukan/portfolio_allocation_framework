{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer', '/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python38.zip', '/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8', '/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/lib-dynload', '', '/Users/doganparlak/Library/Python/3.8/lib/python/site-packages', '/usr/local/lib/python3.8/site-packages', '/usr/local/lib/python3.8/site-packages/selenium-3.141.0-py3.8.egg', '/usr/local/lib/python3.8/site-packages/urllib3-1.26.4-py3.8.egg', '/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi', '/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi', '/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi', '/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi', '/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi', '/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi']\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import A2C as sb_A2C\n",
    "from stable_baselines3 import PPO as sb_PPO\n",
    "from stable_baselines3 import DDPG as sb_DDPG\n",
    "from stable_baselines3 import TD3 as sb_TD3\n",
    "from stable_baselines3.common.noise import ActionNoise\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "from stable_baselines3.common.type_aliases import Schedule\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "import yaml\n",
    "import gym\n",
    "from datetime import datetime\n",
    "from sys import path\n",
    "from os.path import dirname as dir\n",
    "from typing import Any, Dict, Optional, Tuple, Type, Union\n",
    "path.append(dir(path[0]))\n",
    "print(path)\n",
    "#__package__ = \"examples\"\n",
    "\n",
    "from FinancialDataLayer.DataCollection.DataDownloader import DataDownloader\n",
    "from FinancialDataLayer.DataProcessing.DefaultFeatureEngineer import DefaultFeatureEngineer\n",
    "from AgentLayer.DataSplitter.TimeSeriesSplitter import TimeSeriesSplitter\n",
    "from AgentLayer.DataSplitter.BlockingTimeSeriesSplitter import BlockingTimeSeriesSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pypfopt\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "from pypfopt import objective_functions\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(gym.Env, ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def step(self, action):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def render(self, mode=\"human\"):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_env(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax_normalization(actions):\n",
    "        numerator = np.exp(actions)\n",
    "        denominator = np.sum(np.exp(actions))\n",
    "        softmax_output = numerator / denominator\n",
    "        return softmax_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def train_model():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_model():\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def load_model():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConventionalAgent(Agent, ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def train_model():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_model():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_model():\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _return_predict():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _weight_optimization():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLAgent(Agent, ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def train_model():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict():\n",
    "        \n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_model():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_model():\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_weights(rl_actions_list):\n",
    "        agent_weight_df = {'date': [], 'weights': []}\n",
    "        for i in range(len(rl_actions_list)):\n",
    "            date = rl_actions_list.index[i]\n",
    "            tic_list = list(rl_actions_list.columns)\n",
    "            weights_list = rl_actions_list.reset_index()[list(rl_actions_list.columns)].iloc[i].values\n",
    "            weight_dict = {'tic': [], 'weight': []}\n",
    "            for j in range(len(tic_list)):\n",
    "                weight_dict['tic'] += [tic_list[j]]\n",
    "                weight_dict['weight'] += [weights_list[j]]\n",
    "\n",
    "            agent_weight_df['date'] += [date]\n",
    "            agent_weight_df['weights'] += [pd.DataFrame(weight_dict)]\n",
    "\n",
    "        agent_weights = pd.DataFrame(agent_weight_df)\n",
    "        return agent_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFAgent(ConventionalAgent):\n",
    "\n",
    "    def __init__(self,\n",
    "                n_estimators = 100,\n",
    "                criterion = \"squared_error\",\n",
    "                max_depth = None,\n",
    "                min_samples_split = 2,\n",
    "                min_samples_leaf = 1,\n",
    "                min_weight_fraction_leaf = 0,\n",
    "                max_features = 1,\n",
    "                max_leaf_nodes = None,\n",
    "                min_impurity_decrease = 0,\n",
    "                bootstrap = True,\n",
    "                oob_score = False,\n",
    "                n_jobs = None,\n",
    "                random_state = None,\n",
    "                verbose = 0,\n",
    "                warm_start = False,\n",
    "                ccp_alpha = 0,\n",
    "                max_samples = None):\n",
    "\n",
    "        self.model = RandomForestRegressor(n_estimators= n_estimators,\n",
    "                            criterion= criterion,\n",
    "                            max_depth=max_depth,\n",
    "                            min_samples_split=min_samples_split,\n",
    "                            min_samples_leaf=min_samples_leaf,\n",
    "                            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                            max_features=max_features,\n",
    "                            max_leaf_nodes= max_leaf_nodes,\n",
    "                            min_impurity_decrease=min_impurity_decrease,\n",
    "                            bootstrap=bootstrap,\n",
    "                            oob_score=oob_score,\n",
    "                            n_jobs=n_jobs,\n",
    "                            random_state= random_state,\n",
    "                            verbose=verbose,\n",
    "                            warm_start=warm_start,\n",
    "                            ccp_alpha=ccp_alpha,\n",
    "                            max_samples=max_samples)\n",
    "    \n",
    "    def train_model(self, train_x, train_y, **train_params):\n",
    "        '''\n",
    "        *Trains the model*\n",
    "        Input: Train data x and train data y\n",
    "        Output: Linear Regression Model\n",
    "        '''\n",
    "        try:\n",
    "            trained = self.model.fit(train_x, train_y.ravel(), **train_params)\n",
    "            print(\"Model trained succesfully\")\n",
    "            return trained\n",
    "        except Exception as e:\n",
    "            print(\"training unsuccessful\")    \n",
    "    \n",
    "    def predict(self,\n",
    "                test_data, \n",
    "                initial_capital = 0,\n",
    "                tech_indicator_list = [\n",
    "                        \"macd\",\n",
    "                        \"boll_ub\",\n",
    "                        \"boll_lb\",\n",
    "                        \"rsi_30\",\n",
    "                        \"cci_30\",\n",
    "                        \"dx_30\",\n",
    "                        \"close_30_sma\",\n",
    "                        \"close_60_sma\",\n",
    "                    ]):\n",
    "\n",
    "            meta_coefficient = {\"date\": [], \"weights\": []}\n",
    "            unique_trade_date = test_data.date.unique()\n",
    "            portfolio = pd.DataFrame(index=range(1), columns=unique_trade_date)\n",
    "            portfolio.loc[0, unique_trade_date[0]] = initial_capital\n",
    "\n",
    "            for i in range(len(unique_trade_date) - 1):\n",
    "                mu, sigma, tics, df_current, df_next = self._return_predict(\n",
    "                    unique_trade_date, test_data, i, tech_indicator_list)\n",
    "\n",
    "                portfolio_value = self._weight_optimization(\n",
    "                    i, unique_trade_date, meta_coefficient, mu, sigma, tics, portfolio, df_current, df_next)\n",
    "        \n",
    "            portfolio = portfolio_value\n",
    "            portfolio = portfolio.T\n",
    "            portfolio.columns = ['account_value']\n",
    "            portfolio = portfolio.reset_index()\n",
    "            portfolio.columns = ['date', 'account_value']\n",
    "            \n",
    "            return portfolio, meta_coefficient\n",
    "    \n",
    "    def _return_predict(self, unique_trade_date, test_data, i, tech_indicator_list):\n",
    "\n",
    "        current_date = unique_trade_date[i]\n",
    "        next_date = unique_trade_date[i+1]\n",
    "\n",
    "        df_current = test_data[test_data.date ==\n",
    "                                  current_date].reset_index(drop=True)\n",
    "        df_next = test_data[test_data.date ==\n",
    "                               next_date].reset_index(drop=True)\n",
    "\n",
    "        tics = df_current['tic'].values\n",
    "        features = df_current[tech_indicator_list].values\n",
    "\n",
    "        predicted_y = self.model.predict(features)\n",
    "        mu = predicted_y\n",
    "        sigma = risk_models.sample_cov(\n",
    "            df_current.return_list[0], returns_data=True)\n",
    "\n",
    "        return mu, sigma, tics, df_current, df_next\n",
    "    \n",
    "    def _weight_optimization(self, i, unique_trade_date, meta_coefficient, mu, sigma, tics, portfolio, df_current, df_next):\n",
    "\n",
    "        current_date = unique_trade_date[i]\n",
    "        predicted_y_df = pd.DataFrame(\n",
    "            {\"tic\": tics.reshape(-1,), \"predicted_y\": mu.reshape(-1,)})\n",
    "        min_weight, max_weight = 0, 1\n",
    "\n",
    "        ef = EfficientFrontier(mu, sigma)\n",
    "        weights = ef.nonconvex_objective(\n",
    "            objective_functions.sharpe_ratio,\n",
    "            objective_args=(ef.expected_returns, ef.cov_matrix),\n",
    "            weights_sum_to_one=True,\n",
    "            constraints=[\n",
    "                # greater than min_weight\n",
    "                {\"type\": \"ineq\", \"fun\": lambda w: w - min_weight},\n",
    "                # less than max_weight\n",
    "                {\"type\": \"ineq\", \"fun\": lambda w: max_weight - w},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        weight_df = {\"tic\": [], \"weight\": []}\n",
    "        meta_coefficient[\"date\"] += [current_date]\n",
    "\n",
    "        for item in weights:\n",
    "            weight_df['tic'] += [item]\n",
    "            weight_df['weight'] += [weights[item]]\n",
    "\n",
    "        weight_df = pd.DataFrame(weight_df).merge(predicted_y_df, on=['tic'])\n",
    "        meta_coefficient[\"weights\"] += [weight_df]\n",
    "        cap = portfolio.iloc[0, i]\n",
    "        # current cash invested for each stock\n",
    "        current_cash = [element * cap for element in list(weights.values())]\n",
    "        # current held shares\n",
    "        current_shares = list(np.array(current_cash) / np.array(df_current.close))\n",
    "        # next time period price\n",
    "        next_price = np.array(df_next.close)\n",
    "        portfolio.iloc[0, i+1] = np.dot(current_shares, next_price)\n",
    "\n",
    "        return portfolio \n",
    "\n",
    "    def save_model(self,  file_name):\n",
    "        with open(file_name, 'wb') as files:\n",
    "            pickle.dump(self.model, files)\n",
    "        print(\"Model saved succesfully.\")\n",
    "\n",
    "\n",
    "    def load_model(self, file_name):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "        print(\"Model loaded succesfully.\")\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTAgent(ConventionalAgent):\n",
    "    \n",
    "    def __init__(self,\n",
    "                criterion = \"squared_error\",\n",
    "                splitter = \"best\",\n",
    "                max_depth = None,\n",
    "                min_samples_split = 2,\n",
    "                min_samples_leaf = 1,\n",
    "                min_weight_fraction_leaf = 0,\n",
    "                max_features = None,\n",
    "                random_state = None,\n",
    "                max_leaf_nodes = None,\n",
    "                min_impurity_decrease = 0,\n",
    "                ccp_alpha = 0):\n",
    "                \n",
    "\n",
    "        self.model = DecisionTreeRegressor( criterion = criterion,\n",
    "                                            splitter = splitter,\n",
    "                                            max_depth = max_depth,\n",
    "                                            min_samples_split = min_samples_split,\n",
    "                                            min_samples_leaf = min_samples_leaf,\n",
    "                                            min_weight_fraction_leaf = min_weight_fraction_leaf,\n",
    "                                            max_features = max_features,\n",
    "                                            random_state = random_state,\n",
    "                                            max_leaf_nodes = max_leaf_nodes,\n",
    "                                            min_impurity_decrease = min_impurity_decrease,\n",
    "                                            ccp_alpha = ccp_alpha)\n",
    "                                            \n",
    "    def train_model(self, train_x, train_y, **train_params):\n",
    "        '''\n",
    "        *Trains the model*\n",
    "        Input: Train data x and train data y\n",
    "        Output: Linear Regression Model\n",
    "        '''\n",
    "        try:\n",
    "            trained = self.model.fit(train_x, train_y, **train_params)\n",
    "            print(\"Model trained succesfully\")\n",
    "            return trained\n",
    "        except Exception as e:\n",
    "            print(\"training unsuccessful\")    \n",
    "    \n",
    "    def predict(self,\n",
    "                test_data, \n",
    "                initial_capital = 0,\n",
    "                tech_indicator_list = [\n",
    "                        \"macd\",\n",
    "                        \"boll_ub\",\n",
    "                        \"boll_lb\",\n",
    "                        \"rsi_30\",\n",
    "                        \"cci_30\",\n",
    "                        \"dx_30\",\n",
    "                        \"close_30_sma\",\n",
    "                        \"close_60_sma\",\n",
    "                    ]):\n",
    "\n",
    "            meta_coefficient = {\"date\": [], \"weights\": []}\n",
    "            unique_trade_date = test_data.date.unique()\n",
    "            portfolio = pd.DataFrame(index=range(1), columns=unique_trade_date)\n",
    "            portfolio.loc[0, unique_trade_date[0]] = initial_capital\n",
    "\n",
    "            for i in range(len(unique_trade_date) - 1):\n",
    "                mu, sigma, tics, df_current, df_next = self._return_predict(\n",
    "                    unique_trade_date, test_data, i, tech_indicator_list)\n",
    "\n",
    "                portfolio_value = self._weight_optimization(\n",
    "                    i, unique_trade_date, meta_coefficient, mu, sigma, tics, portfolio, df_current, df_next)\n",
    "        \n",
    "            portfolio = portfolio_value\n",
    "            portfolio = portfolio.T\n",
    "            portfolio.columns = ['account_value']\n",
    "            portfolio = portfolio.reset_index()\n",
    "            portfolio.columns = ['date', 'account_value']\n",
    "\n",
    "            return portfolio, meta_coefficient\n",
    "            \n",
    "    def _return_predict(self, unique_trade_date, test_data, i, tech_indicator_list):\n",
    "\n",
    "        current_date = unique_trade_date[i]\n",
    "        next_date = unique_trade_date[i+1]\n",
    "\n",
    "        df_current = test_data[test_data.date ==\n",
    "                                  current_date].reset_index(drop=True)\n",
    "        df_next = test_data[test_data.date ==\n",
    "                               next_date].reset_index(drop=True)\n",
    "\n",
    "        tics = df_current['tic'].values\n",
    "        features = df_current[tech_indicator_list].values\n",
    "\n",
    "        predicted_y = self.model.predict(features)\n",
    "        mu = predicted_y\n",
    "        sigma = risk_models.sample_cov(\n",
    "            df_current.return_list[0], returns_data=True)\n",
    "\n",
    "        return mu, sigma, tics, df_current, df_next\n",
    "\n",
    "    def _weight_optimization(self, i, unique_trade_date, meta_coefficient, mu, sigma, tics, portfolio, df_current, df_next):\n",
    "\n",
    "        current_date = unique_trade_date[i]\n",
    "        predicted_y_df = pd.DataFrame(\n",
    "            {\"tic\": tics.reshape(-1,), \"predicted_y\": mu.reshape(-1,)})\n",
    "        min_weight, max_weight = 0, 1\n",
    "\n",
    "        ef = EfficientFrontier(mu, sigma)\n",
    "        weights = ef.nonconvex_objective(\n",
    "            objective_functions.sharpe_ratio,\n",
    "            objective_args=(ef.expected_returns, ef.cov_matrix),\n",
    "            weights_sum_to_one=True,\n",
    "            constraints=[\n",
    "                # greater than min_weight\n",
    "                {\"type\": \"ineq\", \"fun\": lambda w: w - min_weight},\n",
    "                # less than max_weight\n",
    "                {\"type\": \"ineq\", \"fun\": lambda w: max_weight - w},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        weight_df = {\"tic\": [], \"weight\": []}\n",
    "        meta_coefficient[\"date\"] += [current_date]\n",
    "\n",
    "        for item in weights:\n",
    "            weight_df['tic'] += [item]\n",
    "            weight_df['weight'] += [weights[item]]\n",
    "\n",
    "        weight_df = pd.DataFrame(weight_df).merge(predicted_y_df, on=['tic'])\n",
    "        meta_coefficient[\"weights\"] += [weight_df]\n",
    "        cap = portfolio.iloc[0, i]\n",
    "        # current cash invested for each stock\n",
    "        current_cash = [element * cap for element in list(weights.values())]\n",
    "        # current held shares\n",
    "        current_shares = list(np.array(current_cash) / np.array(df_current.close))\n",
    "        # next time period price\n",
    "        next_price = np.array(df_next.close)\n",
    "        portfolio.iloc[0, i+1] = np.dot(current_shares, next_price)\n",
    "\n",
    "        return portfolio \n",
    "    \n",
    "    def save_model(self,  file_name):\n",
    "        with open(file_name, 'wb') as files:\n",
    "            pickle.dump(self.model, files)\n",
    "        print(\"Model saved succesfully.\")\n",
    "\n",
    "\n",
    "    def load_model(self, file_name):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "        print(\"Model loaded succesfully.\")\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25],\n",
       "       [0.25],\n",
       "       [0.25],\n",
       "       [0.25],\n",
       "       [0.25]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.asarray([0.25] * 5)\n",
    "np.reshape(x,(len(x),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVRAgent(ConventionalAgent):\n",
    "    \n",
    "    def __init__(self,\n",
    "                kernel = 'rbf',\n",
    "                degree = 3,\n",
    "                gamma = 'scale',\n",
    "                coef0 = 0,\n",
    "                tol = 0.001,\n",
    "                C = 1,\n",
    "                epsilon = 0.1,\n",
    "                shrinking = True,\n",
    "                cache_size = 200,\n",
    "                verbose = False,\n",
    "                max_iter = -1):  \n",
    "\n",
    "        self.model = SVR(kernel= kernel,\n",
    "                        degree= degree,\n",
    "                        gamma= gamma, \n",
    "                        coef0= coef0,\n",
    "                        tol= tol,\n",
    "                        C= C,\n",
    "                        epsilon= epsilon,\n",
    "                        shrinking= shrinking,\n",
    "                        cache_size= cache_size,\n",
    "                        verbose= verbose,\n",
    "                        max_iter= max_iter)\n",
    "            \n",
    "    def get_params(self, deep = True):\n",
    "        return self.model.get_params(deep = deep)\n",
    "\n",
    "    def train_model(self, train_x, train_y, **train_params):\n",
    "        '''\n",
    "        *Trains the model*\n",
    "        Input: Train data x and train data y\n",
    "        Output: Linear Regression Model\n",
    "        '''\n",
    "        try:\n",
    "            trained = self.model.fit(train_x, train_y.ravel(), **train_params)\n",
    "            print(\"Model trained succesfully\")\n",
    "            return trained\n",
    "        except Exception as e:\n",
    "            print(\"training unsuccessful\")\n",
    "\n",
    "    def predict(self,\n",
    "               test_data, \n",
    "               initial_capital = 1000000,\n",
    "               transaction_cost_pct = 0.001,\n",
    "               tech_indicator_list = [\n",
    "                    \"macd\",\n",
    "                    \"boll_ub\",\n",
    "                    \"boll_lb\",\n",
    "                    \"rsi_30\",\n",
    "                    \"cci_30\",\n",
    "                    \"dx_30\",\n",
    "                    \"close_30_sma\",\n",
    "                    \"close_60_sma\",\n",
    "                ]):\n",
    "\n",
    "        meta_coefficient = {\"date\": []}\n",
    "        for i in test_data.tic:\n",
    "            meta_coefficient[i] = []\n",
    "        unique_trade_date = test_data.date.unique()\n",
    "        weight_arr = [np.array([1/len(test_data.tic.unique())]*len(test_data.tic.unique()))]\n",
    "        portfolio = pd.DataFrame(index=range(1), columns=unique_trade_date)\n",
    "        portfolio.loc[0, unique_trade_date[0]] = initial_capital\n",
    "        for i in range(len(unique_trade_date) - 1):\n",
    "            mu, sigma, tics, df_current, df_next = self._return_predict(\n",
    "                unique_trade_date, test_data, i, tech_indicator_list)\n",
    "\n",
    "            portfolio_value, weight_arr = self._weight_optimization(\n",
    "                i, unique_trade_date, meta_coefficient, mu, sigma, tics, portfolio, df_current, df_next, transaction_cost_pct, weight_arr)\n",
    "    \n",
    "        portfolio = portfolio_value\n",
    "        portfolio = portfolio.T\n",
    "        portfolio.columns = ['account_value']\n",
    "        portfolio = portfolio.reset_index()\n",
    "        portfolio.columns = ['date', 'account_value']\n",
    "        \n",
    "        meta_coefficient = pd.DataFrame(meta_coefficient).set_index(\"date\")\n",
    "        return portfolio, meta_coefficient\n",
    "    \n",
    "    def _return_predict(self, unique_trade_date, test_data, i, tech_indicator_list):\n",
    "\n",
    "        current_date = unique_trade_date[i]\n",
    "        next_date = unique_trade_date[i+1]\n",
    "\n",
    "        df_current = test_data[test_data.date ==\n",
    "                                  current_date].reset_index(drop=True)\n",
    "        df_next = test_data[test_data.date ==\n",
    "                               next_date].reset_index(drop=True)\n",
    "\n",
    "        tics = df_current['tic'].values\n",
    "        features = df_current[tech_indicator_list].values\n",
    "\n",
    "        predicted_y = self.model.predict(features)\n",
    "        mu = predicted_y\n",
    "        sigma = risk_models.sample_cov(\n",
    "            df_current.return_list[0], returns_data=True)\n",
    "\n",
    "        return mu, sigma, tics, df_current, df_next\n",
    "    \n",
    "    def _weight_optimization(self, i, unique_trade_date, meta_coefficient, mu, sigma, tics, portfolio, df_current, df_next, transaction_cost_pct, weight_arr):\n",
    "        current_date = unique_trade_date[i]\n",
    "        predicted_y_df = pd.DataFrame(\n",
    "            {\"tic\": tics.reshape(-1,), \"predicted_y\": mu.reshape(-1,)})\n",
    "        min_weight, max_weight = 0, 1\n",
    "\n",
    "        ef = EfficientFrontier(mu, sigma)\n",
    "        w_prev = np.array(weight_arr[-1],dtype=object)\n",
    "        print(w_prev)\n",
    "        print(\"---------------\")\n",
    "        ef.add_objective(objective_functions.transaction_cost, w_prev = w_prev, k = transaction_cost_pct)\n",
    "        weights = ef.nonconvex_objective(\n",
    "            objective_functions.sharpe_ratio,\n",
    "            objective_args=(ef.expected_returns, ef.cov_matrix),\n",
    "            weights_sum_to_one=True,\n",
    "            constraints=[\n",
    "                # greater than min_weight\n",
    "                {\"type\": \"ineq\", \"fun\": lambda w: w - min_weight},\n",
    "                # less than max_weight\n",
    "                {\"type\": \"ineq\", \"fun\": lambda w: max_weight - w},\n",
    "            ],\n",
    "        )\n",
    "   \n",
    "        \n",
    "        weight_df = {\"tic\": [], \"weight\": []}\n",
    "        meta_coefficient[\"date\"] += [current_date]\n",
    "\n",
    "        for item in weights:\n",
    "            weight_df['tic'] += [item]\n",
    "            weight_df['weight'] += [weights[item]]\n",
    "\n",
    "        weight_df = pd.DataFrame(weight_df).merge(predicted_y_df, on=['tic'])\n",
    "\n",
    "        tics_list = list(weight_df['tic'])\n",
    "        weights_list = list(weight_df['weight'])\n",
    "        new_weights = []\n",
    "        for j in range(len(tics_list)):\n",
    "            meta_coefficient[tics_list[j]] += [weights_list[j]]\n",
    "            new_weights.append(weights_list[j])\n",
    "        weight_arr.append(new_weights)\n",
    "        cap = portfolio.iloc[0, i]\n",
    "        # current cash invested for each stock\n",
    "        current_cash = [element * cap for element in list(weights.values())]\n",
    "        # current held shares\n",
    "        current_shares = list(np.array(current_cash) / np.array(df_current.close))\n",
    "        # next time period price\n",
    "        next_price = np.array(df_next.close)\n",
    "        portfolio.iloc[0, i+1] = np.dot(current_shares, next_price)\n",
    "\n",
    "        return portfolio , weight_arr\n",
    "\n",
    "    \n",
    "    def save_model(self,  file_name):\n",
    "        with open(file_name, 'wb') as files:\n",
    "            pickle.dump(self.model, files)\n",
    "        print(\"Model saved succesfully.\")\n",
    "\n",
    "\n",
    "    def load_model(self, file_name):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "        print(\"Model loaded succesfully.\")\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRAgent(ConventionalAgent):\n",
    "\n",
    "    def __init__(self,\n",
    "                 fit_intercept=True,\n",
    "                 copy_X=True,\n",
    "                 positive=False):\n",
    "        \"\"\"\n",
    "\n",
    "        @param fit_intercept:\n",
    "        @param copy_X:\n",
    "        @param positive:\n",
    "        \"\"\"\n",
    "        print(fit_intercept)\n",
    "        self.model = LinearRegression(fit_intercept=fit_intercept,\n",
    "                                      copy_X=copy_X,\n",
    "                                      positive=positive)\n",
    "\n",
    "    def train_model(self, train_x, train_y, **train_params):\n",
    "        \"\"\"\n",
    "\n",
    "        @param train_x:\n",
    "        @param train_y:\n",
    "        @param train_params:\n",
    "        @return:\n",
    "        \"\"\"\n",
    "        try:\n",
    "            trained_reg = self.model.fit(train_x, train_y, **train_params)\n",
    "            self.model = trained_reg\n",
    "            print(\"Model trained succesfully\")\n",
    "        except Exception as e:\n",
    "            print(\"training unsuccessful\")\n",
    "\n",
    "    def predict(self,\n",
    "                test_data,\n",
    "                initial_capital=1000000,\n",
    "                tech_indicator_list=[\n",
    "                    \"macd\",\n",
    "                    \"boll_ub\",\n",
    "                    \"boll_lb\",\n",
    "                    \"rsi_30\",\n",
    "                    \"cci_30\",\n",
    "                    \"dx_30\",\n",
    "                    \"close_30_sma\",\n",
    "                    \"close_60_sma\",\n",
    "                ]\n",
    "                ):\n",
    "        \"\"\"\n",
    "\n",
    "        @param test_data:\n",
    "        @param initial_capital:\n",
    "        @param tech_indicator_list:\n",
    "        @return:\n",
    "        \"\"\"\n",
    "\n",
    "        meta_coefficient = {\"date\": []}\n",
    "        for i in test_data.tic:\n",
    "            meta_coefficient[i] = []\n",
    "        unique_trade_date = test_data.date.unique()\n",
    "        portfolio = pd.DataFrame(index=range(1), columns=unique_trade_date)\n",
    "        portfolio.loc[0, unique_trade_date[0]] = initial_capital\n",
    "        for i in range(len(unique_trade_date) - 1):\n",
    "            mu, sigma, tics, df_current, df_next = self._return_predict(\n",
    "                unique_trade_date, test_data, i, tech_indicator_list)\n",
    "\n",
    "            portfolio_value = self._weight_optimization(\n",
    "                i, unique_trade_date, meta_coefficient, mu, sigma, tics, portfolio, df_current, df_next)\n",
    "    \n",
    "        portfolio = portfolio_value\n",
    "        portfolio = portfolio.T\n",
    "        portfolio.columns = ['account_value']\n",
    "        portfolio = portfolio.reset_index()\n",
    "        portfolio.columns = ['date', 'account_value']\n",
    "        \n",
    "        meta_coefficient = pd.DataFrame(meta_coefficient).set_index(\"date\")\n",
    "        return portfolio, meta_coefficient\n",
    "\n",
    "    def _return_predict(self, unique_trade_date, test_data, i, tech_indicator_list):\n",
    "        \"\"\"\n",
    "\n",
    "        @param unique_trade_date:\n",
    "        @param test_data:\n",
    "        @param i:\n",
    "        @param tech_indicator_list:\n",
    "        @return:\n",
    "        \"\"\"\n",
    "        current_date = unique_trade_date[i]\n",
    "        next_date = unique_trade_date[i + 1]\n",
    "\n",
    "        df_current = test_data[test_data.date ==\n",
    "                               current_date].reset_index(drop=True)\n",
    "        df_next = test_data[test_data.date ==\n",
    "                            next_date].reset_index(drop=True)\n",
    "\n",
    "        tics = df_current['tic'].values\n",
    "        features = df_current[tech_indicator_list].values\n",
    "\n",
    "        predicted_y = self.model.predict(features)\n",
    "        mu = predicted_y\n",
    "        sigma = risk_models.sample_cov(\n",
    "            df_current.return_list[0], returns_data=True)\n",
    "\n",
    "        return mu, sigma, tics, df_current, df_next\n",
    "\n",
    "    def _weight_optimization(self, i, unique_trade_date, meta_coefficient, mu, sigma, tics, portfolio, df_current,\n",
    "                             df_next):\n",
    "        \"\"\"\n",
    "\n",
    "        @param i:\n",
    "        @param unique_trade_date:\n",
    "        @param meta_coefficient:\n",
    "        @param mu:\n",
    "        @param sigma:\n",
    "        @param tics:\n",
    "        @param portfolio:\n",
    "        @param df_current:\n",
    "        @param df_next:\n",
    "        @return:\n",
    "        \"\"\"\n",
    "        current_date = unique_trade_date[i]\n",
    "        predicted_y_df = pd.DataFrame(\n",
    "            {\"tic\": tics.reshape(-1,), \"predicted_y\": mu.reshape(-1,)})\n",
    "        min_weight, max_weight = 0, 1\n",
    "\n",
    "        ef = EfficientFrontier(mu, sigma)\n",
    "        weights = ef.nonconvex_objective(\n",
    "            objective_functions.sharpe_ratio,\n",
    "            objective_args=(ef.expected_returns, ef.cov_matrix),\n",
    "            weights_sum_to_one=True,\n",
    "            constraints=[\n",
    "                # greater than min_weight\n",
    "                {\"type\": \"ineq\", \"fun\": lambda w: w - min_weight},\n",
    "                # less than max_weight\n",
    "                {\"type\": \"ineq\", \"fun\": lambda w: max_weight - w},\n",
    "            ],\n",
    "        )\n",
    "     \n",
    "        weight_df = {\"tic\": [], \"weight\": []}\n",
    "        meta_coefficient[\"date\"] += [current_date]\n",
    "\n",
    "        for item in weights:\n",
    "            weight_df['tic'] += [item]\n",
    "            weight_df['weight'] += [weights[item]]\n",
    "\n",
    "        weight_df = pd.DataFrame(weight_df).merge(predicted_y_df, on=['tic'])\n",
    "\n",
    "        tics_list = list(weight_df['tic'])\n",
    "        weights_list = list(weight_df['weight'])\n",
    "        for j in range(len(tics_list)):\n",
    "            meta_coefficient[tics_list[j]] += [weights_list[j]]\n",
    "\n",
    "        cap = portfolio.iloc[0, i]\n",
    "        # current cash invested for each stock\n",
    "        current_cash = [element * cap for element in list(weights.values())]\n",
    "        # current held shares\n",
    "        current_shares = list(np.array(current_cash) / np.array(df_current.close))\n",
    "        # next time period price\n",
    "        next_price = np.array(df_next.close)\n",
    "        portfolio.iloc[0, i+1] = np.dot(current_shares, next_price)\n",
    "\n",
    "        return portfolio \n",
    "\n",
    "    def save_model(self, file_name):\n",
    "        \"\"\"\n",
    "\n",
    "        @param file_name:\n",
    "        @return:\n",
    "        \"\"\"\n",
    "        with open(file_name, 'wb') as files:\n",
    "            pickle.dump(self.model, files)\n",
    "        print(\"Model saved succesfully.\")\n",
    "\n",
    "    def load_model(self, file_name):\n",
    "        \"\"\"\n",
    "\n",
    "        @param file_name:\n",
    "        @return:\n",
    "        \"\"\"\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "        print(\"Model loaded succesfully.\")\n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioEnv(Environment):\n",
    "\n",
    "    def __init__(self,\n",
    "                 df: pd.DataFrame,  # input data\n",
    "                 stock_dim: int,  # number of unique securities in the investment universe\n",
    "                 hmax: float,  # maximum number of shares to trade\n",
    "                 initial_amount: float,  # initial cash value\n",
    "                 transaction_cost_pct: float,  # transaction cost percentage per trade\n",
    "                 reward_scaling: float,  # scaling factor for reward as training progresses\n",
    "                 state_space: int,  # the dimension of input features (state space)\n",
    "                 action_space: int,  # number of actions, which is equal to portfolio dimension\n",
    "                 tech_indicator_list: list,  # a list of technical indicator names\n",
    "                 lookback=252,  #\n",
    "                 day=0):  # an increment number to control date\n",
    "\n",
    "        self.df = df\n",
    "        self.day = day\n",
    "        self.lookback = lookback\n",
    "        self.stock_dim = stock_dim\n",
    "        self.hmax = hmax\n",
    "        self.initial_amount = initial_amount\n",
    "        self.transaction_cost_pct = transaction_cost_pct\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "\n",
    "        # action_space normalization and shape is self.stock_dim\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(self.action_space,))\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf,\n",
    "                                            shape=(self.state_space + len(self.tech_indicator_list), self.state_space))\n",
    "        \n",
    "\n",
    "        # load data from a pandas dataframe\n",
    "        \n",
    "        \n",
    "        self.data = self.df.loc[self.day,:]\n",
    "        self.covs = self.data['cov_list'].values[0]\n",
    "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
    "        self.terminal = False\n",
    "        #self.turbulence_threshold = turbulence_threshold\n",
    "        # initalize state: initial portfolio return + individual stock return + individual weights\n",
    "        self.portfolio_value = self.initial_amount\n",
    "\n",
    "        # memorize portfolio value each step\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        # memorize portfolio return each step\n",
    "        self.portfolio_return_memory = [0]\n",
    "        self.actions_memory = [[1 / self.stock_dim] * self.stock_dim]\n",
    "        self.date_memory=[self.data.date.unique()[0]]\n",
    "\n",
    "    def reset(self):\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        self.day = 0\n",
    "        self.data = self.df.loc[self.day,:]\n",
    "        # load states\n",
    "        self.covs = self.data['cov_list'].values[0]\n",
    "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
    "                \n",
    "        self.portfolio_value = self.initial_amount\n",
    "        self.terminal = False \n",
    "        self.portfolio_return_memory = [0]\n",
    "        self.actions_memory=[[1/self.stock_dim] * self.stock_dim]\n",
    "        self.date_memory=[self.data.date.unique()[0]] \n",
    "        return self.state\n",
    "\n",
    "    def step(self, actions):\n",
    "        self.terminal = self.day >= len(self.df.index.unique()) - 1\n",
    "        if self.terminal:\n",
    "            df = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df.columns = ['daily_return']\n",
    "            print(\"=================================\")\n",
    "            print(\"begin_total_asset:{}\".format(self.asset_memory[0]))\n",
    "            print(\"end_total_asset:{}\".format(self.portfolio_value))\n",
    "\n",
    "            df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df_daily_return.columns = ['daily_return']\n",
    "            if df_daily_return['daily_return'].std() != 0:\n",
    "                sharpe = (252 ** 0.5) * df_daily_return['daily_return'].mean() / \\\n",
    "                         df_daily_return['daily_return'].std()\n",
    "                print(\"Sharpe: \", sharpe)\n",
    "            print(\"=================================\")\n",
    "\n",
    "            return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "        else:\n",
    "            weights = Environment.softmax_normalization(actions)\n",
    "            self.actions_memory.append(weights)\n",
    "            transaction_fee = self.transaction_cost_pct * self.asset_memory[-1] * sum([abs(a_i - b_i) for a_i, b_i in zip(self.actions_memory[-1], self.actions_memory[-2])]) #transaction_fee\n",
    "            last_day_memory = self.data\n",
    "            # load next state\n",
    "            self.day += 1\n",
    "            self.data = self.df.loc[self.day, :]\n",
    "            self.covs = self.data['cov_list'].values[0]\n",
    "            self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)         \n",
    "            portfolio_return = sum(((self.data.close.values / last_day_memory.close.values) - 1) * weights)\n",
    "            # update portfolio value\n",
    "            new_portfolio_value = self.portfolio_value * (1 + portfolio_return) - transaction_fee #transaction_fee\n",
    "            self.portfolio_value = new_portfolio_value\n",
    "\n",
    "            # save into memory\n",
    "            self.portfolio_return_memory.append(portfolio_return)\n",
    "            self.date_memory.append(self.data[\"date\"].unique()[0])\n",
    "            self.asset_memory.append(new_portfolio_value)\n",
    "\n",
    "            # the reward is the new portfolio value or end portfolo value\n",
    "            self.reward = new_portfolio_value\n",
    "\n",
    "        return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        return self.state\n",
    "\n",
    "    def save_asset_memory(self):\n",
    "        date_list = self.date_memory\n",
    "        portfolio_return = self.portfolio_return_memory\n",
    "        df_account_value = pd.DataFrame({'date': date_list, 'daily_return': portfolio_return})\n",
    "        return df_account_value\n",
    "\n",
    "    def save_action_memory(self):\n",
    "        # date and close price length must match actions length\n",
    "        date_list = self.date_memory\n",
    "        df_date = pd.DataFrame(date_list)\n",
    "        df_date.columns = ['date']\n",
    "\n",
    "        action_list = self.actions_memory\n",
    "        df_actions = pd.DataFrame(action_list)\n",
    "        df_actions.columns = self.data.tic.values\n",
    "        df_actions.index = df_date.date\n",
    "        # df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
    "        return df_actions\n",
    "\n",
    "    def get_env(self):\n",
    "        e = DummyVecEnv([lambda: self])\n",
    "        obs = e.reset()\n",
    "        return e, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A2C(RLAgent):\n",
    "\n",
    "    def __init__(self,\n",
    "                 policy: \"MlpPolicy\",\n",
    "                 env: None,\n",
    "                 learning_rate: float = 7e-4,\n",
    "                 n_steps: int = 5,\n",
    "                 gamma: float = 0.99,\n",
    "                 gae_lambda: float = 1.0,\n",
    "                 ent_coef: float = 0.0,\n",
    "                 vf_coef: float = 0.5,\n",
    "                 max_grad_norm: float = 0.5,\n",
    "                 rms_prop_eps: float = 1e-5,\n",
    "                 use_rms_prop: bool = True,\n",
    "                 use_sde: bool = False,\n",
    "                 sde_sample_freq: int = -1,\n",
    "                 normalize_advantage: bool = False,\n",
    "                 tensorboard_log: Optional[str] = None,\n",
    "                 create_eval_env: bool = False,\n",
    "                 policy_kwargs: Optional[Dict[str, Any]] = None,\n",
    "                 verbose: int = 0,\n",
    "                 seed: Optional[int] = None,\n",
    "                 device: Union[th.device, str] = \"auto\",\n",
    "                 _init_setup_model: bool = True):\n",
    "\n",
    "        self.env = env\n",
    "\n",
    "        self.model = sb_A2C(policy = policy,\n",
    "                            env=self.env,\n",
    "                            learning_rate = learning_rate,\n",
    "                            n_steps = n_steps,\n",
    "                            gamma = gamma,\n",
    "                            gae_lambda= gae_lambda,\n",
    "                            ent_coef = ent_coef,\n",
    "                            vf_coef = vf_coef,\n",
    "                            max_grad_norm = max_grad_norm,\n",
    "                            rms_prop_eps= rms_prop_eps,\n",
    "                            use_rms_prop= use_rms_prop,\n",
    "                            use_sde= use_sde,\n",
    "                            sde_sample_freq= sde_sample_freq,\n",
    "                            normalize_advantage= normalize_advantage,\n",
    "                            tensorboard_log=tensorboard_log,  \n",
    "                            create_eval_env= create_eval_env,\n",
    "                            policy_kwargs=policy_kwargs,\n",
    "                            verbose=verbose,\n",
    "                            seed=seed,\n",
    "                            device= device,\n",
    "                            _init_setup_model = _init_setup_model)\n",
    "\n",
    "    def train_model(self, **train_params):\n",
    "        self.model = self.model.learn(**train_params)\n",
    "        return self.model\n",
    "\n",
    "    def predict(self, environment, **test_params):\n",
    "\n",
    "        env_test, obs_test = environment.get_env()\n",
    "        \"\"\"make a prediction\"\"\"\n",
    "        account_memory = []\n",
    "        actions_memory = []\n",
    "\n",
    "        env_test.reset()\n",
    "        for i in range(len(environment.df.index.unique())):\n",
    "            action, _states = self.model.predict(obs_test, **test_params)\n",
    "            obs_test, rewards, dones, info = env_test.step(action)\n",
    "            if i == (len(environment.df.index.unique()) - 2):\n",
    "                account_memory = env_test.env_method(method_name=\"save_asset_memory\")\n",
    "                actions_memory = env_test.env_method(method_name=\"save_action_memory\")\n",
    "            if dones[0]:\n",
    "                print(\"hit end!\")\n",
    "                break\n",
    "        \n",
    "        portfolio_df = account_memory[0]\n",
    "        portfolio_df = portfolio_df.rename(columns={\"daily_return\": \"account_value\"})\n",
    "        portfolio_df.iloc[0, portfolio_df.columns.get_loc(\"account_value\")] = environment.initial_amount\n",
    "        values = list(portfolio_df[\"account_value\"])\n",
    "        for i in range(1,len(values)):\n",
    "            values[i] = (values[i] + 1) * values[i-1]\n",
    "\n",
    "        portfolio_df[\"account_value\"] = values\n",
    "        return portfolio_df, actions_memory[0]\n",
    "\n",
    "    def save_model(self, path):\n",
    "        self.model.save(path)\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model = self.model.load(path)\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO(RLAgent):\n",
    "    def __init__(self,\n",
    "                policy: \"MlpPolicy\",\n",
    "                env: None,\n",
    "                learning_rate:  3e-4,\n",
    "                n_steps: int = 2048,\n",
    "                batch_size: int = 64,\n",
    "                n_epochs: int = 10,\n",
    "                gamma: float = 0.99,\n",
    "                gae_lambda: float = 0.95,\n",
    "                clip_range: Union[float, Schedule] = 0.2,\n",
    "                clip_range_vf: Union[None, float, Schedule] = None,\n",
    "                normalize_advantage: bool = True,\n",
    "                ent_coef: float = 0.0,\n",
    "                vf_coef: float = 0.5,\n",
    "                max_grad_norm: float = 0.5,\n",
    "                use_sde: bool = False,\n",
    "                sde_sample_freq: int = -1,\n",
    "                target_kl: Optional[float] = None,\n",
    "                tensorboard_log: Optional[str] = None,\n",
    "                create_eval_env: bool = False,\n",
    "                policy_kwargs: Optional[Dict[str, Any]] = None,\n",
    "                verbose: int = 0,\n",
    "                seed: Optional[int] = None,\n",
    "                device: Union[th.device, str] = \"auto\",\n",
    "                _init_setup_model: bool = True):\n",
    "\n",
    "        self.env = env\n",
    "        self.model = sb_PPO(policy = policy,\n",
    "                            env=self.env,\n",
    "                            learning_rate = learning_rate,\n",
    "                            n_steps = n_steps,\n",
    "                            gamma = gamma,\n",
    "                            batch_size = batch_size,\n",
    "                            n_epochs = n_epochs,\n",
    "                            gae_lambda=gae_lambda,\n",
    "                            clip_range = clip_range,\n",
    "                            clip_range_vf = clip_range_vf,\n",
    "                            normalize_advantage=normalize_advantage,\n",
    "                            ent_coef=ent_coef,\n",
    "                            vf_coef=vf_coef,\n",
    "                            max_grad_norm=max_grad_norm,\n",
    "                            use_sde=use_sde,\n",
    "                            sde_sample_freq=sde_sample_freq,\n",
    "                            target_kl=target_kl,\n",
    "                            tensorboard_log=tensorboard_log,\n",
    "                            create_eval_env=create_eval_env,\n",
    "                            policy_kwargs=policy_kwargs,\n",
    "                            verbose=verbose,\n",
    "                            seed=seed,\n",
    "                            device=device,\n",
    "                            _init_setup_model = _init_setup_model)\n",
    "    \n",
    "    def train_model(self, **train_params):\n",
    "        self.model = self.model.learn(**train_params)\n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, environment, **test_params):\n",
    "\n",
    "        env_test, obs_test = environment.get_env()\n",
    "        \"\"\"make a prediction\"\"\"\n",
    "        account_memory = []\n",
    "        actions_memory = []\n",
    "\n",
    "        env_test.reset()\n",
    "        for i in range(len(environment.df.index.unique())):\n",
    "            action, _states = self.model.predict(obs_test, **test_params)\n",
    "            obs_test, rewards, dones, info = env_test.step(action)\n",
    "            if i == (len(environment.df.index.unique()) - 2):\n",
    "                account_memory = env_test.env_method(method_name=\"save_asset_memory\")\n",
    "                actions_memory = env_test.env_method(method_name=\"save_action_memory\")\n",
    "            if dones[0]:\n",
    "                print(\"hit end!\")\n",
    "                break\n",
    "        \n",
    "        portfolio_df = account_memory[0]\n",
    "        portfolio_df = portfolio_df.rename(columns={\"daily_return\": \"account_value\"})\n",
    "        portfolio_df.iloc[0, portfolio_df.columns.get_loc(\"account_value\")] = environment.initial_amount\n",
    "        values = list(portfolio_df[\"account_value\"])\n",
    "        for i in range(1,len(values)):\n",
    "            values[i] = (values[i] + 1) * values[i-1]\n",
    "\n",
    "        portfolio_df[\"account_value\"] = values\n",
    "        return portfolio_df, actions_memory[0]\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        self.model = self.model.load(path)\n",
    "        return self.model\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        self.model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPG(RLAgent):\n",
    "    def __init__(self,\n",
    "                policy: \"MlpPolicy\",\n",
    "                env: None,\n",
    "                learning_rate : 1e-3,\n",
    "                buffer_size: 1_000_000,  # 1e6\n",
    "                learning_starts: 100,\n",
    "                batch_size:  100,\n",
    "                tau:  0.005,\n",
    "                gamma:  0.99,\n",
    "                train_freq:  1,\n",
    "                gradient_steps: int = -1,\n",
    "                action_noise: Optional[ActionNoise] = None,\n",
    "                replay_buffer_class: Optional[ReplayBuffer] = None,\n",
    "                replay_buffer_kwargs: Optional[Dict[str, Any]] = None,\n",
    "                optimize_memory_usage: bool = False,\n",
    "                tensorboard_log: Optional[str] = None,\n",
    "                create_eval_env: bool = False,\n",
    "                policy_kwargs: Optional[Dict[str, Any]] = None,\n",
    "                verbose: int = 0,\n",
    "                seed: Optional[int] = None,\n",
    "                device: Union[th.device, str] = \"auto\",\n",
    "                _init_setup_model: bool = True):\n",
    "                \n",
    "        self.env = env\n",
    "    \n",
    "        self.model = sb_DDPG(policy = policy,\n",
    "                            env=self.env,\n",
    "                            learning_rate = learning_rate,\n",
    "                            buffer_size = buffer_size,\n",
    "                            learning_starts= learning_starts,\n",
    "                            batch_size = batch_size,\n",
    "                            tau = tau,\n",
    "                            gamma= gamma,\n",
    "                            train_freq = train_freq,\n",
    "                            gradient_steps = gradient_steps,\n",
    "                            action_noise= action_noise,\n",
    "                            replay_buffer_class= replay_buffer_class,\n",
    "                            replay_buffer_kwargs= replay_buffer_kwargs,\n",
    "                            optimize_memory_usage=optimize_memory_usage,\n",
    "                            tensorboard_log=tensorboard_log,\n",
    "                            create_eval_env=create_eval_env,\n",
    "                            policy_kwargs=policy_kwargs,\n",
    "                            verbose=verbose,\n",
    "                            seed=seed,\n",
    "                            device=device,\n",
    "                            _init_setup_model = _init_setup_model)\n",
    "\n",
    "    def train_model(self, **train_params):\n",
    "        self.model = self.model.learn(**train_params)\n",
    "        return self.model\n",
    "\n",
    "    def predict(self, environment, **test_params):\n",
    "\n",
    "            env_test, obs_test = environment.get_env()\n",
    "            \"\"\"make a prediction\"\"\"\n",
    "            account_memory = []\n",
    "            actions_memory = []\n",
    "\n",
    "            env_test.reset()\n",
    "            for i in range(len(environment.df.index.unique())):\n",
    "                action, _states = self.model.predict(obs_test, **test_params)\n",
    "                obs_test, rewards, dones, info = env_test.step(action)\n",
    "                if i == (len(environment.df.index.unique()) - 2):\n",
    "                    account_memory = env_test.env_method(method_name=\"save_asset_memory\")\n",
    "                    actions_memory = env_test.env_method(method_name=\"save_action_memory\")\n",
    "                if dones[0]:\n",
    "                    print(\"hit end!\")\n",
    "                    break\n",
    "            \n",
    "            portfolio_df = account_memory[0]\n",
    "            portfolio_df = portfolio_df.rename(columns={\"daily_return\": \"account_value\"})\n",
    "            portfolio_df.iloc[0, portfolio_df.columns.get_loc(\"account_value\")] = environment.initial_amount\n",
    "            values = list(portfolio_df[\"account_value\"])\n",
    "            for i in range(1,len(values)):\n",
    "                values[i] = (values[i] + 1) * values[i-1]\n",
    "\n",
    "            portfolio_df[\"account_value\"] = values\n",
    "            return portfolio_df, actions_memory[0]\n",
    "            \n",
    "    def load_model(self, path):\n",
    "        self.model = self.model.load(path)\n",
    "        return self.model\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        self.model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TD3(RLAgent):\n",
    " \n",
    "    def __init__(self,\n",
    "                policy: \"MlpPolicy\",\n",
    "                env: None,\n",
    "                learning_rate: float =  1e-3,\n",
    "                buffer_size: int = 1_000_000,  # 1e6\n",
    "                learning_starts: int = 100,\n",
    "                batch_size: int = 100,\n",
    "                tau: float = 0.005,\n",
    "                gamma: float = 0.99,\n",
    "                train_freq: int = 1,\n",
    "                gradient_steps: int = -1,\n",
    "                action_noise: Optional[ActionNoise] = None,\n",
    "                replay_buffer_class: Optional[ReplayBuffer] = None,\n",
    "                replay_buffer_kwargs: Optional[Dict[str, Any]] = None,\n",
    "                optimize_memory_usage: bool = False,\n",
    "                tensorboard_log: Optional[str] = None,\n",
    "                create_eval_env: bool = False,\n",
    "                policy_kwargs: Optional[Dict[str, Any]] = None,\n",
    "                verbose: int = 0,\n",
    "                seed: Optional[int] = None,\n",
    "                device: Union[th.device, str] = \"auto\",\n",
    "                _init_setup_model: bool = True):\n",
    "                \n",
    "        self.env = env\n",
    "    \n",
    "        self.model = sb_TD3(policy = policy,\n",
    "                            env=self.env,\n",
    "                            learning_rate = learning_rate,\n",
    "                            buffer_size = buffer_size,\n",
    "                            learning_starts= learning_starts,\n",
    "                            batch_size = batch_size,\n",
    "                            tau = tau,\n",
    "                            gamma= gamma,\n",
    "                            train_freq = train_freq,\n",
    "                            gradient_steps = gradient_steps,\n",
    "                            action_noise= action_noise,\n",
    "                            replay_buffer_class= replay_buffer_class,\n",
    "                            replay_buffer_kwargs= replay_buffer_kwargs,\n",
    "                            optimize_memory_usage=optimize_memory_usage,\n",
    "                            tensorboard_log=tensorboard_log,\n",
    "                            create_eval_env=create_eval_env,\n",
    "                            policy_kwargs=policy_kwargs,\n",
    "                            verbose=verbose,\n",
    "                            seed=seed,\n",
    "                            device=device,\n",
    "                            _init_setup_model = _init_setup_model)\n",
    "\n",
    "    def train_model(self, **train_params):\n",
    "        self.model = self.model.learn(**train_params)\n",
    "        return self.model\n",
    "\n",
    "    def predict(self, environment, **test_params):\n",
    "\n",
    "        env_test, obs_test = environment.get_env()\n",
    "        \"\"\"make a prediction\"\"\"\n",
    "        account_memory = []\n",
    "        actions_memory = []\n",
    "\n",
    "        env_test.reset()\n",
    "        for i in range(len(environment.df.index.unique())):\n",
    "            action, _states = self.model.predict(obs_test, **test_params)\n",
    "            obs_test, rewards, dones, info = env_test.step(action)\n",
    "            if i == (len(environment.df.index.unique()) - 2):\n",
    "                account_memory = env_test.env_method(method_name=\"save_asset_memory\")\n",
    "                actions_memory = env_test.env_method(method_name=\"save_action_memory\")\n",
    "            if dones[0]:\n",
    "                print(\"hit end!\")\n",
    "                break\n",
    "        \n",
    "        portfolio_df = account_memory[0]\n",
    "        portfolio_df = portfolio_df.rename(columns={\"daily_return\": \"account_value\"})\n",
    "        portfolio_df.iloc[0, portfolio_df.columns.get_loc(\"account_value\")] = environment.initial_amount\n",
    "        values = list(portfolio_df[\"account_value\"])\n",
    "        for i in range(1,len(values)):\n",
    "            values[i] = (values[i] + 1) * values[i-1]\n",
    "\n",
    "        portfolio_df[\"account_value\"] = values\n",
    "        return portfolio_df, actions_memory[0]\n",
    "        \n",
    "    def load_model(self, path):\n",
    "        self.model = self.model.load(path)\n",
    "        return self.model\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        self.model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather user parameters\n",
    "with open(\"../user_params.yaml\", \"r\") as stream:\n",
    "    try:\n",
    "        user_params = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = user_params[\"TICKERS\"]\n",
    "env_kwargs = user_params[\"ENV_PARAMS\"]\n",
    "train_params = user_params[\"TRAIN_PARAMS\"]\n",
    "policy_params = user_params[\"POLICY_PARAMS\"]\n",
    "test_params = user_params[\"TEST_PARAMS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test 3: Downloading from Yahoo.........\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (12924, 8)\n",
      "        date       open       high        low      close     volume   tic  day\n",
      "0 2008-12-31   3.070357   3.133571   3.047857   2.606277  607541200  AAPL    2\n",
      "1 2008-12-31  41.590000  43.049999  41.500000  32.005890    5443100    BA    2\n",
      "2 2008-12-31  43.700001  45.099998  43.700001  30.628826    6277400   CAT    2\n",
      "3 2008-12-31  72.900002  74.629997  72.900002  43.314426    9964300   CVX    2\n",
      "4 2009-01-02   3.067143   3.251429   3.041429   2.771173  746015200  AAPL    4\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTest 3: Downloading from Yahoo.........\")\n",
    "downloaded_df = DataDownloader(start_date='2009-01-01',\n",
    "                                end_date='2021-10-31',\n",
    "                                ticker_list= tickers).download_from_yahoo()\n",
    "print(downloaded_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test 4: Feature engineer.........\n",
      "Successfully added technical indicators\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (3231, 8)\n",
      "Successfully added vix\n",
      "Successfully added turbulence index\n",
      "Successfully added covariances\n",
      "Successfully added returns\n"
     ]
    }
   ],
   "source": [
    " # PREPROCESS DATA\n",
    "print(\"\\nTest 4: Feature engineer.........\")\n",
    "data_processor = DefaultFeatureEngineer(use_default=False,\n",
    "                                        tech_indicator_list=env_kwargs[\"tech_indicator_list\"],\n",
    "                                        use_vix=True,\n",
    "                                        use_turbulence=True,\n",
    "                                        use_covar=True)\n",
    "# included technical indicators as features\n",
    "df_processed = data_processor.extend_data(downloaded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = TimeSeriesSplitter()\n",
    "train = splitter.get_split_data(df_processed, '2009-01-01', '2020-06-30')\n",
    "trade = splitter.get_split_data(df_processed, '2020-07-01', '2021-09-02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare conventional data\n",
    "X, y = data_processor.prepare_ml_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'degree': 3, 'gamma': 'scale', 'coef0': 0, 'tol': 0.001, 'epsilon': 0.1, 'shrinking': True, 'cache_size': 200, 'verbose': False, 'max_iter': -1}\n"
     ]
    }
   ],
   "source": [
    "policy_params[\"SVR_PARAMS\"].pop('C', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_params = policy_params[\"SVR_PARAMS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = BlockingTimeSeriesSplitter(n_splits = 5)\n",
    "for i,j in cv.split(X,y):\n",
    "    print(i)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CC= [0.01, 1, 100]\n",
    "svr_scores = []\n",
    "for c in CC:\n",
    "    btss = BlockingTimeSeriesSplitter(n_splits = 5)\n",
    "    svr = SVRAgent(C =c, **svr_params)\n",
    "    scores = []\n",
    "    for train_idx,test_idx in btss.split(X,y):\n",
    "       svr.train_model(X[train_idx], y[train_idx], **train_params[\"SVR_PARAMS\"])\n",
    "       temp_portfolio,_,_ = svr.predict(X[test_idx], **test_params[\"SVR_PARAMS\"])\n",
    "       scores.append(temp_portfolio.tail(1)[\"account_value\"][0])\n",
    "       \n",
    "    scores_mean = sum(scores) / len(scores)\n",
    "    print(scores_mean)\n",
    "    svr_scores.append(scores_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create agent\n",
    "svr = SVRAgent(**policy_params[\"SVR_PARAMS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained succesfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1, coef0=0)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr.train_model(X, y, **train_params[\"SVR_PARAMS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25 0.25 0.25 0.25]\n",
      "---------------\n",
      "[0.0 1.0 0.0 0.0]\n",
      "---------------\n",
      "[5.233631138980191e-17 1.0 0.0 6.6547046648835655e-19]\n",
      "---------------\n",
      "[0.0 0.9999999999999998 1.6653345369377348e-16 1.0099357455337315e-16]\n",
      "---------------\n",
      "[0.0 0.9999999999999999 3.3306690738754696e-16 0.0]\n",
      "---------------\n",
      "[1.0020135657823857e-16 1.0 0.0 6.876750473604274e-19]\n",
      "---------------\n",
      "[6.568032439433712e-17 0.9999999999999999 8.326672684688674e-17\n",
      " 5.626902065834138e-17]\n",
      "---------------\n",
      "[0.0 1.0 2.7755575615628914e-17 4.112382106040844e-17]\n",
      "---------------\n",
      "[5.161294594603768e-17 1.0 0.0 4.029129968539667e-17]\n",
      "---------------\n",
      "[0.0 1.0 2.220446049250313e-16 0.0]\n",
      "---------------\n",
      "[6.321234834330744e-17 1.0 0.0 0.0]\n",
      "---------------\n",
      "[0.0 1.0 0.0 1.2491826339985263e-17]\n",
      "---------------\n",
      "[0.0 1.0 0.0 0.0]\n",
      "---------------\n",
      "[1.8134957645801395e-17 1.0 0.0 7.154551451430371e-17]\n",
      "---------------\n",
      "[0.0 1.0 1.249000902703301e-16 0.0]\n",
      "---------------\n",
      "[5.421606887426042e-17 1.0 0.0 0.0]\n",
      "---------------\n",
      "[4.133457043706442e-18 1.0 6.938893903907228e-17 5.832210417652506e-18]\n",
      "---------------\n",
      "[2.7087633625970008e-17 1.0 0.0 0.0]\n",
      "---------------\n",
      "[2.0816681711721685e-17 0.9999999999999999 7.043491041969769e-17\n",
      " 8.326672684688674e-17]\n",
      "---------------\n",
      "[0.0 1.0 2.2551405187698492e-17 0.0]\n",
      "---------------\n",
      "[2.0816681711721685e-17 1.0 8.221286142794618e-17 0.0]\n",
      "---------------\n",
      "[0.0 8.881784197001252e-16 0.9999999999999991 5.148882705414565e-18]\n",
      "---------------\n",
      "[0.0 2.498001805406602e-16 1.0 7.453190154655698e-17]\n",
      "---------------\n",
      "[0.8695438168215598 0.0 0.13045618317844554 0.0]\n",
      "---------------\n",
      "[1.2010873284393823e-15 0.0 1.0 0.0]\n",
      "---------------\n",
      "[0.0 1.0 0.0 2.0348406650399417e-16]\n",
      "---------------\n",
      "[0.0 0.9999999999999998 3.885780586188048e-16 0.0]\n",
      "---------------\n",
      "[0.0 0.9999999999999999 2.7755575615628914e-16 4.42768870395779e-17]\n",
      "---------------\n",
      "[0.0 0.9999999999999999 1.3877787807814457e-16 6.300596093378972e-17]\n",
      "---------------\n",
      "[0.0 1.0 0.0 0.0]\n",
      "---------------\n",
      "[0.0 1.0 0.0 9.177510095846021e-19]\n",
      "---------------\n",
      "[0.0 1.0 0.0 5.677310047445082e-17]\n",
      "---------------\n",
      "[5.901256152304853e-17 1.0 0.0 3.4161747188918202e-18]\n",
      "---------------\n",
      "[0.0 0.9999999999999996 4.996003610813204e-16 5.566002248521914e-17]\n",
      "---------------\n",
      "[2.922397215910851e-17 1.0 0.0 2.1734549183452904e-16]\n",
      "---------------\n",
      "[0.0 1.0 0.0 1.591121239010072e-16]\n",
      "---------------\n",
      "[1.584930582278869e-16 0.9999999999999991 7.424616477180734e-16 0.0]\n",
      "---------------\n",
      "[0.0 1.0 0.0 3.69342218967821e-16]\n",
      "---------------\n",
      "[0.0 0.9999999999999999 0.0 1.1525363139727785e-16]\n",
      "---------------\n",
      "[0.0 1.0 0.0 5.3688480260734867e-17]\n",
      "---------------\n",
      "[0.0 0.9999999999999998 0.0 2.421250433683947e-16]\n",
      "---------------\n",
      "[7.674805267908345e-17 1.0 5.551115123125783e-17 0.0]\n",
      "---------------\n",
      "[0.0 1.0 0.0 0.0]\n",
      "---------------\n",
      "[7.711138560073575e-18 0.9999999999999999 3.0531133177191805e-16 0.0]\n",
      "---------------\n",
      "[1.3315581933773415e-16 0.9999999999999999 0.0 7.644607230512059e-17]\n",
      "---------------\n",
      "[6.47047380633394e-17 1.0 0.0 0.0]\n",
      "---------------\n",
      "[6.938893903907228e-17 0.9999999999999999 7.28583859910259e-17 0.0]\n",
      "---------------\n",
      "[3.599551212651875e-17 1.0 4.9873299934333204e-18 5.2150124496552763e-17]\n",
      "---------------\n",
      "[3.365363543395006e-16 0.9999999999999999 2.2551405187698492e-17 0.0]\n",
      "---------------\n",
      "[0.0 1.0 1.3877787807814457e-17 0.0]\n",
      "---------------\n",
      "[8.326672684688674e-17 1.0 0.0 1.3877787807814457e-17]\n",
      "---------------\n",
      "[0.0 1.0 0.0 6.591949208711867e-17]\n",
      "---------------\n",
      "[0.0 1.0 0.0 0.0]\n",
      "---------------\n",
      "[0.0 1.0 0.0 0.0]\n",
      "---------------\n",
      "[3.3380273971711046e-17 1.0 0.0 1.7285915398971107e-17]\n",
      "---------------\n",
      "[0.0 0.9999999999999998 3.157196726277789e-16 0.0]\n",
      "---------------\n",
      "[0.0 1.0 0.0 0.0]\n",
      "---------------\n",
      "[0.0 0.0 1.0 0.0]\n",
      "---------------\n",
      "[5.610146361047247e-17 0.0 1.0 0.0]\n",
      "---------------\n",
      "[0.0 0.0 1.0 0.0]\n",
      "---------------\n",
      "[0.0 0.0 1.0 8.071064286596896e-17]\n",
      "---------------\n",
      "[0.0 0.0 1.0 0.0]\n",
      "---------------\n",
      "[6.238257009167734e-18 0.5141151591179645 0.48588484088203554 0.0]\n",
      "---------------\n",
      "[0.0 0.36794541474678094 0.6320545852532193 0.0]\n",
      "---------------\n",
      "[2.8651883905679425e-16 0.4655811529202027 0.534418847079797\n",
      " 8.895333980918538e-17]\n",
      "---------------\n",
      "[0.0 0.14434060710511465 0.8556593928948859 0.0]\n",
      "---------------\n",
      "[0.0 0.1000030520548542 0.899996947945146 9.346549885511371e-17]\n",
      "---------------\n",
      "[0.0 0.5919285058988162 0.40807149410118404 0.0]\n",
      "---------------\n",
      "[2.196855766137469e-17 0.9999999999999998 2.654126918244515e-16 0.0]\n",
      "---------------\n",
      "[0.0 1.0 0.0 6.94238283511202e-17]\n",
      "---------------\n",
      "[4.1766624280771455e-18 0.9999999999999998 1.942890293094024e-16\n",
      " 6.705376426154851e-17]\n",
      "---------------\n",
      "[2.7755575615628914e-17 1.0 0.0 3.8163916471489756e-17]\n",
      "---------------\n",
      "[2.1499458709548652e-17 1.0 6.938893903907228e-18 4.280836639503417e-17]\n",
      "---------------\n",
      "[2.1510571102112408e-16 0.9999999999999999 2.3418766925686896e-17 0.0]\n",
      "---------------\n",
      "[0.0 1.0 0.0 5.2475385148298415e-17]\n",
      "---------------\n",
      "[2.636779683484747e-16 1.0 0.0 7.19910242530375e-17]\n",
      "---------------\n",
      "[0.0 1.0 0.0 0.0]\n",
      "---------------\n",
      "[6.938893903907228e-18 1.0 0.0 0.0]\n",
      "---------------\n",
      "[0.0 0.9999999999999998 1.3877787807814457e-16 7.979727989493313e-17]\n",
      "---------------\n",
      "[0.0 0.9999999999999999 1.6609977282477928e-16 0.0]\n",
      "---------------\n",
      "[1.6653345369377348e-16 1.0 0.0 1.1102230246251565e-16]\n",
      "---------------\n",
      "[1.249000902703301e-16 0.9999999999999999 0.0 5.551115123125783e-17]\n",
      "---------------\n",
      "[4.3686243591330353e-17 0.018177172913089592 0.9818228270869106 0.0]\n",
      "---------------\n",
      "[0.0 7.43762690325056e-16 0.9999999999999999 0.0]\n",
      "---------------\n",
      "[0.0 0.0 1.0 0.0]\n",
      "---------------\n",
      "[0.0 1.8214596497756474e-17 1.0 0.0]\n",
      "---------------\n",
      "[0.0 1.942890293094024e-16 1.0 0.0]\n",
      "---------------\n",
      "[2.498001805406602e-16 0.0 0.9999999999999998 0.0]\n",
      "---------------\n",
      "[2.21748321836805e-16 1.887379141862766e-15 0.9999999999999986 0.0]\n",
      "---------------\n",
      "[8.333754880180721e-16 0.0 1.0 0.0]\n",
      "---------------\n",
      "[1.6653345369377348e-16 6.38378239159465e-16 0.9999999999999993 0.0]\n",
      "---------------\n",
      "[0.0 0.0 1.0 3.6200730303110675e-17]\n",
      "---------------\n",
      "[0.0 0.0 4.163336342344337e-17 1.0]\n",
      "---------------\n",
      "[0.0 2.5672496906360667e-16 0.0 0.9999999999999998]\n",
      "---------------\n",
      "[0.0 7.528699885739343e-16 1.0 0.0]\n",
      "---------------\n",
      "[9.159339953157541e-16 0.0 1.0 0.0]\n",
      "---------------\n",
      "[1.1934897514720433e-15 0.0 1.0 0.0]\n",
      "---------------\n",
      "[0.0 0.0 1.0 0.0]\n",
      "---------------\n",
      "[8.604228440844963e-16 0.0 0.9999999999999998 0.0]\n",
      "---------------\n",
      "[5.828670879282072e-16 0.0 0.9999999999999994 1.1449174941446927e-16]\n",
      "---------------\n",
      "[2.1649348980190553e-15 0.0 1.0 0.0]\n",
      "---------------\n",
      "[0.0 0.0 1.0 0.0]\n",
      "---------------\n",
      "[8.326672684688674e-17 4.163336342344337e-16 0.9999999999999994\n",
      " 1.6653345369377348e-16]\n",
      "---------------\n",
      "[0.0 3.164135620181696e-15 0.9999999999999981 2.985459102156085e-15]\n",
      "---------------\n",
      "[0.0 5.759281940243e-16 0.9999999999999998 3.191891195797325e-16]\n",
      "---------------\n",
      "[0.0 4.440892098500626e-16 0.9999999999999997 4.440892098500626e-16]\n",
      "---------------\n",
      "[3.885780586188048e-16 0.0 1.0 0.0]\n",
      "---------------\n",
      "[0.0 9.575673587391975e-16 0.9999999999999994 2.2898349882893854e-16]\n",
      "---------------\n",
      "[0.0 6.626643678231403e-16 0.9999999999999993 2.0469737016526324e-16]\n",
      "---------------\n",
      "[0.0 3.677613769070831e-16 0.9999999999999996 1.7867651802561113e-16]\n",
      "---------------\n",
      "[8.43769498715119e-15 0.0 0.9999999999999978 0.0]\n",
      "---------------\n",
      "[5.551115123125783e-16 4.3021142204224816e-16 0.9999999999999982\n",
      " 7.389922007661198e-16]\n",
      "---------------\n",
      "[0.0 1.3183898417423734e-15 0.999999999999998 8.673617379884035e-16]\n",
      "---------------\n",
      "[4.551914400963142e-15 0.0 0.9999999999999986 0.0]\n",
      "---------------\n",
      "[7.494005416219807e-16 9.298117831235686e-16 0.9999999999999988 0.0]\n",
      "---------------\n",
      "[0.0 1.3791051634015616e-14 0.9999999999999887 3.925950276678636e-15]\n",
      "---------------\n",
      "[2.0539125955565396e-15 0.0 1.0 0.0]\n",
      "---------------\n",
      "[6.395729177631205e-17 0.9999999999999986 1.3877787807814457e-15 0.0]\n",
      "---------------\n",
      "[0.0 0.0 1.0 0.0]\n",
      "---------------\n",
      "[0.0 0.0 1.0 0.0]\n",
      "---------------\n",
      "[4.826064060199348e-16 0.0 1.0 0.0]\n",
      "---------------\n",
      "[0.0 0.0 1.0 0.0]\n",
      "---------------\n",
      "[0.0 1.4779844015322396e-15 1.0 4.616947665170033e-16]\n",
      "---------------\n",
      "[0.0 0.0 1.0 4.9551755979844935e-17]\n",
      "---------------\n",
      "[1.0979135380687004e-15 2.498001805406602e-16 0.9999999999999987\n",
      " 2.0515810927426937e-17]\n",
      "---------------\n",
      "[4.875514432771362e-17 0.0 1.0 0.0]\n",
      "---------------\n",
      "[8.796448240319123e-16 1.2420620087993939e-15 0.9999999999999973\n",
      " 4.3796191987298316e-16]\n",
      "---------------\n",
      "[2.1559757887496514e-16 2.220446049250313e-16 0.9999999999999996\n",
      " 4.6090941412256785e-17]\n",
      "---------------\n",
      "[0.0 2.498001805406602e-16 1.0 1.7532601949889796e-16]\n",
      "---------------\n",
      "[0.9176558342073348 1.0547986095676976e-14 0.0823441657926528\n",
      " 2.007075061705166e-15]\n",
      "---------------\n",
      "[1.0 0.0 0.0 1.4116312285761268e-15]\n",
      "---------------\n",
      "[0.0 3.8163916471489756e-16 0.9999999999999992 6.869504964868156e-16]\n",
      "---------------\n",
      "[0.0 1.4944642745540193e-15 0.9999999999999991 7.806255641895632e-17]\n",
      "---------------\n",
      "[1.0 0.0 5.204170427930421e-17 0.0]\n",
      "---------------\n",
      "[1.0 4.996003610813204e-16 0.0 1.6653345369377348e-16]\n",
      "---------------\n",
      "[0.9185151296155576 0.08148487038444191 1.1449174941446927e-16\n",
      " 3.139849491518021e-16]\n",
      "---------------\n",
      "[1.0 0.0 0.0 0.0]\n",
      "---------------\n",
      "[0.9855274949032855 0.014472505096714508 3.8250652645288596e-16 0.0]\n",
      "---------------\n",
      "[0.0 0.9999999999999998 4.440892098500626e-16 0.0]\n",
      "---------------\n",
      "[0.0 1.0 0.0 3.434752482434078e-16]\n",
      "---------------\n",
      "[0.13850752550730136 0.0 0.8614924744926995 0.0]\n",
      "---------------\n",
      "[3.308533977744547e-16 2.7755575615628914e-16 0.9999999999999998 0.0]\n",
      "---------------\n",
      "[0.0 0.0 1.0 0.0]\n",
      "---------------\n",
      "[1.3519176929461654e-16 2.220446049250313e-16 1.0 0.0]\n",
      "---------------\n",
      "[0.0 5.967448757360216e-16 0.9999999999999993 1.5822641571557194e-16]\n",
      "---------------\n",
      "[5.3078734334531803e-17 2.7755575615628914e-16 1.0 0.0]\n",
      "---------------\n",
      "[2.8449465006019636e-16 0.0 1.0 0.0]\n",
      "---------------\n",
      "[0.0 7.563394355258879e-16 1.0 4.909267437014364e-16]\n",
      "---------------\n",
      "[0.0 0.0 1.0 2.495833401061631e-16]\n",
      "---------------\n",
      "[0.1659249476277805 0.0 0.8340750523722203 0.0]\n",
      "---------------\n",
      "[0.12583212098844684 1.4476267407026455e-15 0.8741678790115507\n",
      " 1.0473392986209973e-15]\n",
      "---------------\n",
      "[0.14606966241298971 0.0 0.8539303375870119 0.0]\n",
      "---------------\n",
      "[0.24911611900332226 5.898059818321144e-17 0.750883880996678 0.0]\n",
      "---------------\n",
      "[1.0 0.0 2.220446049250313e-16 0.0]\n",
      "---------------\n",
      "[1.0 0.0 0.0 6.106226635438361e-16]\n",
      "---------------\n",
      "[0.9999999999999996 8.326672684688674e-17 4.718447854656915e-16 0.0]\n",
      "---------------\n",
      "[0.8194341755836562 0.0 0.18056582441634395 0.0]\n",
      "---------------\n",
      "[0.9999999999999994 0.0 8.690964614643804e-16 0.0]\n",
      "---------------\n",
      "[0.9999999999999999 3.9898639947466563e-16 0.0 0.0]\n",
      "---------------\n",
      "[1.2953842788873016e-17 1.0 0.0 0.0]\n",
      "---------------\n",
      "[5.766654383520971e-17 0.9999999999999997 1.457167719820518e-16\n",
      " 9.586515828275046e-17]\n",
      "---------------\n",
      "[0.0 1.0 0.0 8.212912202746421e-18]\n",
      "---------------\n",
      "[0.0 1.0 0.0 0.0]\n",
      "---------------\n",
      "[0.0 1.0 2.0816681711721685e-17 2.3696703058003095e-17]\n",
      "---------------\n",
      "[0.0 1.0 1.1516320541406648e-16 0.0]\n",
      "---------------\n",
      "[0.0 1.0 1.3594057484824739e-16 8.326672684688674e-17]\n",
      "---------------\n",
      "[5.551115123125783e-17 1.0 0.0 2.7755575615628914e-17]\n",
      "---------------\n",
      "[0.0 1.0 1.1275702593849246e-16 1.1821419446321614e-17]\n",
      "---------------\n",
      "[0.0 1.0 1.1102230246251565e-16 9.900965942309361e-18]\n",
      "---------------\n",
      "[4.678176894205071e-16 0.0 1.0 0.0]\n",
      "---------------\n",
      "[1.423787921389349e-16 1.2212453270876722e-15 0.9999999999999987\n",
      " 9.25185853854297e-18]\n",
      "---------------\n",
      "[0.0 1.0 0.0 2.629429336633382e-17]\n",
      "---------------\n",
      "[0.0 0.9999999999999999 2.220446049250313e-16 0.0]\n",
      "---------------\n",
      "[0.0 1.0547118733938987e-15 0.9999999999999996 2.2642145601498727e-16]\n",
      "---------------\n",
      "[0.0 1.970645868709653e-15 0.9999999999999982 7.533216058322254e-16]\n",
      "---------------\n",
      "[7.349622190427369e-16 2.220446049250313e-16 0.9999999999999997 0.0]\n",
      "---------------\n",
      "[2.7755575615628914e-16 0.5732378746681992 0.4267621253317999\n",
      " 4.787836793695988e-16]\n",
      "---------------\n",
      "[0.0 1.0 0.0 5.562875096913726e-16]\n",
      "---------------\n",
      "[0.9999999999999952 0.0 8.104628079763643e-15 0.0]\n",
      "---------------\n",
      "[1.0 0.0 0.0 0.0]\n",
      "---------------\n",
      "[1.8041124150158794e-16 1.6653345369377348e-16 0.4602428071053857\n",
      " 0.539757192894614]\n",
      "---------------\n",
      "[0.0 0.0 1.0 0.0]\n",
      "---------------\n",
      "[2.151057110211241e-16 0.0 1.0 6.38378239159465e-16]\n",
      "---------------\n",
      "[3.5648567431323386e-16 0.0 0.9999999999999999 1.2262326570811055e-16]\n",
      "---------------\n",
      "[0.0 0.0 1.0 0.0]\n",
      "---------------\n",
      "[0.0 0.0 1.0 0.0]\n",
      "---------------\n",
      "[0.0 7.577223315102658e-17 1.0 0.0]\n",
      "---------------\n",
      "[2.3245294578089215e-16 0.0 1.0 0.0]\n",
      "---------------\n",
      "[2.0816681711721685e-17 0.0 1.0 3.191891195797325e-16]\n",
      "---------------\n",
      "[0.9999999999999944 5.547645676173829e-15 0.0 5.7592819402429996e-15]\n",
      "---------------\n",
      "[1.0 5.967448757360216e-16 0.0 2.914335439641036e-16]\n",
      "---------------\n",
      "[1.0 1.3877787807814457e-17 0.0 4.163336342344337e-17]\n",
      "---------------\n",
      "[0.999999999999998 0.0 3.774758283725532e-15 0.0]\n",
      "---------------\n",
      "[0.9999999999999888 0.0 1.329492071988625e-14 0.0]\n",
      "---------------\n",
      "[0.7104196826007798 0.0 0.2895803173992295 0.0]\n",
      "---------------\n",
      "[0.6900045827751026 9.70621152895923e-15 0.30999541722488405\n",
      " 3.671759077339409e-15]\n",
      "---------------\n",
      "[0.0 0.0 1.0 3.95516952522712e-16]\n",
      "---------------\n",
      "[0.0 0.0 1.0 1.2871648191747909e-15]\n",
      "---------------\n",
      "[0.0 1.3877787807814457e-16 1.0 0.0]\n",
      "---------------\n",
      "[1.9596316132504617e-16 5.551115123125783e-17 0.9999999999999996\n",
      " 1.3598765805207163e-16]\n",
      "---------------\n",
      "[0.0 1.3877787807814457e-15 0.9999999999999991 0.0]\n",
      "---------------\n",
      "[0.0 0.0 1.0 8.380361229397649e-17]\n",
      "---------------\n",
      "[4.996003610813204e-16 0.0 0.9999999999999997 0.0]\n",
      "---------------\n",
      "[0.0 1.609302968663684e-14 1.0 4.9422271830579234e-15]\n",
      "---------------\n",
      "[0.0 6.248473960468459e-14 1.0 8.520961713998076e-15]\n",
      "---------------\n",
      "[0.0 5.065392549852277e-16 0.9999999999999991 1.6393136847980827e-15]\n",
      "---------------\n",
      "[9.409140133698202e-15 0.0 0.9999999999999976 0.0]\n",
      "---------------\n",
      "[0.0 9.367506770274758e-16 0.9999999999999992 5.412337245047638e-16]\n",
      "---------------\n",
      "[0.99999999999999 0.0 1.1898902002593914e-14 0.0]\n",
      "---------------\n",
      "[0.0 6.38378239159465e-16 1.0 1.186550857568136e-15]\n",
      "---------------\n",
      "[0.483855353422997 0.0 0.516144646577003 1.0408340855860843e-16]\n",
      "---------------\n",
      "[0.4399909893681438 1.1926223897340549e-15 0.5600090106318539\n",
      " 1.117595599398058e-15]\n",
      "---------------\n",
      "[0.9999999999999996 2.3592239273284576e-16 0.0 2.498001805406602e-16]\n",
      "---------------\n",
      "[0.9999999999999999 0.0 1.3877787807814457e-16 0.0]\n",
      "---------------\n",
      "[1.0 5.315192730392937e-15 0.0 5.551115123125783e-16]\n",
      "---------------\n",
      "[1.0 0.0 2.7755575615628914e-16 2.8449465006019636e-16]\n",
      "---------------\n",
      "[6.245004513516506e-17 0.0 0.9999999999999997 1.6306400674181987e-16]\n",
      "---------------\n",
      "[2.255140518769869e-17 1.0 0.0 5.907369558442012e-16]\n",
      "---------------\n",
      "[1.4812478424501086e-17 0.9999999999999999 8.326672684688674e-17 0.0]\n",
      "---------------\n",
      "[0.0 0.9999999999999998 0.0 4.277448555678104e-16]\n",
      "---------------\n",
      "[0.0 1.0 0.0 7.273103552487995e-17]\n",
      "---------------\n",
      "[0.0 1.0 2.7755575615628914e-17 9.086508776627266e-17]\n",
      "---------------\n",
      "[0.0 0.9999999999999998 5.656041442065313e-17 2.220446049250313e-16]\n",
      "---------------\n",
      "[6.983271481820427e-17 1.0 8.326672684688674e-17 0.0]\n",
      "---------------\n",
      "[2.7755575615628914e-17 1.0 1.1102230246251565e-16 0.0]\n",
      "---------------\n",
      "[0.0 0.9999999999999972 1.1102230246251565e-16 3.0083601164740274e-15]\n",
      "---------------\n",
      "[0.0 0.5345999051742781 1.1102230246251565e-16 0.46540009482572164]\n",
      "---------------\n",
      "[3.978266777358445e-17 1.0 0.0 0.0]\n",
      "---------------\n",
      "[0.0 0.9999999999999994 5.551115123125783e-16 1.6310033846627345e-16]\n",
      "---------------\n",
      "[1.8806299951660186e-17 1.0 0.0 1.3918413099801172e-16]\n",
      "---------------\n",
      "[0.0 1.0 0.0 5.4492126415414395e-16]\n",
      "---------------\n",
      "[1.8041124150158794e-16 1.0 0.0 1.7569279364693102e-14]\n",
      "---------------\n",
      "[0.0 0.0 0.9999999999999927 8.12128142513302e-14]\n",
      "---------------\n",
      "[3.0808688933348094e-15 8.835850874335708e-15 0.0 1.0]\n",
      "---------------\n",
      "[0.0 0.0 8.604228440844963e-15 0.9999999999999933]\n",
      "---------------\n",
      "[0.0 0.0 1.0 2.0816681711721685e-16]\n",
      "---------------\n",
      "[1.0 3.191891195797325e-16 0.0 0.0]\n",
      "---------------\n",
      "[0.9999999999999997 0.0 7.060324547225605e-16 2.437286483747414e-16]\n",
      "---------------\n",
      "[0.9999999999999997 0.0 7.216449660063518e-16 2.220446049250313e-16]\n",
      "---------------\n",
      "[0.9999999999999997 3.885780586188048e-16 1.1102230246251565e-16 0.0]\n",
      "---------------\n",
      "[1.0 7.216449660063518e-16 0.0 0.0]\n",
      "---------------\n",
      "[0.9999999999999994 0.0 0.0 1.033895191682177e-15]\n",
      "---------------\n",
      "[1.0 0.0 0.0 3.469446951953614e-17]\n",
      "---------------\n",
      "[0.9999999999999991 3.469446951953614e-17 1.1102230246251565e-15 0.0]\n",
      "---------------\n",
      "[0.9999999999999954 6.716849298982197e-15 0.0 0.0]\n",
      "---------------\n",
      "[0.9999999999999997 0.0 7.494005416219807e-16 2.8796409701215e-16]\n",
      "---------------\n",
      "[1.0 0.0 1.942890293094024e-16 1.5439038936193583e-16]\n",
      "---------------\n",
      "[0.9999999999999927 0.0 9.547918011776346e-15 0.0]\n",
      "---------------\n",
      "[1.0 0.0 0.0 0.0]\n",
      "---------------\n",
      "[0.0 2.6229018956769323e-15 1.0 2.4841240175987878e-15]\n",
      "---------------\n",
      "[0.0 7.91033905045424e-16 1.0 0.0]\n",
      "---------------\n",
      "[7.239409287888264e-16 0.0 0.9999999999999997 0.0]\n",
      "---------------\n",
      "[0.0 0.0 0.9999999999999993 7.0133409056859275e-16]\n",
      "---------------\n",
      "[0.0 4.579669976578771e-16 0.9999999999999997 0.0]\n",
      "---------------\n",
      "[0.0 0.0 1.0 0.0]\n",
      "---------------\n",
      "[7.886683130097952e-17 0.0 1.0 1.7290726328927004e-16]\n",
      "---------------\n",
      "[1.0282459547610431e-16 0.0 1.0 0.0]\n",
      "---------------\n",
      "[1.8359190506675498e-16 0.0 1.0 0.0]\n",
      "---------------\n",
      "[1.249000902703301e-16 0.0 1.0 9.265468083558662e-17]\n",
      "---------------\n",
      "[2.636779683484747e-16 5.551115123125783e-17 0.9999999999999996\n",
      " 8.908814689457538e-17]\n",
      "---------------\n",
      "[8.314459675869298e-18 1.6653345369377348e-16 1.0 0.0]\n",
      "---------------\n",
      "[0.0 0.0 1.0 0.0]\n",
      "---------------\n",
      "[7.955071529035495e-18 0.0 1.0 0.0]\n",
      "---------------\n",
      "[0.0 0.0 1.0 1.4700897367091155e-16]\n",
      "---------------\n",
      "[0.4126106932120605 0.0 0.5873893067879395 8.613986260397333e-16]\n",
      "---------------\n",
      "[0.0 0.0 1.0 7.37257477290143e-16]\n",
      "---------------\n",
      "[1.1501216645726231e-15 0.0 0.9999999999999997 0.0]\n",
      "---------------\n",
      "[1.0304257447302234e-15 4.627374872168133e-16 0.9999999999999988 0.0]\n",
      "---------------\n",
      "[0.0 0.0 0.9999999999999998 2.983724378680108e-16]\n",
      "---------------\n",
      "[0.0 0.0 0.9999999999999999 7.28583859910259e-16]\n",
      "---------------\n",
      "[0.15741621488905064 0.0 0.84258378511095 0.0]\n",
      "---------------\n",
      "[0.48791973660444254 1.1362438767648086e-16 0.5120802633955572\n",
      " 6.418476861114186e-17]\n",
      "---------------\n",
      "[0.5747530052740258 0.0 0.42524699472597416 2.7755575615628914e-17]\n",
      "---------------\n",
      "[0.4585818457258677 2.688821387764051e-17 0.5414181542741324 0.0]\n",
      "---------------\n",
      "[0.4365918876461303 0.0 0.5634081123538714 0.0]\n",
      "---------------\n",
      "[0.3851215518936479 2.1597307275911248e-16 0.614878448106352\n",
      " 2.6020852139652106e-18]\n",
      "---------------\n",
      "[0.38488447657508673 0.0 0.6151155234249134 1.2728533504979822e-16]\n",
      "---------------\n",
      "[0.3973794113405987 0.0 0.6026205886594034 0.0]\n",
      "---------------\n",
      "[0.46500454761548354 0.0 0.5349954523845188 0.0]\n",
      "---------------\n",
      "[0.45259593993047814 1.6609977282477928e-16 0.5474040600695219 0.0]\n",
      "---------------\n",
      "[0.581913457373867 7.029966886396011e-16 0.4180865426261314\n",
      " 9.407622250656722e-16]\n",
      "---------------\n",
      "[1.0 4.163336342344337e-17 8.326672684688674e-17 0.0]\n",
      "---------------\n",
      "[0.9999999999999999 0.0 1.734723475976807e-16 1.43982048506075e-16]\n",
      "---------------\n",
      "[1.0 1.0408340855860843e-17 0.0 0.0]\n",
      "---------------\n",
      "[1.0 0.0 0.0 9.71445146547012e-17]\n",
      "---------------\n",
      "[0.38185937947003085 2.949029909160572e-16 0.6181406205299691 0.0]\n",
      "---------------\n",
      "[0.6624719453935327 0.0 0.3375280546064673 5.334274688628682e-17]\n",
      "---------------\n",
      "[0.3317937625855024 0.0 0.6682062374144979 1.2576745200831851e-16]\n",
      "---------------\n",
      "[0.5189671599285489 0.0 0.4810328400714512 4.336808689942018e-19]\n",
      "---------------\n",
      "[0.5270939320542303 4.575333167888829e-16 0.4729060679457696 0.0]\n",
      "---------------\n",
      "[0.6302968891093319 1.0408340855860843e-16 0.3697031108906682 0.0]\n",
      "---------------\n",
      "[0.934935728609846 2.0426368929626904e-16 0.06506427139015403 0.0]\n",
      "---------------\n",
      "[0.7268033697246302 0.0 0.27319663027536967 4.172009959724221e-16]\n",
      "---------------\n",
      "[0.7439170771972928 2.5153490401663703e-17 0.2560829228027072\n",
      " 1.7780915628762273e-17]\n",
      "---------------\n",
      "[0.3931483415771191 8.673617379884035e-18 0.6068516584228799\n",
      " 9.209213253091875e-16]\n",
      "---------------\n",
      "          date   account_value\n",
      "0   2020-07-01         1000000\n",
      "1   2020-07-02  1002717.337037\n",
      "2   2020-07-06  1042091.814716\n",
      "3   2020-07-07   992014.183768\n",
      "4   2020-07-08   998669.002421\n",
      "..         ...             ...\n",
      "291 2021-08-26  1285781.489085\n",
      "292 2021-08-27  1295139.470885\n",
      "293 2021-08-30   1322295.09542\n",
      "294 2021-08-31  1315714.418036\n",
      "295 2021-09-01  1305284.227699\n",
      "\n",
      "[296 rows x 2 columns]\n",
      "--------\n",
      "\n",
      "                    AAPL            BA           CAT           CVX\n",
      "date                                                              \n",
      "2020-07-01  0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00\n",
      "2020-07-02  5.233631e-17  1.000000e+00  0.000000e+00  6.654705e-19\n",
      "2020-07-06  0.000000e+00  1.000000e+00  1.665335e-16  1.009936e-16\n",
      "2020-07-07  0.000000e+00  1.000000e+00  3.330669e-16  0.000000e+00\n",
      "2020-07-08  1.002014e-16  1.000000e+00  0.000000e+00  6.876750e-19\n",
      "...                  ...           ...           ...           ...\n",
      "2021-08-25  9.349357e-01  2.042637e-16  6.506427e-02  0.000000e+00\n",
      "2021-08-26  7.268034e-01  0.000000e+00  2.731966e-01  4.172010e-16\n",
      "2021-08-27  7.439171e-01  2.515349e-17  2.560829e-01  1.778092e-17\n",
      "2021-08-30  3.931483e-01  8.673617e-18  6.068517e-01  9.209213e-16\n",
      "2021-08-31  3.212793e-01  3.329585e-16  6.787207e-01  0.000000e+00\n",
      "\n",
      "[295 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#predict \n",
    "portfolio, meta_coefficient = svr.predict(trade, **test_params[\"SVR_PARAMS\"])\n",
    "print(portfolio)\n",
    "print(\"--------\\n\")\n",
    "print(meta_coefficient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>1002717.337037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>1042091.814716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>992014.183768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>998669.002421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>2021-08-26</td>\n",
       "      <td>1285781.489085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2021-08-27</td>\n",
       "      <td>1295139.470885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>2021-08-30</td>\n",
       "      <td>1322295.09542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>1315714.418036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>1305284.227699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date   account_value\n",
       "0   2020-07-01         1000000\n",
       "1   2020-07-02  1002717.337037\n",
       "2   2020-07-06  1042091.814716\n",
       "3   2020-07-07   992014.183768\n",
       "4   2020-07-08   998669.002421\n",
       "..         ...             ...\n",
       "291 2021-08-26  1285781.489085\n",
       "292 2021-08-27  1295139.470885\n",
       "293 2021-08-30   1322295.09542\n",
       "294 2021-08-31  1315714.418036\n",
       "295 2021-09-01  1305284.227699\n",
       "\n",
       "[296 rows x 2 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>BA</th>\n",
       "      <th>CAT</th>\n",
       "      <th>CVX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>5.233631e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.654705e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-06</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.665335e-16</td>\n",
       "      <td>1.009936e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-07</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.330669e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-08</th>\n",
       "      <td>1.002014e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.876750e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-25</th>\n",
       "      <td>9.349357e-01</td>\n",
       "      <td>2.042637e-16</td>\n",
       "      <td>6.506427e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-26</th>\n",
       "      <td>7.268034e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.731966e-01</td>\n",
       "      <td>4.172010e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27</th>\n",
       "      <td>7.439171e-01</td>\n",
       "      <td>2.515349e-17</td>\n",
       "      <td>2.560829e-01</td>\n",
       "      <td>1.778092e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-30</th>\n",
       "      <td>3.931483e-01</td>\n",
       "      <td>8.673617e-18</td>\n",
       "      <td>6.068517e-01</td>\n",
       "      <td>9.209213e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>3.212793e-01</td>\n",
       "      <td>3.329585e-16</td>\n",
       "      <td>6.787207e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    AAPL            BA           CAT           CVX\n",
       "date                                                              \n",
       "2020-07-01  0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00\n",
       "2020-07-02  5.233631e-17  1.000000e+00  0.000000e+00  6.654705e-19\n",
       "2020-07-06  0.000000e+00  1.000000e+00  1.665335e-16  1.009936e-16\n",
       "2020-07-07  0.000000e+00  1.000000e+00  3.330669e-16  0.000000e+00\n",
       "2020-07-08  1.002014e-16  1.000000e+00  0.000000e+00  6.876750e-19\n",
       "...                  ...           ...           ...           ...\n",
       "2021-08-25  9.349357e-01  2.042637e-16  6.506427e-02  0.000000e+00\n",
       "2021-08-26  7.268034e-01  0.000000e+00  2.731966e-01  4.172010e-16\n",
       "2021-08-27  7.439171e-01  2.515349e-17  2.560829e-01  1.778092e-17\n",
       "2021-08-30  3.931483e-01  8.673617e-18  6.068517e-01  9.209213e-16\n",
       "2021-08-31  3.212793e-01  3.329585e-16  6.787207e-01  0.000000e+00\n",
       "\n",
       "[295 rows x 4 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.1488641758680014e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 2.3645032162296554e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 6.245004513516506e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 8.326672684688674e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 1.0408340855860843e-16), ('BA', 1.0), ('CAT', 1.1870850139893797e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 3.651050815844936e-17), ('BA', 0.9999999999999997), ('CAT', 0.0), ('CVX', 2.6268863386608166e-16)])\n",
      "OrderedDict([('AAPL', 1.9081958235744878e-17), ('BA', 0.9999999999999998), ('CAT', 2.969519390948734e-17), ('CVX', 2.636779683484747e-16)])\n",
      "OrderedDict([('AAPL', 6.938893903907228e-17), ('BA', 0.9999999999999999), ('CAT', 1.7219868020753275e-16), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 1.9081957977250937e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 1.3877787807814457e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 1.3730498403511938e-17), ('CVX', 2.0816681711721685e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 8.326672684688674e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 4.5688858465762796e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 6.938893903907228e-18), ('BA', 0.9999999999999997), ('CAT', 8.063560701490277e-17), ('CVX', 3.885780586188048e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 2.8118077479118065e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 8.184754933245932e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 1.387778780781447e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 5.551115123125783e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.4423799760957423e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 1.0234868508263162e-16), ('BA', 0.9999999999999997), ('CAT', 0.0), ('CVX', 2.671474153004283e-16)])\n",
      "OrderedDict([('AAPL', 6.938893903907253e-18), ('BA', 1.0), ('CAT', 2.657420235588304e-18), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 2.4649353206724883e-17), ('CVX', 1.6653345369377348e-16)])\n",
      "OrderedDict([('AAPL', 1.0408340855860843e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 4.510281058219214e-17), ('BA', 1.0), ('CAT', 4.403759148844487e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 1.3877787807814457e-17), ('BA', 1.0), ('CAT', 4.2857414124145004e-17), ('CVX', 8.326672684688674e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 3.1167528782125175e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 3.4413956241758934e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 2.081668171172171e-17), ('BA', 0.9999999999999998), ('CAT', 5.813508902080232e-17), ('CVX', 1.942890293094024e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 0.0), ('CVX', 2.498001805406602e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 5.551115123125783e-17)])\n",
      "OrderedDict([('AAPL', 2.7755575615628914e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 1.1232516005410869e-17), ('CVX', 8.326672684688674e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 2.7755575615628914e-17)])\n",
      "OrderedDict([('AAPL', 5.551115123125783e-17), ('BA', 0.9999999999999999), ('CAT', 3.59120230259864e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 2.0816681711721685e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 3.469446951953614e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 3.507925521110234e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 1.232595164407831e-32), ('BA', 1.0), ('CAT', 9.367534030855337e-18), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 2.220446049250313e-16)])\n",
      "OrderedDict([('AAPL', 1.387778780781447e-17), ('BA', 1.0), ('CAT', 5.548017852236703e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.0238264349311046e-16), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 3.469446951953614e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 2.7755575615628914e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 5.551115123125783e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.9096619782960715e-17), ('CVX', 8.326672684688674e-17)])\n",
      "OrderedDict([('AAPL', 8.673618413859986e-19), ('BA', 1.0), ('CAT', 4.523391170163582e-18), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.5421826512377113e-17), ('CVX', 5.551115123125783e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 1.6411185066973194e-16), ('CVX', 5.551115123125783e-17)])\n",
      "OrderedDict([('AAPL', 6.331740656296074e-17), ('BA', 1.0), ('CAT', 5.217138890408027e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 6.071533206356939e-18), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 3.469446951953614e-17), ('BA', 0.9999999999999999), ('CAT', 4.9105757041354376e-17), ('CVX', 5.551115123125783e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 2.7755575615628914e-16)])\n",
      "OrderedDict([('AAPL', 6.591949208711867e-17), ('BA', 0.9999999999999998), ('CAT', 0.0), ('CVX', 1.734723475976807e-16)])\n",
      "OrderedDict([('AAPL', 2.7755575615628914e-17), ('BA', 0.9999999999999999), ('CAT', 9.224975806650622e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 1.3877787807814457e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 1.4271173212306312e-17), ('CVX', 9.71445146547012e-17)])\n",
      "OrderedDict([('AAPL', 3.4694469674632507e-17), ('BA', 0.9999999999999997), ('CAT', 2.445464451723656e-17), ('CVX', 3.608224830031759e-16)])\n",
      "OrderedDict([('AAPL', 3.642919299551295e-17), ('BA', 1.0), ('CAT', 1.0585764810418784e-16), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 2.77555756156289e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 2.4286128663675296e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 2.7755575615628914e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 2.9080536302498414e-17), ('CVX', 1.1102230246251565e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 4.4238830576669537e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 0.0), ('CVX', 1.4051260155412137e-16)])\n",
      "OrderedDict([('AAPL', 7.37257477290143e-18), ('BA', 0.9999999999999997), ('CAT', 0.0), ('CVX', 2.7798943702528334e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 1.3877787807814457e-16)])\n",
      "OrderedDict([('AAPL', 1.3877787807814457e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 2.7755575615628914e-17)])\n",
      "OrderedDict([('AAPL', 5.551115123125783e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 1.1102230246251565e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 3.1727148175099516e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 6.938893903907228e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.7085036602863526e-17), ('CVX', 2.7755575615628914e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 3.2723642619180196e-17), ('CVX', 5.551115123125783e-17)])\n",
      "OrderedDict([('AAPL', 1.214306433183765e-17), ('BA', 0.9999999999999998), ('CAT', 8.150812214342714e-17), ('CVX', 3.3306690738754696e-16)])\n",
      "OrderedDict([('AAPL', 4.163336342344337e-17), ('BA', 0.9999999999999998), ('CAT', 3.699306940430759e-17), ('CVX', 5.551115123125783e-17)])\n",
      "OrderedDict([('AAPL', 6.245004513516504e-17), ('BA', 0.9999999999999997), ('CAT', 0.0), ('CVX', 3.191891195797325e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 2.7755575615628914e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 1.3877787807814457e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.9599305117949567e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999998), ('CAT', 1.3389047949399925e-17), ('CVX', 3.0531133177191805e-16)])\n",
      "OrderedDict([('AAPL', 2.0816681711721685e-17), ('BA', 0.9999999999999999), ('CAT', 4.830418054485316e-17), ('CVX', 2.7755575615628914e-17)])\n",
      "OrderedDict([('AAPL', 5.551115123125783e-17), ('BA', 0.9999999999999999), ('CAT', 4.4303087793325095e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 5.204170427930421e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 3.469446951953614e-17), ('BA', 0.9999999999999999), ('CAT', 4.9813522019877223e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 1.942890293094024e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 1.6653345369377348e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 4.1633362699660334e-17), ('BA', 1.0), ('CAT', 2.6950958525909564e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 8.636453149568025e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.9027229377709858e-17), ('CVX', 1.1102230246251565e-16)])\n",
      "OrderedDict([('AAPL', 4.597017211338539e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 1.387778780781447e-17), ('BA', 1.0), ('CAT', 3.853653370629568e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999998), ('CAT', 3.5572967655772776e-17), ('CVX', 1.5092094240998222e-16)])\n",
      "OrderedDict([('AAPL', 4.163336342344337e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 5.551115123125783e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.9447997550375367e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 1.6479873021779667e-17), ('BA', 1.0), ('CAT', 1.1281593857231391e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 3.7296554733501365e-17), ('BA', 1.0), ('CAT', 6.4028282883096016e-18), ('CVX', 1.3877787807814457e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 6.938893903907228e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 9.438205107808874e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999994), ('CAT', 0.0), ('CVX', 9.532305500492555e-16)])\n",
      "OrderedDict([('AAPL', 2.7755575615628914e-17), ('BA', 1.0), ('CAT', 1.287565246150567e-16), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 9.020562075079397e-17), ('BA', 0.9999999999999999), ('CAT', 1.460513675866537e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 1.9081957641208813e-17), ('BA', 0.9999999999999999), ('CAT', 2.3513244231523267e-17), ('CVX', 1.3183898417423734e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 3.1385407103465216e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 7.632783252938922e-17), ('BA', 0.9999999999999999), ('CAT', 0.0), ('CVX', 8.326672684688674e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 1.942890293094024e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 2.5019751947098416e-17), ('CVX', 1.3877787807814457e-16)])\n",
      "OrderedDict([('AAPL', 8.500144968955339e-17), ('BA', 0.9999999999999998), ('CAT', 8.150265251855094e-18), ('CVX', 1.734723475976807e-16)])\n",
      "OrderedDict([('AAPL', 1.5612511283791264e-17), ('BA', 1.0), ('CAT', 5.654323139527733e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 3.724155542855699e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 1.632679658504415e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 8.998878031629699e-18), ('BA', 0.9999999999999999), ('CAT', 7.83901766985398e-18), ('CVX', 5.898059818321144e-17)])\n",
      "OrderedDict([('AAPL', 4.683753385137379e-17), ('BA', 1.0), ('CAT', 3.6648155338922065e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 1.032160465104273e-16), ('BA', 0.9999999999999998), ('CAT', 4.648490291058475e-17), ('CVX', 6.245004513516506e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.9753929492680207e-18), ('CVX', 3.469446951953614e-17)])\n",
      "OrderedDict([('AAPL', 1.3877787807814457e-17), ('BA', 1.0), ('CAT', 8.499299330083883e-18), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 3.509217691199057e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 2.7755575615628914e-17), ('BA', 1.0), ('CAT', 4.333014068141462e-17), ('CVX', 8.326672684688674e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 0.0), ('CVX', 8.326672684688674e-17)])\n",
      "OrderedDict([('AAPL', 2.992397996059992e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 1.214306433183765e-17)])\n",
      "OrderedDict([('AAPL', 1.5265566588595902e-16), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 9.71445146547012e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 8.326672684688674e-17)])\n",
      "OrderedDict([('AAPL', 8.673617379884048e-18), ('BA', 1.0), ('CAT', 0.0), ('CVX', 5.898059818321144e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 3.5542037359115917e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 0.0), ('CVX', 5.095750210681871e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 9.108523233645864e-17), ('CVX', 1.1102230246251565e-16)])\n",
      "OrderedDict([('AAPL', 8.326672684688674e-17), ('BA', 1.0), ('CAT', 8.42376248392051e-18), ('CVX', 5.551115123125783e-17)])\n",
      "OrderedDict([('AAPL', 2.0816681711721697e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 4.163336342344337e-17), ('BA', 0.9999999999999999), ('CAT', 0.0), ('CVX', 1.3877787807814457e-16)])\n",
      "OrderedDict([('AAPL', 4.85722573273506e-17), ('BA', 1.0), ('CAT', 2.004348499950642e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 1.2836953722228372e-16), ('BA', 0.9999999999999999), ('CAT', 6.198876856000938e-18), ('CVX', 1.3877787807814457e-17)])\n",
      "OrderedDict([('AAPL', 5.204170427930421e-17), ('BA', 1.0), ('CAT', 9.254281333622118e-18), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 6.245004513516506e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 3.0775629146283514e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 2.7755575615628914e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999998), ('CAT', 6.124821714441869e-17), ('CVX', 1.3877787807814457e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999997), ('CAT', 0.0), ('CVX', 5.863365348801608e-16)])\n",
      "OrderedDict([('AAPL', 3.7296554559017954e-17), ('BA', 0.9999999999999994), ('CAT', 0.0), ('CVX', 6.435824095873954e-16)])\n",
      "OrderedDict([('AAPL', 5.2909066017292616e-17), ('BA', 1.0), ('CAT', 1.7210947207837083e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 2.47198095326695e-17), ('BA', 1.0), ('CAT', 2.1826797449390156e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 3.5561831257524545e-17), ('BA', 0.9999999999999999), ('CAT', 4.742744048654636e-17), ('CVX', 2.7755575615628914e-17)])\n",
      "OrderedDict([('AAPL', 5.637851255565595e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 6.938893903907228e-17), ('BA', 1.0), ('CAT', 1.9475458898401268e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 8.326672684688674e-17), ('BA', 0.9999999999999998), ('CAT', 5.176051003770804e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 9.71445146547012e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 5.551115123125783e-17)])\n",
      "OrderedDict([('AAPL', 5.551115123125783e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 4.989301251607633e-17), ('CVX', 1.1102230246251565e-16)])\n",
      "OrderedDict([('AAPL', 1.084202168026484e-16), ('BA', 0.9999999999999994), ('CAT', 0.0), ('CVX', 5.48172618408671e-16)])\n",
      "OrderedDict([('AAPL', 4.35849273339173e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999996), ('CAT', 2.4416441057627958e-17), ('CVX', 3.0184188481996443e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999997), ('CAT', 1.2964264421554697e-16), ('CVX', 2.0816681711721685e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999998), ('CAT', 3.154671321740691e-17), ('CVX', 2.0816681711721685e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999996), ('CAT', 1.6185143540629003e-17), ('CVX', 4.579669976578771e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999998), ('CAT', 6.263898928838505e-18), ('CVX', 2.636779683484747e-16)])\n",
      "OrderedDict([('AAPL', 1.387778780781447e-17), ('BA', 0.9999999999999999), ('CAT', 1.0546535441959098e-16), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.761943932030622e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999997), ('CAT', 4.6426412009646455e-17), ('CVX', 3.191891195797325e-16)])\n",
      "OrderedDict([('AAPL', 3.469446951953614e-18), ('BA', 0.9999999999999999), ('CAT', 8.471825700950773e-18), ('CVX', 1.5265566588595902e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999997), ('CAT', 0.0), ('CVX', 5.551115123125783e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.1713382345122827e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.302468308424844e-18), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 3.122502243833556e-17), ('BA', 0.9999999999999998), ('CAT', 2.0655950433379598e-19), ('CVX', 2.7755575615628914e-16)])\n",
      "OrderedDict([('AAPL', 5.204170427930421e-17), ('BA', 0.9999999999999994), ('CAT', 1.2220917629551597e-17), ('CVX', 5.620504062164855e-16)])\n",
      "OrderedDict([('AAPL', 1.6306400674181987e-16), ('BA', 0.9999999999999999), ('CAT', 7.30163673043666e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 0.0), ('CVX', 2.42861286636753e-16)])\n",
      "OrderedDict([('AAPL', 1.3877787807814457e-17), ('BA', 1.0), ('CAT', 6.234915847019054e-18), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 6.938893903907228e-18), ('BA', 1.0), ('CAT', 3.1393493729536076e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 5.551115123125783e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 1.3877787807814457e-16)])\n",
      "OrderedDict([('AAPL', 3.469446951953614e-17), ('BA', 1.0), ('CAT', 1.4243716119487747e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 8.326672684688674e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 1.734723475976807e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 9.71445146547012e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 2.7755575615628914e-16)])\n",
      "OrderedDict([('AAPL', 1.5612511283791264e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 2.0816681711721685e-17), ('BA', 0.9999999999999998), ('CAT', 2.0895622917397673e-16), ('CVX', 1.249000902703301e-16)])\n",
      "OrderedDict([('AAPL', 2.0816681711721685e-17), ('BA', 1.0), ('CAT', 7.341471007713017e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.1076397303697419e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 1.3877787807814457e-16)])\n",
      "OrderedDict([('AAPL', 1.214306424394971e-16), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 6.938893903907228e-18), ('BA', 0.9999999999999998), ('CAT', 2.596573948935405e-16), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 6.938893903907228e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 3.494203810306751e-17), ('CVX', 1.6653345369377348e-16)])\n",
      "OrderedDict([('AAPL', 2.7755575615628914e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 3.469446951953614e-17), ('BA', 1.0), ('CAT', 5.7687395168355e-18), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 2.0816681711721685e-17), ('BA', 0.9999999999999999), ('CAT', 1.0864707013444042e-16), ('CVX', 6.938893903907228e-17)])\n",
      "OrderedDict([('AAPL', 4.85722573273506e-17), ('BA', 0.9999999999999999), ('CAT', 0.0), ('CVX', 5.898059818321144e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 7.343397048050244e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 4.163336342344337e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 1.1102230246251565e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999998), ('CAT', 6.07435175677228e-17), ('CVX', 1.942890293094024e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 9.577959011466553e-17), ('CVX', 5.551115123125783e-17)])\n",
      "OrderedDict([('AAPL', 5.290906591389504e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 5.204170427930421e-18)])\n",
      "OrderedDict([('AAPL', 3.664603343001005e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999998), ('CAT', 4.197832928457085e-17), ('CVX', 3.122502256758253e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 3.1225022567582546e-17), ('BA', 0.9999999999999998), ('CAT', 0.0), ('CVX', 3.5388358909926865e-16)])\n",
      "OrderedDict([('AAPL', 4.857225732735059e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 6.938893903907228e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.778281204462806e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 5.4385653432303337e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 9.714451465470118e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 2.205320789894072e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 0.0), ('CVX', 3.0531133177191805e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999998), ('CAT', 1.2448886902472947e-16), ('CVX', 5.551115123125783e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 8.704999828245222e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999998), ('CAT', 4.137394305190464e-17), ('CVX', 2.7755575615628914e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 6.938893903907228e-17)])\n",
      "OrderedDict([('AAPL', 6.938893903907228e-18), ('BA', 1.0), ('CAT', 1.8598312942264493e-17), ('CVX', 8.326672684688674e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 6.652330741552105e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 0.0), ('CVX', 2.3592239273284576e-16)])\n",
      "OrderedDict([('AAPL', 1.387778780781447e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 1.249000902703301e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 0.0), ('CVX', 1.5265566588595902e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 6.460951035255421e-17), ('CVX', 1.3877787807814457e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 5.757910562465945e-17), ('CVX', 9.71445146547012e-17)])\n",
      "OrderedDict([('AAPL', 2.081668171172168e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 6.11217114374039e-17), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 2.6888213774242933e-17), ('BA', 0.9999999999999999), ('CAT', 1.84826700409136e-17), ('CVX', 1.214306433183765e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 1.734723475976807e-18), ('BA', 0.9999999999999997), ('CAT', 7.004936094203263e-17), ('CVX', 3.5388358909926865e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 1.6653345369377348e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999998), ('CAT', 1.0011364103912423e-16), ('CVX', 8.326672684688674e-17)])\n",
      "OrderedDict([('AAPL', 2.7755575615628914e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 5.2041704279304274e-18), ('BA', 1.0), ('CAT', 3.9547446356647906e-17), ('CVX', 1.1102230246251565e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 0.0), ('CVX', 2.498001805406602e-16)])\n",
      "OrderedDict([('AAPL', 5.551115123125783e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 3.92166015249771e-18), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 2.7755575615628914e-17)])\n",
      "OrderedDict([('AAPL', 4.163336342344337e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999998), ('CAT', 1.434376573209089e-16), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.0232431952737418e-16), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 6.938893903907228e-18), ('BA', 0.9999999999999998), ('CAT', 9.48167537528814e-17), ('CVX', 1.249000902703301e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999999), ('CAT', 3.5361539838839923e-17), ('CVX', 1.1102230246251565e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999997), ('CAT', 2.1292088043433287e-16), ('CVX', 1.8041124150158794e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999996), ('CAT', 3.22888567471528e-17), ('CVX', 4.3021142204224816e-16)])\n",
      "OrderedDict([('AAPL', 6.245004513516506e-17), ('BA', 0.9999999999999994), ('CAT', 1.4783039151618919e-16), ('CVX', 2.7755575615628914e-16)])\n",
      "OrderedDict([('AAPL', 3.469446951953614e-18), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 1.3877787807814457e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 2.7755575615628914e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.962280005050844e-16), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 4.4885969940899884e-17), ('BA', 0.9999999999999999), ('CAT', 1.1847468297795423e-16), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999996), ('CAT', 2.996881266201443e-16), ('CVX', 1.3877787807814457e-16)])\n",
      "OrderedDict([('AAPL', 7.632783294297951e-17), ('BA', 0.9999999999999999), ('CAT', 4.289800514266122e-18), ('CVX', 1.5265566588595902e-16)])\n",
      "OrderedDict([('AAPL', 2.42861286636753e-17), ('BA', 0.9999999999999996), ('CAT', 9.602138707615564e-17), ('CVX', 2.3592239273284576e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.9158895502026588e-16), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 5.2041704279304706e-18), ('BA', 1.0), ('CAT', 3.811978882491975e-17), ('CVX', 5.551115123125783e-17)])\n",
      "OrderedDict([('AAPL', 2.7755575615628914e-17), ('BA', 1.0), ('CAT', 2.0663951381290316e-16), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 9.714451465470118e-17), ('BA', 0.9999999999999998), ('CAT', 0.0), ('CVX', 1.1102230246251565e-16)])\n",
      "OrderedDict([('AAPL', 6.938893903907228e-18), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 3.262855792235944e-16), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 2.465190328815662e-32), ('BA', 0.9999999999999997), ('CAT', 0.0), ('CVX', 2.7755575615628914e-16)])\n",
      "OrderedDict([('AAPL', 3.8163916471489756e-17), ('BA', 0.9999999999999997), ('CAT', 2.823291781749236e-17), ('CVX', 3.8163916471489756e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999998), ('CAT', 3.847552293707296e-16), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 3.469446951953614e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 9.367506770274758e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 2.4286128663675296e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 1.4571677213714816e-16), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999997), ('CAT', 0.0), ('CVX', 4.0939474033052647e-16)])\n",
      "OrderedDict([('AAPL', 1.387778770441688e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 2.0816680600197737e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999996), ('CAT', 4.3565532894197587e-16), ('CVX', 1.6653345369377348e-16)])\n",
      "OrderedDict([('AAPL', 1.0408340855860843e-17), ('BA', 1.0), ('CAT', 1.3825859485118211e-16), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 1.9081958235744878e-17), ('BA', 0.9999999999999998), ('CAT', 1.622237185325134e-17), ('CVX', 1.249000902703301e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999991), ('CAT', 5.648011314971466e-16), ('CVX', 3.8163916471489756e-16)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 0.9999999999999996), ('CAT', 1.4909506956646916e-16), ('CVX', 3.469446951953614e-16)])\n",
      "OrderedDict([('AAPL', 1.3877787807814457e-16), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 4.969651182900353e-18), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 2.220446049250313e-16)])\n",
      "OrderedDict([('AAPL', 2.2551405187698492e-17), ('BA', 0.9999999999999997), ('CAT', 0.0), ('CVX', 5.689893001203927e-16)])\n",
      "OrderedDict([('AAPL', 1.3877787807814506e-17), ('BA', 1.0), ('CAT', 4.070504439306948e-18), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 2.328477680075618e-16), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 1.191186015127598e-16), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 7.493937535778693e-18), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 4.163336342344337e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 5.551115123125783e-17), ('BA', 1.0), ('CAT', 0.0), ('CVX', 0.0)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 6.004560716445448e-17), ('CVX', 5.551115123125783e-17)])\n",
      "OrderedDict([('AAPL', 0.0), ('BA', 1.0), ('CAT', 0.0), ('CVX', 2.220446049250313e-16)])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer/model_structure.ipynb Cell 31'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer/model_structure.ipynb#ch0000043?line=0'>1</a>\u001b[0m portfolio, portfolio_cumprod, meta_coefficient \u001b[39m=\u001b[39m lr\u001b[39m.\u001b[39mpredict(trade, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtest_params[\u001b[39m\"\u001b[39m\u001b[39mLR_PARAMS\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "portfolio, meta_coefficient = lr.predict(trade, **test_params[\"LR_PARAMS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ee38ef4a5a9feb55287fd749643f13d043cb0a7addaab2a9c224cbe137c0062"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
