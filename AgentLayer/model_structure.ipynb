{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer', '/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python38.zip', '/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8', '/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/lib-dynload', '', '/Users/doganparlak/Library/Python/3.8/lib/python/site-packages', '/usr/local/lib/python3.8/site-packages', '/usr/local/lib/python3.8/site-packages/selenium-3.141.0-py3.8.egg', '/usr/local/lib/python3.8/site-packages/urllib3-1.26.4-py3.8.egg', '/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi', '/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi', '/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi', '/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi', '/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi']\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import A2C as sb_A2C\n",
    "from stable_baselines3 import PPO as sb_PPO\n",
    "from stable_baselines3 import DDPG as sb_DDPG\n",
    "from stable_baselines3 import TD3 as sb_TD3\n",
    "from stable_baselines3.common.noise import ActionNoise\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "from stable_baselines3.common.type_aliases import Schedule\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "import yaml\n",
    "import gym\n",
    "from datetime import datetime\n",
    "from sys import path\n",
    "from os.path import dirname as dir\n",
    "from typing import Any, Dict, Optional, Tuple, Type, Union\n",
    "path.append(dir(path[0]))\n",
    "print(path)\n",
    "#__package__ = \"examples\"\n",
    "\n",
    "from FinancialDataLayer.DataCollection.DataDownloader import DataDownloader\n",
    "from FinancialDataLayer.DataProcessing.DefaultFeatureEngineer import DefaultFeatureEngineer\n",
    "from AgentLayer.DataSplitter.TimeSeriesSplitter import TimeSeriesSplitter\n",
    "from AgentLayer.DataSplitter.BlockingTimeSeriesSplitter import BlockingTimeSeriesSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pypfopt\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "from pypfopt import objective_functions\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(gym.Env, ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def step(self, action):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def render(self, mode=\"human\"):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_env(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax_normalization(actions):\n",
    "        numerator = np.exp(actions)\n",
    "        denominator = np.sum(np.exp(actions))\n",
    "        softmax_output = numerator / denominator\n",
    "        return softmax_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def train_model():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_model():\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def load_model():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConventionalAgent(Agent, ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def train_model():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_model():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_model():\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _return_predict():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _weight_optimization():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLAgent(Agent, ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def train_model():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict():\n",
    "        \n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_model():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_model():\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_weights(rl_actions_list):\n",
    "        agent_weight_df = {'date': [], 'weights': []}\n",
    "        for i in range(len(rl_actions_list)):\n",
    "            date = rl_actions_list.index[i]\n",
    "            tic_list = list(rl_actions_list.columns)\n",
    "            weights_list = rl_actions_list.reset_index()[list(rl_actions_list.columns)].iloc[i].values\n",
    "            weight_dict = {'tic': [], 'weight': []}\n",
    "            for j in range(len(tic_list)):\n",
    "                weight_dict['tic'] += [tic_list[j]]\n",
    "                weight_dict['weight'] += [weights_list[j]]\n",
    "\n",
    "            agent_weight_df['date'] += [date]\n",
    "            agent_weight_df['weights'] += [pd.DataFrame(weight_dict)]\n",
    "\n",
    "        agent_weights = pd.DataFrame(agent_weight_df)\n",
    "        return agent_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFAgent(ConventionalAgent):\n",
    "\n",
    "    def __init__(self,\n",
    "                n_estimators = 100,\n",
    "                criterion = \"squared_error\",\n",
    "                max_depth = None,\n",
    "                min_samples_split = 2,\n",
    "                min_samples_leaf = 1,\n",
    "                min_weight_fraction_leaf = 0,\n",
    "                max_features = 1,\n",
    "                max_leaf_nodes = None,\n",
    "                min_impurity_decrease = 0,\n",
    "                bootstrap = True,\n",
    "                oob_score = False,\n",
    "                n_jobs = None,\n",
    "                random_state = None,\n",
    "                verbose = 0,\n",
    "                warm_start = False,\n",
    "                ccp_alpha = 0,\n",
    "                max_samples = None):\n",
    "\n",
    "        self.model = RandomForestRegressor(n_estimators= n_estimators,\n",
    "                            criterion= criterion,\n",
    "                            max_depth=max_depth,\n",
    "                            min_samples_split=min_samples_split,\n",
    "                            min_samples_leaf=min_samples_leaf,\n",
    "                            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                            max_features=max_features,\n",
    "                            max_leaf_nodes= max_leaf_nodes,\n",
    "                            min_impurity_decrease=min_impurity_decrease,\n",
    "                            bootstrap=bootstrap,\n",
    "                            oob_score=oob_score,\n",
    "                            n_jobs=n_jobs,\n",
    "                            random_state= random_state,\n",
    "                            verbose=verbose,\n",
    "                            warm_start=warm_start,\n",
    "                            ccp_alpha=ccp_alpha,\n",
    "                            max_samples=max_samples)\n",
    "    \n",
    "    def train_model(self, train_x, train_y, **train_params):\n",
    "        '''\n",
    "        *Trains the model*\n",
    "        Input: Train data x and train data y\n",
    "        Output: Linear Regression Model\n",
    "        '''\n",
    "        try:\n",
    "            trained = self.model.fit(train_x, train_y.ravel(), **train_params)\n",
    "            print(\"Model trained succesfully\")\n",
    "            return trained\n",
    "        except Exception as e:\n",
    "            print(\"training unsuccessful\")    \n",
    "    \n",
    "    def predict(self,\n",
    "                test_data, \n",
    "                initial_capital = 0,\n",
    "                tech_indicator_list = [\n",
    "                        \"macd\",\n",
    "                        \"boll_ub\",\n",
    "                        \"boll_lb\",\n",
    "                        \"rsi_30\",\n",
    "                        \"cci_30\",\n",
    "                        \"dx_30\",\n",
    "                        \"close_30_sma\",\n",
    "                        \"close_60_sma\",\n",
    "                    ]):\n",
    "\n",
    "            meta_coefficient = {\"date\": [], \"weights\": []}\n",
    "            unique_trade_date = test_data.date.unique()\n",
    "            portfolio = pd.DataFrame(index=range(1), columns=unique_trade_date)\n",
    "            portfolio.loc[0, unique_trade_date[0]] = initial_capital\n",
    "\n",
    "            for i in range(len(unique_trade_date) - 1):\n",
    "                mu, sigma, tics, df_current, df_next = self._return_predict(\n",
    "                    unique_trade_date, test_data, i, tech_indicator_list)\n",
    "\n",
    "                portfolio_value = self._weight_optimization(\n",
    "                    i, unique_trade_date, meta_coefficient, mu, sigma, tics, portfolio, df_current, df_next)\n",
    "        \n",
    "            portfolio = portfolio_value\n",
    "            portfolio = portfolio.T\n",
    "            portfolio.columns = ['account_value']\n",
    "            portfolio = portfolio.reset_index()\n",
    "            portfolio.columns = ['date', 'account_value']\n",
    "            \n",
    "            return portfolio, meta_coefficient\n",
    "    \n",
    "    def _return_predict(self, unique_trade_date, test_data, i, tech_indicator_list):\n",
    "\n",
    "        current_date = unique_trade_date[i]\n",
    "        next_date = unique_trade_date[i+1]\n",
    "\n",
    "        df_current = test_data[test_data.date ==\n",
    "                                  current_date].reset_index(drop=True)\n",
    "        df_next = test_data[test_data.date ==\n",
    "                               next_date].reset_index(drop=True)\n",
    "\n",
    "        tics = df_current['tic'].values\n",
    "        features = df_current[tech_indicator_list].values\n",
    "\n",
    "        predicted_y = self.model.predict(features)\n",
    "        mu = predicted_y\n",
    "        sigma = risk_models.sample_cov(\n",
    "            df_current.return_list[0], returns_data=True)\n",
    "\n",
    "        return mu, sigma, tics, df_current, df_next\n",
    "    \n",
    "    def _weight_optimization(self, i, unique_trade_date, meta_coefficient, mu, sigma, tics, portfolio, df_current, df_next):\n",
    "\n",
    "        current_date = unique_trade_date[i]\n",
    "        predicted_y_df = pd.DataFrame(\n",
    "            {\"tic\": tics.reshape(-1,), \"predicted_y\": mu.reshape(-1,)})\n",
    "        min_weight, max_weight = 0, 1\n",
    "\n",
    "        ef = EfficientFrontier(mu, sigma)\n",
    "        weights = ef.nonconvex_objective(\n",
    "            objective_functions.sharpe_ratio,\n",
    "            objective_args=(ef.expected_returns, ef.cov_matrix),\n",
    "            weights_sum_to_one=True,\n",
    "            constraints=[\n",
    "                # greater than min_weight\n",
    "                {\"type\": \"ineq\", \"fun\": lambda w: w - min_weight},\n",
    "                # less than max_weight\n",
    "                {\"type\": \"ineq\", \"fun\": lambda w: max_weight - w},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        weight_df = {\"tic\": [], \"weight\": []}\n",
    "        meta_coefficient[\"date\"] += [current_date]\n",
    "\n",
    "        for item in weights:\n",
    "            weight_df['tic'] += [item]\n",
    "            weight_df['weight'] += [weights[item]]\n",
    "\n",
    "        weight_df = pd.DataFrame(weight_df).merge(predicted_y_df, on=['tic'])\n",
    "        meta_coefficient[\"weights\"] += [weight_df]\n",
    "        cap = portfolio.iloc[0, i]\n",
    "        # current cash invested for each stock\n",
    "        current_cash = [element * cap for element in list(weights.values())]\n",
    "        # current held shares\n",
    "        current_shares = list(np.array(current_cash) / np.array(df_current.close))\n",
    "        # next time period price\n",
    "        next_price = np.array(df_next.close)\n",
    "        portfolio.iloc[0, i+1] = np.dot(current_shares, next_price)\n",
    "\n",
    "        return portfolio \n",
    "\n",
    "    def save_model(self,  file_name):\n",
    "        with open(file_name, 'wb') as files:\n",
    "            pickle.dump(self.model, files)\n",
    "        print(\"Model saved succesfully.\")\n",
    "\n",
    "\n",
    "    def load_model(self, file_name):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "        print(\"Model loaded succesfully.\")\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTAgent(ConventionalAgent):\n",
    "    \n",
    "    def __init__(self,\n",
    "                criterion = \"squared_error\",\n",
    "                splitter = \"best\",\n",
    "                max_depth = None,\n",
    "                min_samples_split = 2,\n",
    "                min_samples_leaf = 1,\n",
    "                min_weight_fraction_leaf = 0,\n",
    "                max_features = None,\n",
    "                random_state = None,\n",
    "                max_leaf_nodes = None,\n",
    "                min_impurity_decrease = 0,\n",
    "                ccp_alpha = 0):\n",
    "                \n",
    "\n",
    "        self.model = DecisionTreeRegressor( criterion = criterion,\n",
    "                                            splitter = splitter,\n",
    "                                            max_depth = max_depth,\n",
    "                                            min_samples_split = min_samples_split,\n",
    "                                            min_samples_leaf = min_samples_leaf,\n",
    "                                            min_weight_fraction_leaf = min_weight_fraction_leaf,\n",
    "                                            max_features = max_features,\n",
    "                                            random_state = random_state,\n",
    "                                            max_leaf_nodes = max_leaf_nodes,\n",
    "                                            min_impurity_decrease = min_impurity_decrease,\n",
    "                                            ccp_alpha = ccp_alpha)\n",
    "                                            \n",
    "    def train_model(self, train_x, train_y, **train_params):\n",
    "        '''\n",
    "        *Trains the model*\n",
    "        Input: Train data x and train data y\n",
    "        Output: Linear Regression Model\n",
    "        '''\n",
    "        try:\n",
    "            trained = self.model.fit(train_x, train_y, **train_params)\n",
    "            print(\"Model trained succesfully\")\n",
    "            return trained\n",
    "        except Exception as e:\n",
    "            print(\"training unsuccessful\")    \n",
    "    \n",
    "    def predict(self,\n",
    "                test_data, \n",
    "                initial_capital = 0,\n",
    "                tech_indicator_list = [\n",
    "                        \"macd\",\n",
    "                        \"boll_ub\",\n",
    "                        \"boll_lb\",\n",
    "                        \"rsi_30\",\n",
    "                        \"cci_30\",\n",
    "                        \"dx_30\",\n",
    "                        \"close_30_sma\",\n",
    "                        \"close_60_sma\",\n",
    "                    ]):\n",
    "\n",
    "            meta_coefficient = {\"date\": [], \"weights\": []}\n",
    "            unique_trade_date = test_data.date.unique()\n",
    "            portfolio = pd.DataFrame(index=range(1), columns=unique_trade_date)\n",
    "            portfolio.loc[0, unique_trade_date[0]] = initial_capital\n",
    "\n",
    "            for i in range(len(unique_trade_date) - 1):\n",
    "                mu, sigma, tics, df_current, df_next = self._return_predict(\n",
    "                    unique_trade_date, test_data, i, tech_indicator_list)\n",
    "\n",
    "                portfolio_value = self._weight_optimization(\n",
    "                    i, unique_trade_date, meta_coefficient, mu, sigma, tics, portfolio, df_current, df_next)\n",
    "        \n",
    "            portfolio = portfolio_value\n",
    "            portfolio = portfolio.T\n",
    "            portfolio.columns = ['account_value']\n",
    "            portfolio = portfolio.reset_index()\n",
    "            portfolio.columns = ['date', 'account_value']\n",
    "\n",
    "            return portfolio, meta_coefficient\n",
    "            \n",
    "    def _return_predict(self, unique_trade_date, test_data, i, tech_indicator_list):\n",
    "\n",
    "        current_date = unique_trade_date[i]\n",
    "        next_date = unique_trade_date[i+1]\n",
    "\n",
    "        df_current = test_data[test_data.date ==\n",
    "                                  current_date].reset_index(drop=True)\n",
    "        df_next = test_data[test_data.date ==\n",
    "                               next_date].reset_index(drop=True)\n",
    "\n",
    "        tics = df_current['tic'].values\n",
    "        features = df_current[tech_indicator_list].values\n",
    "\n",
    "        predicted_y = self.model.predict(features)\n",
    "        mu = predicted_y\n",
    "        sigma = risk_models.sample_cov(\n",
    "            df_current.return_list[0], returns_data=True)\n",
    "\n",
    "        return mu, sigma, tics, df_current, df_next\n",
    "\n",
    "    def _weight_optimization(self, i, unique_trade_date, meta_coefficient, mu, sigma, tics, portfolio, df_current, df_next):\n",
    "\n",
    "        current_date = unique_trade_date[i]\n",
    "        predicted_y_df = pd.DataFrame(\n",
    "            {\"tic\": tics.reshape(-1,), \"predicted_y\": mu.reshape(-1,)})\n",
    "        min_weight, max_weight = 0, 1\n",
    "\n",
    "        ef = EfficientFrontier(mu, sigma)\n",
    "        weights = ef.nonconvex_objective(\n",
    "            objective_functions.sharpe_ratio,\n",
    "            objective_args=(ef.expected_returns, ef.cov_matrix),\n",
    "            weights_sum_to_one=True,\n",
    "            constraints=[\n",
    "                # greater than min_weight\n",
    "                {\"type\": \"ineq\", \"fun\": lambda w: w - min_weight},\n",
    "                # less than max_weight\n",
    "                {\"type\": \"ineq\", \"fun\": lambda w: max_weight - w},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        weight_df = {\"tic\": [], \"weight\": []}\n",
    "        meta_coefficient[\"date\"] += [current_date]\n",
    "\n",
    "        for item in weights:\n",
    "            weight_df['tic'] += [item]\n",
    "            weight_df['weight'] += [weights[item]]\n",
    "\n",
    "        weight_df = pd.DataFrame(weight_df).merge(predicted_y_df, on=['tic'])\n",
    "        meta_coefficient[\"weights\"] += [weight_df]\n",
    "        cap = portfolio.iloc[0, i]\n",
    "        # current cash invested for each stock\n",
    "        current_cash = [element * cap for element in list(weights.values())]\n",
    "        # current held shares\n",
    "        current_shares = list(np.array(current_cash) / np.array(df_current.close))\n",
    "        # next time period price\n",
    "        next_price = np.array(df_next.close)\n",
    "        portfolio.iloc[0, i+1] = np.dot(current_shares, next_price)\n",
    "\n",
    "        return portfolio \n",
    "    \n",
    "    def save_model(self,  file_name):\n",
    "        with open(file_name, 'wb') as files:\n",
    "            pickle.dump(self.model, files)\n",
    "        print(\"Model saved succesfully.\")\n",
    "\n",
    "\n",
    "    def load_model(self, file_name):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "        print(\"Model loaded succesfully.\")\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVRAgent(ConventionalAgent):\n",
    "    \n",
    "    def __init__(self,\n",
    "                kernel = 'rbf',\n",
    "                degree = 3,\n",
    "                gamma = 'scale',\n",
    "                coef0 = 0,\n",
    "                tol = 0.001,\n",
    "                C = 1,\n",
    "                epsilon = 0.1,\n",
    "                shrinking = True,\n",
    "                cache_size = 200,\n",
    "                verbose = False,\n",
    "                max_iter = -1):  \n",
    "\n",
    "        self.model = SVR(kernel= kernel,\n",
    "                        degree= degree,\n",
    "                        gamma= gamma, \n",
    "                        coef0= coef0,\n",
    "                        tol= tol,\n",
    "                        C= C,\n",
    "                        epsilon= epsilon,\n",
    "                        shrinking= shrinking,\n",
    "                        cache_size= cache_size,\n",
    "                        verbose= verbose,\n",
    "                        max_iter= max_iter)\n",
    "            \n",
    "    def get_params(self, deep = True):\n",
    "        return self.model.get_params(deep = deep)\n",
    "\n",
    "    def train_model(self, train_x, train_y, **train_params):\n",
    "        '''\n",
    "        *Trains the model*\n",
    "        Input: Train data x and train data y\n",
    "        Output: Linear Regression Model\n",
    "        '''\n",
    "        try:\n",
    "            trained = self.model.fit(train_x, train_y.ravel(), **train_params)\n",
    "            print(\"Model trained succesfully\")\n",
    "            return trained\n",
    "        except Exception as e:\n",
    "            print(\"training unsuccessful\")\n",
    "\n",
    "    def predict(self,\n",
    "               test_data, \n",
    "               initial_capital = 1000000,\n",
    "               tech_indicator_list = [\n",
    "                    \"macd\",\n",
    "                    \"boll_ub\",\n",
    "                    \"boll_lb\",\n",
    "                    \"rsi_30\",\n",
    "                    \"cci_30\",\n",
    "                    \"dx_30\",\n",
    "                    \"close_30_sma\",\n",
    "                    \"close_60_sma\",\n",
    "                ]):\n",
    "\n",
    "        meta_coefficient = {\"date\": []}\n",
    "        for i in test_data.tic:\n",
    "            meta_coefficient[i] = []\n",
    "        unique_trade_date = test_data.date.unique()\n",
    "        portfolio = pd.DataFrame(index=range(1), columns=unique_trade_date)\n",
    "        portfolio.loc[0, unique_trade_date[0]] = initial_capital\n",
    "        for i in range(len(unique_trade_date) - 1):\n",
    "            mu, sigma, tics, df_current, df_next = self._return_predict(\n",
    "                unique_trade_date, test_data, i, tech_indicator_list)\n",
    "\n",
    "            portfolio_value = self._weight_optimization(\n",
    "                i, unique_trade_date, meta_coefficient, mu, sigma, tics, portfolio, df_current, df_next)\n",
    "    \n",
    "        portfolio = portfolio_value\n",
    "        portfolio = portfolio.T\n",
    "        portfolio.columns = ['account_value']\n",
    "        portfolio = portfolio.reset_index()\n",
    "        portfolio.columns = ['date', 'account_value']\n",
    "\n",
    "        '''Backtest hasn't been implemented yet, hence commented.'''\n",
    "        #stats = backtest_stats(portfolio, value_col_name='account_value')\n",
    "        \n",
    "        portfolio_cumprod = (\n",
    "            portfolio.account_value.pct_change()+1).cumprod()-1\n",
    "\n",
    "        meta_coefficient = pd.DataFrame(meta_coefficient).set_index(\"date\")\n",
    "        return portfolio, portfolio_cumprod, pd.DataFrame(meta_coefficient)\n",
    "    \n",
    "    def _return_predict(self, unique_trade_date, test_data, i, tech_indicator_list):\n",
    "\n",
    "        current_date = unique_trade_date[i]\n",
    "        next_date = unique_trade_date[i+1]\n",
    "\n",
    "        df_current = test_data[test_data.date ==\n",
    "                                  current_date].reset_index(drop=True)\n",
    "        df_next = test_data[test_data.date ==\n",
    "                               next_date].reset_index(drop=True)\n",
    "\n",
    "        tics = df_current['tic'].values\n",
    "        features = df_current[tech_indicator_list].values\n",
    "\n",
    "        predicted_y = self.model.predict(features)\n",
    "        mu = predicted_y\n",
    "        sigma = risk_models.sample_cov(\n",
    "            df_current.return_list[0], returns_data=True)\n",
    "\n",
    "        return mu, sigma, tics, df_current, df_next\n",
    "    \n",
    "    def _weight_optimization(self, i, unique_trade_date, meta_coefficient, mu, sigma, tics, portfolio, df_current, df_next):\n",
    "        current_date = unique_trade_date[i]\n",
    "        predicted_y_df = pd.DataFrame(\n",
    "            {\"tic\": tics.reshape(-1,), \"predicted_y\": mu.reshape(-1,)})\n",
    "        min_weight, max_weight = 0, 1\n",
    "\n",
    "        ef = EfficientFrontier(mu, sigma)\n",
    "        weights = ef.nonconvex_objective(\n",
    "            objective_functions.sharpe_ratio,\n",
    "            objective_args=(ef.expected_returns, ef.cov_matrix),\n",
    "            weights_sum_to_one=True,\n",
    "            constraints=[\n",
    "                # greater than min_weight\n",
    "                {\"type\": \"ineq\", \"fun\": lambda w: w - min_weight},\n",
    "                # less than max_weight\n",
    "                {\"type\": \"ineq\", \"fun\": lambda w: max_weight - w},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        weight_df = {\"tic\": [], \"weight\": []}\n",
    "        meta_coefficient[\"date\"] += [current_date]\n",
    "\n",
    "        for item in weights:\n",
    "            weight_df['tic'] += [item]\n",
    "            weight_df['weight'] += [weights[item]]\n",
    "\n",
    "        weight_df = pd.DataFrame(weight_df).merge(predicted_y_df, on=['tic'])\n",
    "\n",
    "        tics_list = list(weight_df['tic'])\n",
    "        weights_list = list(weight_df['weight'])\n",
    "        for j in range(len(tics_list)):\n",
    "            meta_coefficient[tics_list[j]] += [weights_list[j]]\n",
    "\n",
    "        cap = portfolio.iloc[0, i]\n",
    "        # current cash invested for each stock\n",
    "        current_cash = [element * cap for element in list(weights.values())]\n",
    "        # current held shares\n",
    "        current_shares = list(np.array(current_cash) / np.array(df_current.close))\n",
    "        # next time period price\n",
    "        next_price = np.array(df_next.close)\n",
    "        portfolio.iloc[0, i+1] = np.dot(current_shares, next_price)\n",
    "\n",
    "        return portfolio \n",
    "\n",
    "    \n",
    "    def save_model(self,  file_name):\n",
    "        with open(file_name, 'wb') as files:\n",
    "            pickle.dump(self.model, files)\n",
    "        print(\"Model saved succesfully.\")\n",
    "\n",
    "\n",
    "    def load_model(self, file_name):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "        print(\"Model loaded succesfully.\")\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRAgent(ConventionalAgent):\n",
    "\n",
    "    def __init__(self,\n",
    "                 fit_intercept=True,\n",
    "                 copy_X=True,\n",
    "                 positive=False):\n",
    "        \"\"\"\n",
    "\n",
    "        @param fit_intercept:\n",
    "        @param copy_X:\n",
    "        @param positive:\n",
    "        \"\"\"\n",
    "        print(fit_intercept)\n",
    "        self.model = LinearRegression(fit_intercept=fit_intercept,\n",
    "                                      copy_X=copy_X,\n",
    "                                      positive=positive)\n",
    "\n",
    "    def train_model(self, train_x, train_y, **train_params):\n",
    "        \"\"\"\n",
    "\n",
    "        @param train_x:\n",
    "        @param train_y:\n",
    "        @param train_params:\n",
    "        @return:\n",
    "        \"\"\"\n",
    "        try:\n",
    "            trained_reg = self.model.fit(train_x, train_y, **train_params)\n",
    "            self.model = trained_reg\n",
    "            print(\"Model trained succesfully\")\n",
    "        except Exception as e:\n",
    "            print(\"training unsuccessful\")\n",
    "\n",
    "    def predict(self,\n",
    "                test_data,\n",
    "                initial_capital=1000000,\n",
    "                tech_indicator_list=[\n",
    "                    \"macd\",\n",
    "                    \"boll_ub\",\n",
    "                    \"boll_lb\",\n",
    "                    \"rsi_30\",\n",
    "                    \"cci_30\",\n",
    "                    \"dx_30\",\n",
    "                    \"close_30_sma\",\n",
    "                    \"close_60_sma\",\n",
    "                ]\n",
    "                ):\n",
    "        \"\"\"\n",
    "\n",
    "        @param test_data:\n",
    "        @param initial_capital:\n",
    "        @param tech_indicator_list:\n",
    "        @return:\n",
    "        \"\"\"\n",
    "\n",
    "        meta_coefficient = {\"date\": []}\n",
    "        for i in test_data.tic:\n",
    "            meta_coefficient[i] = []\n",
    "        unique_trade_date = test_data.date.unique()\n",
    "        portfolio = pd.DataFrame(index=range(1), columns=unique_trade_date)\n",
    "        portfolio.loc[0, unique_trade_date[0]] = initial_capital\n",
    "        for i in range(len(unique_trade_date) - 1):\n",
    "            mu, sigma, tics, df_current, df_next = self._return_predict(\n",
    "                unique_trade_date, test_data, i, tech_indicator_list)\n",
    "\n",
    "            portfolio_value = self._weight_optimization(\n",
    "                i, unique_trade_date, meta_coefficient, mu, sigma, tics, portfolio, df_current, df_next)\n",
    "    \n",
    "        portfolio = portfolio_value\n",
    "        portfolio = portfolio.T\n",
    "        portfolio.columns = ['account_value']\n",
    "        portfolio = portfolio.reset_index()\n",
    "        portfolio.columns = ['date', 'account_value']\n",
    "        \n",
    "        meta_coefficient = pd.DataFrame(meta_coefficient).set_index(\"date\")\n",
    "        return portfolio, meta_coefficient\n",
    "\n",
    "    def _return_predict(self, unique_trade_date, test_data, i, tech_indicator_list):\n",
    "        \"\"\"\n",
    "\n",
    "        @param unique_trade_date:\n",
    "        @param test_data:\n",
    "        @param i:\n",
    "        @param tech_indicator_list:\n",
    "        @return:\n",
    "        \"\"\"\n",
    "        current_date = unique_trade_date[i]\n",
    "        next_date = unique_trade_date[i + 1]\n",
    "\n",
    "        df_current = test_data[test_data.date ==\n",
    "                               current_date].reset_index(drop=True)\n",
    "        df_next = test_data[test_data.date ==\n",
    "                            next_date].reset_index(drop=True)\n",
    "\n",
    "        tics = df_current['tic'].values\n",
    "        features = df_current[tech_indicator_list].values\n",
    "\n",
    "        predicted_y = self.model.predict(features)\n",
    "        mu = predicted_y\n",
    "        sigma = risk_models.sample_cov(\n",
    "            df_current.return_list[0], returns_data=True)\n",
    "\n",
    "        return mu, sigma, tics, df_current, df_next\n",
    "\n",
    "    def _weight_optimization(self, i, unique_trade_date, meta_coefficient, mu, sigma, tics, portfolio, df_current,\n",
    "                             df_next):\n",
    "        \"\"\"\n",
    "\n",
    "        @param i:\n",
    "        @param unique_trade_date:\n",
    "        @param meta_coefficient:\n",
    "        @param mu:\n",
    "        @param sigma:\n",
    "        @param tics:\n",
    "        @param portfolio:\n",
    "        @param df_current:\n",
    "        @param df_next:\n",
    "        @return:\n",
    "        \"\"\"\n",
    "        current_date = unique_trade_date[i]\n",
    "        predicted_y_df = pd.DataFrame(\n",
    "            {\"tic\": tics.reshape(-1,), \"predicted_y\": mu.reshape(-1,)})\n",
    "        min_weight, max_weight = 0, 1\n",
    "\n",
    "        ef = EfficientFrontier(mu, sigma)\n",
    "        weights = ef.nonconvex_objective(\n",
    "            objective_functions.sharpe_ratio,\n",
    "            objective_args=(ef.expected_returns, ef.cov_matrix),\n",
    "            weights_sum_to_one=True,\n",
    "            constraints=[\n",
    "                # greater than min_weight\n",
    "                {\"type\": \"ineq\", \"fun\": lambda w: w - min_weight},\n",
    "                # less than max_weight\n",
    "                {\"type\": \"ineq\", \"fun\": lambda w: max_weight - w},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        weight_df = {\"tic\": [], \"weight\": []}\n",
    "        meta_coefficient[\"date\"] += [current_date]\n",
    "\n",
    "        for item in weights:\n",
    "            weight_df['tic'] += [item]\n",
    "            weight_df['weight'] += [weights[item]]\n",
    "\n",
    "        weight_df = pd.DataFrame(weight_df).merge(predicted_y_df, on=['tic'])\n",
    "\n",
    "        tics_list = list(weight_df['tic'])\n",
    "        weights_list = list(weight_df['weight'])\n",
    "        for j in range(len(tics_list)):\n",
    "            meta_coefficient[tics_list[j]] += [weights_list[j]]\n",
    "\n",
    "        cap = portfolio.iloc[0, i]\n",
    "        # current cash invested for each stock\n",
    "        current_cash = [element * cap for element in list(weights.values())]\n",
    "        # current held shares\n",
    "        current_shares = list(np.array(current_cash) / np.array(df_current.close))\n",
    "        # next time period price\n",
    "        next_price = np.array(df_next.close)\n",
    "        portfolio.iloc[0, i+1] = np.dot(current_shares, next_price)\n",
    "\n",
    "        return portfolio \n",
    "\n",
    "    def save_model(self, file_name):\n",
    "        \"\"\"\n",
    "\n",
    "        @param file_name:\n",
    "        @return:\n",
    "        \"\"\"\n",
    "        with open(file_name, 'wb') as files:\n",
    "            pickle.dump(self.model, files)\n",
    "        print(\"Model saved succesfully.\")\n",
    "\n",
    "    def load_model(self, file_name):\n",
    "        \"\"\"\n",
    "\n",
    "        @param file_name:\n",
    "        @return:\n",
    "        \"\"\"\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "        print(\"Model loaded succesfully.\")\n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioEnv(Environment):\n",
    "\n",
    "    def __init__(self,\n",
    "                 df: pd.DataFrame,  # input data\n",
    "                 stock_dim: int,  # number of unique securities in the investment universe\n",
    "                 hmax: float,  # maximum number of shares to trade\n",
    "                 initial_amount: float,  # initial cash value\n",
    "                 transaction_cost_pct: float,  # transaction cost percentage per trade\n",
    "                 reward_scaling: float,  # scaling factor for reward as training progresses\n",
    "                 state_space: int,  # the dimension of input features (state space)\n",
    "                 action_space: int,  # number of actions, which is equal to portfolio dimension\n",
    "                 tech_indicator_list: list,  # a list of technical indicator names\n",
    "                 lookback=252,  #\n",
    "                 day=0):  # an increment number to control date\n",
    "\n",
    "        self.df = df\n",
    "        self.day = day\n",
    "        self.lookback = lookback\n",
    "        self.stock_dim = stock_dim\n",
    "        self.hmax = hmax\n",
    "        self.initial_amount = initial_amount\n",
    "        self.transaction_cost_pct = transaction_cost_pct\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "\n",
    "        # action_space normalization and shape is self.stock_dim\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(self.action_space,))\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf,\n",
    "                                            shape=(self.state_space + len(self.tech_indicator_list), self.state_space))\n",
    "        \n",
    "\n",
    "        # load data from a pandas dataframe\n",
    "        \n",
    "        \n",
    "        self.data = self.df.loc[self.day,:]\n",
    "        self.covs = self.data['cov_list'].values[0]\n",
    "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
    "        self.terminal = False\n",
    "        #self.turbulence_threshold = turbulence_threshold\n",
    "        # initalize state: initial portfolio return + individual stock return + individual weights\n",
    "        self.portfolio_value = self.initial_amount\n",
    "\n",
    "        # memorize portfolio value each step\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        # memorize portfolio return each step\n",
    "        self.portfolio_return_memory = [0]\n",
    "        self.actions_memory = [[1 / self.stock_dim] * self.stock_dim]\n",
    "        self.date_memory=[self.data.date.unique()[0]]\n",
    "\n",
    "    def reset(self):\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        self.day = 0\n",
    "        self.data = self.df.loc[self.day,:]\n",
    "        # load states\n",
    "        self.covs = self.data['cov_list'].values[0]\n",
    "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
    "                \n",
    "        self.portfolio_value = self.initial_amount\n",
    "        self.terminal = False \n",
    "        self.portfolio_return_memory = [0]\n",
    "        self.actions_memory=[[1/self.stock_dim] * self.stock_dim]\n",
    "        self.date_memory=[self.data.date.unique()[0]] \n",
    "        return self.state\n",
    "\n",
    "    def step(self, actions):\n",
    "        self.terminal = self.day >= len(self.df.index.unique()) - 1\n",
    "        if self.terminal:\n",
    "            df = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df.columns = ['daily_return']\n",
    "            print(\"=================================\")\n",
    "            print(\"begin_total_asset:{}\".format(self.asset_memory[0]))\n",
    "            print(\"end_total_asset:{}\".format(self.portfolio_value))\n",
    "\n",
    "            df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df_daily_return.columns = ['daily_return']\n",
    "            if df_daily_return['daily_return'].std() != 0:\n",
    "                sharpe = (252 ** 0.5) * df_daily_return['daily_return'].mean() / \\\n",
    "                         df_daily_return['daily_return'].std()\n",
    "                print(\"Sharpe: \", sharpe)\n",
    "            print(\"=================================\")\n",
    "\n",
    "            return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "        else:\n",
    "            weights = Environment.softmax_normalization(actions)\n",
    "            self.actions_memory.append(weights)\n",
    "            transaction_fee = self.transaction_cost_pct * self.asset_memory[-1] * sum([abs(a_i - b_i) for a_i, b_i in zip(self.actions_memory[-1], self.actions_memory[-2])]) #transaction_fee\n",
    "            last_day_memory = self.data\n",
    "            # load next state\n",
    "            self.day += 1\n",
    "            self.data = self.df.loc[self.day, :]\n",
    "            self.covs = self.data['cov_list'].values[0]\n",
    "            self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)         \n",
    "            portfolio_return = sum(((self.data.close.values / last_day_memory.close.values) - 1) * weights)\n",
    "            # update portfolio value\n",
    "            new_portfolio_value = self.portfolio_value * (1 + portfolio_return) - transaction_fee #transaction_fee\n",
    "            self.portfolio_value = new_portfolio_value\n",
    "\n",
    "            # save into memory\n",
    "            self.portfolio_return_memory.append(portfolio_return)\n",
    "            self.date_memory.append(self.data[\"date\"].unique()[0])\n",
    "            self.asset_memory.append(new_portfolio_value)\n",
    "\n",
    "            # the reward is the new portfolio value or end portfolo value\n",
    "            self.reward = new_portfolio_value\n",
    "\n",
    "        return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        return self.state\n",
    "\n",
    "    def save_asset_memory(self):\n",
    "        date_list = self.date_memory\n",
    "        portfolio_return = self.portfolio_return_memory\n",
    "        df_account_value = pd.DataFrame({'date': date_list, 'daily_return': portfolio_return})\n",
    "        return df_account_value\n",
    "\n",
    "    def save_action_memory(self):\n",
    "        # date and close price length must match actions length\n",
    "        date_list = self.date_memory\n",
    "        df_date = pd.DataFrame(date_list)\n",
    "        df_date.columns = ['date']\n",
    "\n",
    "        action_list = self.actions_memory\n",
    "        df_actions = pd.DataFrame(action_list)\n",
    "        df_actions.columns = self.data.tic.values\n",
    "        df_actions.index = df_date.date\n",
    "        # df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
    "        return df_actions\n",
    "\n",
    "    def get_env(self):\n",
    "        e = DummyVecEnv([lambda: self])\n",
    "        obs = e.reset()\n",
    "        return e, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A2C(RLAgent):\n",
    "\n",
    "    def __init__(self,\n",
    "                 policy: \"MlpPolicy\",\n",
    "                 env: None,\n",
    "                 learning_rate: float = 7e-4,\n",
    "                 n_steps: int = 5,\n",
    "                 gamma: float = 0.99,\n",
    "                 gae_lambda: float = 1.0,\n",
    "                 ent_coef: float = 0.0,\n",
    "                 vf_coef: float = 0.5,\n",
    "                 max_grad_norm: float = 0.5,\n",
    "                 rms_prop_eps: float = 1e-5,\n",
    "                 use_rms_prop: bool = True,\n",
    "                 use_sde: bool = False,\n",
    "                 sde_sample_freq: int = -1,\n",
    "                 normalize_advantage: bool = False,\n",
    "                 tensorboard_log: Optional[str] = None,\n",
    "                 create_eval_env: bool = False,\n",
    "                 policy_kwargs: Optional[Dict[str, Any]] = None,\n",
    "                 verbose: int = 0,\n",
    "                 seed: Optional[int] = None,\n",
    "                 device: Union[th.device, str] = \"auto\",\n",
    "                 _init_setup_model: bool = True):\n",
    "\n",
    "        self.env = env\n",
    "\n",
    "        self.model = sb_A2C(policy = policy,\n",
    "                            env=self.env,\n",
    "                            learning_rate = learning_rate,\n",
    "                            n_steps = n_steps,\n",
    "                            gamma = gamma,\n",
    "                            gae_lambda= gae_lambda,\n",
    "                            ent_coef = ent_coef,\n",
    "                            vf_coef = vf_coef,\n",
    "                            max_grad_norm = max_grad_norm,\n",
    "                            rms_prop_eps= rms_prop_eps,\n",
    "                            use_rms_prop= use_rms_prop,\n",
    "                            use_sde= use_sde,\n",
    "                            sde_sample_freq= sde_sample_freq,\n",
    "                            normalize_advantage= normalize_advantage,\n",
    "                            tensorboard_log=tensorboard_log,  \n",
    "                            create_eval_env= create_eval_env,\n",
    "                            policy_kwargs=policy_kwargs,\n",
    "                            verbose=verbose,\n",
    "                            seed=seed,\n",
    "                            device= device,\n",
    "                            _init_setup_model = _init_setup_model)\n",
    "\n",
    "    def train_model(self, **train_params):\n",
    "        self.model = self.model.learn(**train_params)\n",
    "        return self.model\n",
    "\n",
    "    def predict(self, environment, **test_params):\n",
    "\n",
    "        env_test, obs_test = environment.get_env()\n",
    "        \"\"\"make a prediction\"\"\"\n",
    "        account_memory = []\n",
    "        actions_memory = []\n",
    "\n",
    "        env_test.reset()\n",
    "        for i in range(len(environment.df.index.unique())):\n",
    "            action, _states = self.model.predict(obs_test, **test_params)\n",
    "            obs_test, rewards, dones, info = env_test.step(action)\n",
    "            if i == (len(environment.df.index.unique()) - 2):\n",
    "                account_memory = env_test.env_method(method_name=\"save_asset_memory\")\n",
    "                actions_memory = env_test.env_method(method_name=\"save_action_memory\")\n",
    "            if dones[0]:\n",
    "                print(\"hit end!\")\n",
    "                break\n",
    "        \n",
    "        portfolio_df = account_memory[0]\n",
    "        portfolio_df = portfolio_df.rename(columns={\"daily_return\": \"account_value\"})\n",
    "        portfolio_df.iloc[0, portfolio_df.columns.get_loc(\"account_value\")] = environment.initial_amount\n",
    "        values = list(portfolio_df[\"account_value\"])\n",
    "        for i in range(1,len(values)):\n",
    "            values[i] = (values[i] + 1) * values[i-1]\n",
    "\n",
    "        portfolio_df[\"account_value\"] = values\n",
    "        return portfolio_df, actions_memory[0]\n",
    "\n",
    "    def save_model(self, path):\n",
    "        self.model.save(path)\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model = self.model.load(path)\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO(RLAgent):\n",
    "    def __init__(self,\n",
    "                policy: \"MlpPolicy\",\n",
    "                env: None,\n",
    "                learning_rate:  3e-4,\n",
    "                n_steps: int = 2048,\n",
    "                batch_size: int = 64,\n",
    "                n_epochs: int = 10,\n",
    "                gamma: float = 0.99,\n",
    "                gae_lambda: float = 0.95,\n",
    "                clip_range: Union[float, Schedule] = 0.2,\n",
    "                clip_range_vf: Union[None, float, Schedule] = None,\n",
    "                normalize_advantage: bool = True,\n",
    "                ent_coef: float = 0.0,\n",
    "                vf_coef: float = 0.5,\n",
    "                max_grad_norm: float = 0.5,\n",
    "                use_sde: bool = False,\n",
    "                sde_sample_freq: int = -1,\n",
    "                target_kl: Optional[float] = None,\n",
    "                tensorboard_log: Optional[str] = None,\n",
    "                create_eval_env: bool = False,\n",
    "                policy_kwargs: Optional[Dict[str, Any]] = None,\n",
    "                verbose: int = 0,\n",
    "                seed: Optional[int] = None,\n",
    "                device: Union[th.device, str] = \"auto\",\n",
    "                _init_setup_model: bool = True):\n",
    "\n",
    "        self.env = env\n",
    "        self.model = sb_PPO(policy = policy,\n",
    "                            env=self.env,\n",
    "                            learning_rate = learning_rate,\n",
    "                            n_steps = n_steps,\n",
    "                            gamma = gamma,\n",
    "                            batch_size = batch_size,\n",
    "                            n_epochs = n_epochs,\n",
    "                            gae_lambda=gae_lambda,\n",
    "                            clip_range = clip_range,\n",
    "                            clip_range_vf = clip_range_vf,\n",
    "                            normalize_advantage=normalize_advantage,\n",
    "                            ent_coef=ent_coef,\n",
    "                            vf_coef=vf_coef,\n",
    "                            max_grad_norm=max_grad_norm,\n",
    "                            use_sde=use_sde,\n",
    "                            sde_sample_freq=sde_sample_freq,\n",
    "                            target_kl=target_kl,\n",
    "                            tensorboard_log=tensorboard_log,\n",
    "                            create_eval_env=create_eval_env,\n",
    "                            policy_kwargs=policy_kwargs,\n",
    "                            verbose=verbose,\n",
    "                            seed=seed,\n",
    "                            device=device,\n",
    "                            _init_setup_model = _init_setup_model)\n",
    "    \n",
    "    def train_model(self, **train_params):\n",
    "        self.model = self.model.learn(**train_params)\n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, environment, **test_params):\n",
    "\n",
    "        env_test, obs_test = environment.get_env()\n",
    "        \"\"\"make a prediction\"\"\"\n",
    "        account_memory = []\n",
    "        actions_memory = []\n",
    "\n",
    "        env_test.reset()\n",
    "        for i in range(len(environment.df.index.unique())):\n",
    "            action, _states = self.model.predict(obs_test, **test_params)\n",
    "            obs_test, rewards, dones, info = env_test.step(action)\n",
    "            if i == (len(environment.df.index.unique()) - 2):\n",
    "                account_memory = env_test.env_method(method_name=\"save_asset_memory\")\n",
    "                actions_memory = env_test.env_method(method_name=\"save_action_memory\")\n",
    "            if dones[0]:\n",
    "                print(\"hit end!\")\n",
    "                break\n",
    "        \n",
    "        portfolio_df = account_memory[0]\n",
    "        portfolio_df = portfolio_df.rename(columns={\"daily_return\": \"account_value\"})\n",
    "        portfolio_df.iloc[0, portfolio_df.columns.get_loc(\"account_value\")] = environment.initial_amount\n",
    "        values = list(portfolio_df[\"account_value\"])\n",
    "        for i in range(1,len(values)):\n",
    "            values[i] = (values[i] + 1) * values[i-1]\n",
    "\n",
    "        portfolio_df[\"account_value\"] = values\n",
    "        return portfolio_df, actions_memory[0]\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        self.model = self.model.load(path)\n",
    "        return self.model\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        self.model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPG(RLAgent):\n",
    "    def __init__(self,\n",
    "                policy: \"MlpPolicy\",\n",
    "                env: None,\n",
    "                learning_rate : 1e-3,\n",
    "                buffer_size: 1_000_000,  # 1e6\n",
    "                learning_starts: 100,\n",
    "                batch_size:  100,\n",
    "                tau:  0.005,\n",
    "                gamma:  0.99,\n",
    "                train_freq:  1,\n",
    "                gradient_steps: int = -1,\n",
    "                action_noise: Optional[ActionNoise] = None,\n",
    "                replay_buffer_class: Optional[ReplayBuffer] = None,\n",
    "                replay_buffer_kwargs: Optional[Dict[str, Any]] = None,\n",
    "                optimize_memory_usage: bool = False,\n",
    "                tensorboard_log: Optional[str] = None,\n",
    "                create_eval_env: bool = False,\n",
    "                policy_kwargs: Optional[Dict[str, Any]] = None,\n",
    "                verbose: int = 0,\n",
    "                seed: Optional[int] = None,\n",
    "                device: Union[th.device, str] = \"auto\",\n",
    "                _init_setup_model: bool = True):\n",
    "                \n",
    "        self.env = env\n",
    "    \n",
    "        self.model = sb_DDPG(policy = policy,\n",
    "                            env=self.env,\n",
    "                            learning_rate = learning_rate,\n",
    "                            buffer_size = buffer_size,\n",
    "                            learning_starts= learning_starts,\n",
    "                            batch_size = batch_size,\n",
    "                            tau = tau,\n",
    "                            gamma= gamma,\n",
    "                            train_freq = train_freq,\n",
    "                            gradient_steps = gradient_steps,\n",
    "                            action_noise= action_noise,\n",
    "                            replay_buffer_class= replay_buffer_class,\n",
    "                            replay_buffer_kwargs= replay_buffer_kwargs,\n",
    "                            optimize_memory_usage=optimize_memory_usage,\n",
    "                            tensorboard_log=tensorboard_log,\n",
    "                            create_eval_env=create_eval_env,\n",
    "                            policy_kwargs=policy_kwargs,\n",
    "                            verbose=verbose,\n",
    "                            seed=seed,\n",
    "                            device=device,\n",
    "                            _init_setup_model = _init_setup_model)\n",
    "\n",
    "    def train_model(self, **train_params):\n",
    "        self.model = self.model.learn(**train_params)\n",
    "        return self.model\n",
    "\n",
    "    def predict(self, environment, **test_params):\n",
    "\n",
    "            env_test, obs_test = environment.get_env()\n",
    "            \"\"\"make a prediction\"\"\"\n",
    "            account_memory = []\n",
    "            actions_memory = []\n",
    "\n",
    "            env_test.reset()\n",
    "            for i in range(len(environment.df.index.unique())):\n",
    "                action, _states = self.model.predict(obs_test, **test_params)\n",
    "                obs_test, rewards, dones, info = env_test.step(action)\n",
    "                if i == (len(environment.df.index.unique()) - 2):\n",
    "                    account_memory = env_test.env_method(method_name=\"save_asset_memory\")\n",
    "                    actions_memory = env_test.env_method(method_name=\"save_action_memory\")\n",
    "                if dones[0]:\n",
    "                    print(\"hit end!\")\n",
    "                    break\n",
    "            \n",
    "            portfolio_df = account_memory[0]\n",
    "            portfolio_df = portfolio_df.rename(columns={\"daily_return\": \"account_value\"})\n",
    "            portfolio_df.iloc[0, portfolio_df.columns.get_loc(\"account_value\")] = environment.initial_amount\n",
    "            values = list(portfolio_df[\"account_value\"])\n",
    "            for i in range(1,len(values)):\n",
    "                values[i] = (values[i] + 1) * values[i-1]\n",
    "\n",
    "            portfolio_df[\"account_value\"] = values\n",
    "            return portfolio_df, actions_memory[0]\n",
    "            \n",
    "    def load_model(self, path):\n",
    "        self.model = self.model.load(path)\n",
    "        return self.model\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        self.model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TD3(RLAgent):\n",
    " \n",
    "    def __init__(self,\n",
    "                policy: \"MlpPolicy\",\n",
    "                env: None,\n",
    "                learning_rate: float =  1e-3,\n",
    "                buffer_size: int = 1_000_000,  # 1e6\n",
    "                learning_starts: int = 100,\n",
    "                batch_size: int = 100,\n",
    "                tau: float = 0.005,\n",
    "                gamma: float = 0.99,\n",
    "                train_freq: int = 1,\n",
    "                gradient_steps: int = -1,\n",
    "                action_noise: Optional[ActionNoise] = None,\n",
    "                replay_buffer_class: Optional[ReplayBuffer] = None,\n",
    "                replay_buffer_kwargs: Optional[Dict[str, Any]] = None,\n",
    "                optimize_memory_usage: bool = False,\n",
    "                tensorboard_log: Optional[str] = None,\n",
    "                create_eval_env: bool = False,\n",
    "                policy_kwargs: Optional[Dict[str, Any]] = None,\n",
    "                verbose: int = 0,\n",
    "                seed: Optional[int] = None,\n",
    "                device: Union[th.device, str] = \"auto\",\n",
    "                _init_setup_model: bool = True):\n",
    "                \n",
    "        self.env = env\n",
    "    \n",
    "        self.model = sb_TD3(policy = policy,\n",
    "                            env=self.env,\n",
    "                            learning_rate = learning_rate,\n",
    "                            buffer_size = buffer_size,\n",
    "                            learning_starts= learning_starts,\n",
    "                            batch_size = batch_size,\n",
    "                            tau = tau,\n",
    "                            gamma= gamma,\n",
    "                            train_freq = train_freq,\n",
    "                            gradient_steps = gradient_steps,\n",
    "                            action_noise= action_noise,\n",
    "                            replay_buffer_class= replay_buffer_class,\n",
    "                            replay_buffer_kwargs= replay_buffer_kwargs,\n",
    "                            optimize_memory_usage=optimize_memory_usage,\n",
    "                            tensorboard_log=tensorboard_log,\n",
    "                            create_eval_env=create_eval_env,\n",
    "                            policy_kwargs=policy_kwargs,\n",
    "                            verbose=verbose,\n",
    "                            seed=seed,\n",
    "                            device=device,\n",
    "                            _init_setup_model = _init_setup_model)\n",
    "\n",
    "    def train_model(self, **train_params):\n",
    "        self.model = self.model.learn(**train_params)\n",
    "        return self.model\n",
    "\n",
    "    def predict(self, environment, **test_params):\n",
    "\n",
    "        env_test, obs_test = environment.get_env()\n",
    "        \"\"\"make a prediction\"\"\"\n",
    "        account_memory = []\n",
    "        actions_memory = []\n",
    "\n",
    "        env_test.reset()\n",
    "        for i in range(len(environment.df.index.unique())):\n",
    "            action, _states = self.model.predict(obs_test, **test_params)\n",
    "            obs_test, rewards, dones, info = env_test.step(action)\n",
    "            if i == (len(environment.df.index.unique()) - 2):\n",
    "                account_memory = env_test.env_method(method_name=\"save_asset_memory\")\n",
    "                actions_memory = env_test.env_method(method_name=\"save_action_memory\")\n",
    "            if dones[0]:\n",
    "                print(\"hit end!\")\n",
    "                break\n",
    "        \n",
    "        portfolio_df = account_memory[0]\n",
    "        portfolio_df = portfolio_df.rename(columns={\"daily_return\": \"account_value\"})\n",
    "        portfolio_df.iloc[0, portfolio_df.columns.get_loc(\"account_value\")] = environment.initial_amount\n",
    "        values = list(portfolio_df[\"account_value\"])\n",
    "        for i in range(1,len(values)):\n",
    "            values[i] = (values[i] + 1) * values[i-1]\n",
    "\n",
    "        portfolio_df[\"account_value\"] = values\n",
    "        return portfolio_df, actions_memory[0]\n",
    "        \n",
    "    def load_model(self, path):\n",
    "        self.model = self.model.load(path)\n",
    "        return self.model\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        self.model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather user parameters\n",
    "with open(\"../user_params.yaml\", \"r\") as stream:\n",
    "    try:\n",
    "        user_params = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = user_params[\"TICKERS\"]\n",
    "env_kwargs = user_params[\"ENV_PARAMS\"]\n",
    "train_params = user_params[\"TRAIN_PARAMS\"]\n",
    "policy_params = user_params[\"POLICY_PARAMS\"]\n",
    "test_params = user_params[\"TEST_PARAMS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test 3: Downloading from Yahoo.........\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (12924, 8)\n",
      "        date       open       high        low      close     volume   tic  day\n",
      "0 2008-12-31   3.070357   3.133571   3.047857   2.606278  607541200  AAPL    2\n",
      "1 2008-12-31  41.590000  43.049999  41.500000  32.005890    5443100    BA    2\n",
      "2 2008-12-31  43.700001  45.099998  43.700001  30.628828    6277400   CAT    2\n",
      "3 2008-12-31  72.900002  74.629997  72.900002  43.314423    9964300   CVX    2\n",
      "4 2009-01-02   3.067143   3.251429   3.041429   2.771174  746015200  AAPL    4\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTest 3: Downloading from Yahoo.........\")\n",
    "downloaded_df = DataDownloader(start_date='2009-01-01',\n",
    "                                end_date='2021-10-31',\n",
    "                                ticker_list= tickers).download_from_yahoo()\n",
    "print(downloaded_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test 4: Feature engineer.........\n",
      "Successfully added technical indicators\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (3231, 8)\n",
      "Successfully added vix\n",
      "Successfully added turbulence index\n",
      "Successfully added covariances\n",
      "Successfully added returns\n"
     ]
    }
   ],
   "source": [
    " # PREPROCESS DATA\n",
    "print(\"\\nTest 4: Feature engineer.........\")\n",
    "data_processor = DefaultFeatureEngineer(use_default=False,\n",
    "                                        tech_indicator_list=env_kwargs[\"tech_indicator_list\"],\n",
    "                                        use_vix=True,\n",
    "                                        use_turbulence=True,\n",
    "                                        use_covar=True)\n",
    "# included technical indicators as features\n",
    "df_processed = data_processor.extend_data(downloaded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>return_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>11.533929</td>\n",
       "      <td>11.552857</td>\n",
       "      <td>11.475357</td>\n",
       "      <td>9.849807</td>\n",
       "      <td>193508000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.091907</td>\n",
       "      <td>9.973601</td>\n",
       "      <td>9.686132</td>\n",
       "      <td>58.973134</td>\n",
       "      <td>56.041939</td>\n",
       "      <td>4.076954</td>\n",
       "      <td>9.738817</td>\n",
       "      <td>9.566210</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>0.440003</td>\n",
       "      <td>[[0.00028413587787510906, 0.000181404842105353...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>BA</td>\n",
       "      <td>64.900002</td>\n",
       "      <td>65.290001</td>\n",
       "      <td>64.620003</td>\n",
       "      <td>52.123989</td>\n",
       "      <td>2137400.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.163486</td>\n",
       "      <td>53.158961</td>\n",
       "      <td>50.459629</td>\n",
       "      <td>49.174001</td>\n",
       "      <td>30.865939</td>\n",
       "      <td>6.670857</td>\n",
       "      <td>51.751255</td>\n",
       "      <td>53.392653</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>0.440003</td>\n",
       "      <td>[[0.00028413587787510906, 0.000181404842105353...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>CAT</td>\n",
       "      <td>93.830002</td>\n",
       "      <td>93.900002</td>\n",
       "      <td>93.309998</td>\n",
       "      <td>68.765228</td>\n",
       "      <td>2542700.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.742873</td>\n",
       "      <td>70.643169</td>\n",
       "      <td>64.949729</td>\n",
       "      <td>68.265893</td>\n",
       "      <td>72.930064</td>\n",
       "      <td>45.749416</td>\n",
       "      <td>65.923381</td>\n",
       "      <td>62.360931</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>0.440003</td>\n",
       "      <td>[[0.00028413587787510906, 0.000181404842105353...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>CVX</td>\n",
       "      <td>91.580002</td>\n",
       "      <td>91.800003</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>57.546177</td>\n",
       "      <td>5152900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.203227</td>\n",
       "      <td>58.549675</td>\n",
       "      <td>53.227383</td>\n",
       "      <td>65.105876</td>\n",
       "      <td>107.259713</td>\n",
       "      <td>53.406336</td>\n",
       "      <td>54.660563</td>\n",
       "      <td>53.596116</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>0.440003</td>\n",
       "      <td>[[0.00028413587787510906, 0.000181404842105353...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>11.630000</td>\n",
       "      <td>11.795000</td>\n",
       "      <td>11.601429</td>\n",
       "      <td>10.063865</td>\n",
       "      <td>445138400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101104</td>\n",
       "      <td>10.012172</td>\n",
       "      <td>9.684601</td>\n",
       "      <td>62.862041</td>\n",
       "      <td>142.930628</td>\n",
       "      <td>25.488753</td>\n",
       "      <td>9.760335</td>\n",
       "      <td>9.586746</td>\n",
       "      <td>17.610001</td>\n",
       "      <td>2.341040</td>\n",
       "      <td>[[0.000284961686123903, 0.000180694738134857, ...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>CVX</td>\n",
       "      <td>113.220001</td>\n",
       "      <td>113.580002</td>\n",
       "      <td>111.650002</td>\n",
       "      <td>108.743820</td>\n",
       "      <td>9096100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.178449</td>\n",
       "      <td>112.516860</td>\n",
       "      <td>98.478378</td>\n",
       "      <td>61.699285</td>\n",
       "      <td>98.878378</td>\n",
       "      <td>34.651291</td>\n",
       "      <td>102.406340</td>\n",
       "      <td>98.743036</td>\n",
       "      <td>16.980000</td>\n",
       "      <td>1.475714</td>\n",
       "      <td>[[0.00027957826767784706, 6.779463388570945e-0...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>149.820007</td>\n",
       "      <td>153.169998</td>\n",
       "      <td>149.720001</td>\n",
       "      <td>151.930588</td>\n",
       "      <td>100077900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.306373</td>\n",
       "      <td>152.340869</td>\n",
       "      <td>137.144779</td>\n",
       "      <td>58.671047</td>\n",
       "      <td>166.690629</td>\n",
       "      <td>23.469447</td>\n",
       "      <td>144.414871</td>\n",
       "      <td>146.737928</td>\n",
       "      <td>16.530001</td>\n",
       "      <td>9.694290</td>\n",
       "      <td>[[0.0002727967689602005, 5.925418256587937e-05...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>BA</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>208.740005</td>\n",
       "      <td>204.600006</td>\n",
       "      <td>207.850006</td>\n",
       "      <td>8825500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.006977</td>\n",
       "      <td>231.687612</td>\n",
       "      <td>205.504387</td>\n",
       "      <td>41.943087</td>\n",
       "      <td>-146.293232</td>\n",
       "      <td>35.544181</td>\n",
       "      <td>218.354333</td>\n",
       "      <td>219.751167</td>\n",
       "      <td>16.530001</td>\n",
       "      <td>9.694290</td>\n",
       "      <td>[[0.0002727967689602005, 5.925418256587937e-05...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>CAT</td>\n",
       "      <td>197.360001</td>\n",
       "      <td>204.500000</td>\n",
       "      <td>197.050003</td>\n",
       "      <td>202.135101</td>\n",
       "      <td>4462700.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.741819</td>\n",
       "      <td>203.795313</td>\n",
       "      <td>184.458964</td>\n",
       "      <td>51.696323</td>\n",
       "      <td>106.185006</td>\n",
       "      <td>4.524754</td>\n",
       "      <td>193.625509</td>\n",
       "      <td>200.327880</td>\n",
       "      <td>16.530001</td>\n",
       "      <td>9.694290</td>\n",
       "      <td>[[0.0002727967689602005, 5.925418256587937e-05...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>CVX</td>\n",
       "      <td>111.580002</td>\n",
       "      <td>113.269997</td>\n",
       "      <td>111.580002</td>\n",
       "      <td>109.762665</td>\n",
       "      <td>7538200.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.107039</td>\n",
       "      <td>112.487226</td>\n",
       "      <td>99.640377</td>\n",
       "      <td>62.860193</td>\n",
       "      <td>96.313756</td>\n",
       "      <td>34.027289</td>\n",
       "      <td>102.917375</td>\n",
       "      <td>98.971939</td>\n",
       "      <td>16.530001</td>\n",
       "      <td>9.694290</td>\n",
       "      <td>[[0.0002727967689602005, 5.925418256587937e-05...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10904 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   tic        open        high         low       close  \\\n",
       "0    2010-12-31  AAPL   11.533929   11.552857   11.475357    9.849807   \n",
       "0    2010-12-31    BA   64.900002   65.290001   64.620003   52.123989   \n",
       "0    2010-12-31   CAT   93.830002   93.900002   93.309998   68.765228   \n",
       "0    2010-12-31   CVX   91.580002   91.800003   91.000000   57.546177   \n",
       "1    2011-01-03  AAPL   11.630000   11.795000   11.601429   10.063865   \n",
       "...         ...   ...         ...         ...         ...         ...   \n",
       "2724 2021-10-27   CVX  113.220001  113.580002  111.650002  108.743820   \n",
       "2725 2021-10-28  AAPL  149.820007  153.169998  149.720001  151.930588   \n",
       "2725 2021-10-28    BA  206.000000  208.740005  204.600006  207.850006   \n",
       "2725 2021-10-28   CAT  197.360001  204.500000  197.050003  202.135101   \n",
       "2725 2021-10-28   CVX  111.580002  113.269997  111.580002  109.762665   \n",
       "\n",
       "           volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0     193508000.0  4.0  0.091907    9.973601    9.686132  58.973134   \n",
       "0       2137400.0  4.0 -0.163486   53.158961   50.459629  49.174001   \n",
       "0       2542700.0  4.0  1.742873   70.643169   64.949729  68.265893   \n",
       "0       5152900.0  4.0  1.203227   58.549675   53.227383  65.105876   \n",
       "1     445138400.0  0.0  0.101104   10.012172    9.684601  62.862041   \n",
       "...           ...  ...       ...         ...         ...        ...   \n",
       "2724    9096100.0  2.0  3.178449  112.516860   98.478378  61.699285   \n",
       "2725  100077900.0  3.0  1.306373  152.340869  137.144779  58.671047   \n",
       "2725    8825500.0  3.0 -3.006977  231.687612  205.504387  41.943087   \n",
       "2725    4462700.0  3.0  0.741819  203.795313  184.458964  51.696323   \n",
       "2725    7538200.0  3.0  3.107039  112.487226   99.640377  62.860193   \n",
       "\n",
       "          cci_30      dx_30  close_30_sma  close_60_sma        vix  \\\n",
       "0      56.041939   4.076954      9.738817      9.566210  17.750000   \n",
       "0      30.865939   6.670857     51.751255     53.392653  17.750000   \n",
       "0      72.930064  45.749416     65.923381     62.360931  17.750000   \n",
       "0     107.259713  53.406336     54.660563     53.596116  17.750000   \n",
       "1     142.930628  25.488753      9.760335      9.586746  17.610001   \n",
       "...          ...        ...           ...           ...        ...   \n",
       "2724   98.878378  34.651291    102.406340     98.743036  16.980000   \n",
       "2725  166.690629  23.469447    144.414871    146.737928  16.530001   \n",
       "2725 -146.293232  35.544181    218.354333    219.751167  16.530001   \n",
       "2725  106.185006   4.524754    193.625509    200.327880  16.530001   \n",
       "2725   96.313756  34.027289    102.917375     98.971939  16.530001   \n",
       "\n",
       "      turbulence                                           cov_list  \\\n",
       "0       0.440003  [[0.00028413587787510906, 0.000181404842105353...   \n",
       "0       0.440003  [[0.00028413587787510906, 0.000181404842105353...   \n",
       "0       0.440003  [[0.00028413587787510906, 0.000181404842105353...   \n",
       "0       0.440003  [[0.00028413587787510906, 0.000181404842105353...   \n",
       "1       2.341040  [[0.000284961686123903, 0.000180694738134857, ...   \n",
       "...          ...                                                ...   \n",
       "2724    1.475714  [[0.00027957826767784706, 6.779463388570945e-0...   \n",
       "2725    9.694290  [[0.0002727967689602005, 5.925418256587937e-05...   \n",
       "2725    9.694290  [[0.0002727967689602005, 5.925418256587937e-05...   \n",
       "2725    9.694290  [[0.0002727967689602005, 5.925418256587937e-05...   \n",
       "2725    9.694290  [[0.0002727967689602005, 5.925418256587937e-05...   \n",
       "\n",
       "                                            return_list  \n",
       "0     tic             AAPL        BA       CAT      ...  \n",
       "0     tic             AAPL        BA       CAT      ...  \n",
       "0     tic             AAPL        BA       CAT      ...  \n",
       "0     tic             AAPL        BA       CAT      ...  \n",
       "1     tic             AAPL        BA       CAT      ...  \n",
       "...                                                 ...  \n",
       "2724  tic             AAPL        BA       CAT      ...  \n",
       "2725  tic             AAPL        BA       CAT      ...  \n",
       "2725  tic             AAPL        BA       CAT      ...  \n",
       "2725  tic             AAPL        BA       CAT      ...  \n",
       "2725  tic             AAPL        BA       CAT      ...  \n",
       "\n",
       "[10904 rows x 20 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = TimeSeriesSplitter()\n",
    "train = splitter.get_split_data(df_processed, '2009-01-01', '2020-06-30')\n",
    "trade = splitter.get_split_data(df_processed, '2020-07-01', '2021-09-02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>return_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>11.533929</td>\n",
       "      <td>11.552857</td>\n",
       "      <td>11.475357</td>\n",
       "      <td>9.849807</td>\n",
       "      <td>193508000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.091907</td>\n",
       "      <td>9.973601</td>\n",
       "      <td>9.686132</td>\n",
       "      <td>58.973134</td>\n",
       "      <td>56.041939</td>\n",
       "      <td>4.076954</td>\n",
       "      <td>9.738817</td>\n",
       "      <td>9.566210</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>0.440003</td>\n",
       "      <td>[[0.00028413587787510906, 0.000181404842105353...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>BA</td>\n",
       "      <td>64.900002</td>\n",
       "      <td>65.290001</td>\n",
       "      <td>64.620003</td>\n",
       "      <td>52.123989</td>\n",
       "      <td>2137400.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.163486</td>\n",
       "      <td>53.158961</td>\n",
       "      <td>50.459629</td>\n",
       "      <td>49.174001</td>\n",
       "      <td>30.865939</td>\n",
       "      <td>6.670857</td>\n",
       "      <td>51.751255</td>\n",
       "      <td>53.392653</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>0.440003</td>\n",
       "      <td>[[0.00028413587787510906, 0.000181404842105353...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>CAT</td>\n",
       "      <td>93.830002</td>\n",
       "      <td>93.900002</td>\n",
       "      <td>93.309998</td>\n",
       "      <td>68.765228</td>\n",
       "      <td>2542700.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.742873</td>\n",
       "      <td>70.643169</td>\n",
       "      <td>64.949729</td>\n",
       "      <td>68.265893</td>\n",
       "      <td>72.930064</td>\n",
       "      <td>45.749416</td>\n",
       "      <td>65.923381</td>\n",
       "      <td>62.360931</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>0.440003</td>\n",
       "      <td>[[0.00028413587787510906, 0.000181404842105353...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>CVX</td>\n",
       "      <td>91.580002</td>\n",
       "      <td>91.800003</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>57.546177</td>\n",
       "      <td>5152900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.203227</td>\n",
       "      <td>58.549675</td>\n",
       "      <td>53.227383</td>\n",
       "      <td>65.105876</td>\n",
       "      <td>107.259713</td>\n",
       "      <td>53.406336</td>\n",
       "      <td>54.660563</td>\n",
       "      <td>53.596116</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>0.440003</td>\n",
       "      <td>[[0.00028413587787510906, 0.000181404842105353...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>11.630000</td>\n",
       "      <td>11.795000</td>\n",
       "      <td>11.601429</td>\n",
       "      <td>10.063865</td>\n",
       "      <td>445138400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101104</td>\n",
       "      <td>10.012172</td>\n",
       "      <td>9.684601</td>\n",
       "      <td>62.862041</td>\n",
       "      <td>142.930628</td>\n",
       "      <td>25.488753</td>\n",
       "      <td>9.760335</td>\n",
       "      <td>9.586746</td>\n",
       "      <td>17.610001</td>\n",
       "      <td>2.341040</td>\n",
       "      <td>[[0.000284961686123903, 0.000180694738134857, ...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>CVX</td>\n",
       "      <td>88.779999</td>\n",
       "      <td>88.830002</td>\n",
       "      <td>86.180000</td>\n",
       "      <td>78.338341</td>\n",
       "      <td>13766000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.752701</td>\n",
       "      <td>93.112448</td>\n",
       "      <td>76.463885</td>\n",
       "      <td>46.927257</td>\n",
       "      <td>-141.407494</td>\n",
       "      <td>18.869071</td>\n",
       "      <td>84.164340</td>\n",
       "      <td>80.878847</td>\n",
       "      <td>34.730000</td>\n",
       "      <td>1.877656</td>\n",
       "      <td>[[0.0006521349436256184, 0.0006959985856115124...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>88.312500</td>\n",
       "      <td>90.542503</td>\n",
       "      <td>87.820000</td>\n",
       "      <td>89.329300</td>\n",
       "      <td>130646000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.088531</td>\n",
       "      <td>92.294062</td>\n",
       "      <td>78.598772</td>\n",
       "      <td>62.399287</td>\n",
       "      <td>92.968125</td>\n",
       "      <td>23.584901</td>\n",
       "      <td>83.104048</td>\n",
       "      <td>76.785886</td>\n",
       "      <td>31.780001</td>\n",
       "      <td>12.311248</td>\n",
       "      <td>[[0.0006532268491239941, 0.0007078388987480551...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>BA</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>194.500000</td>\n",
       "      <td>176.270004</td>\n",
       "      <td>194.490005</td>\n",
       "      <td>78499900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.740439</td>\n",
       "      <td>223.696927</td>\n",
       "      <td>154.242075</td>\n",
       "      <td>53.814440</td>\n",
       "      <td>45.363542</td>\n",
       "      <td>14.268369</td>\n",
       "      <td>173.214335</td>\n",
       "      <td>154.108667</td>\n",
       "      <td>31.780001</td>\n",
       "      <td>12.311248</td>\n",
       "      <td>[[0.0006532268491239941, 0.0007078388987480551...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>CAT</td>\n",
       "      <td>123.720001</td>\n",
       "      <td>126.040001</td>\n",
       "      <td>123.279999</td>\n",
       "      <td>119.876396</td>\n",
       "      <td>2798700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.323072</td>\n",
       "      <td>130.677977</td>\n",
       "      <td>113.093651</td>\n",
       "      <td>52.455059</td>\n",
       "      <td>13.227561</td>\n",
       "      <td>5.712842</td>\n",
       "      <td>118.600579</td>\n",
       "      <td>113.334042</td>\n",
       "      <td>31.780001</td>\n",
       "      <td>12.311248</td>\n",
       "      <td>[[0.0006532268491239941, 0.0007078388987480551...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>CVX</td>\n",
       "      <td>86.910004</td>\n",
       "      <td>88.570000</td>\n",
       "      <td>86.599998</td>\n",
       "      <td>79.434692</td>\n",
       "      <td>7022200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.920215</td>\n",
       "      <td>93.216081</td>\n",
       "      <td>75.896348</td>\n",
       "      <td>47.804786</td>\n",
       "      <td>-127.197546</td>\n",
       "      <td>18.869071</td>\n",
       "      <td>84.158300</td>\n",
       "      <td>81.069896</td>\n",
       "      <td>31.780001</td>\n",
       "      <td>12.311248</td>\n",
       "      <td>[[0.0006532268491239941, 0.0007078388987480551...</td>\n",
       "      <td>tic             AAPL        BA       CAT      ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9556 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   tic        open        high         low       close  \\\n",
       "0    2010-12-31  AAPL   11.533929   11.552857   11.475357    9.849807   \n",
       "0    2010-12-31    BA   64.900002   65.290001   64.620003   52.123989   \n",
       "0    2010-12-31   CAT   93.830002   93.900002   93.309998   68.765228   \n",
       "0    2010-12-31   CVX   91.580002   91.800003   91.000000   57.546177   \n",
       "1    2011-01-03  AAPL   11.630000   11.795000   11.601429   10.063865   \n",
       "...         ...   ...         ...         ...         ...         ...   \n",
       "2387 2020-06-26   CVX   88.779999   88.830002   86.180000   78.338341   \n",
       "2388 2020-06-29  AAPL   88.312500   90.542503   87.820000   89.329300   \n",
       "2388 2020-06-29    BA  181.000000  194.500000  176.270004  194.490005   \n",
       "2388 2020-06-29   CAT  123.720001  126.040001  123.279999  119.876396   \n",
       "2388 2020-06-29   CVX   86.910004   88.570000   86.599998   79.434692   \n",
       "\n",
       "           volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0     193508000.0  4.0  0.091907    9.973601    9.686132  58.973134   \n",
       "0       2137400.0  4.0 -0.163486   53.158961   50.459629  49.174001   \n",
       "0       2542700.0  4.0  1.742873   70.643169   64.949729  68.265893   \n",
       "0       5152900.0  4.0  1.203227   58.549675   53.227383  65.105876   \n",
       "1     445138400.0  0.0  0.101104   10.012172    9.684601  62.862041   \n",
       "...           ...  ...       ...         ...         ...        ...   \n",
       "2387   13766000.0  4.0 -0.752701   93.112448   76.463885  46.927257   \n",
       "2388  130646000.0  0.0  3.088531   92.294062   78.598772  62.399287   \n",
       "2388   78499900.0  0.0  6.740439  223.696927  154.242075  53.814440   \n",
       "2388    2798700.0  0.0  1.323072  130.677977  113.093651  52.455059   \n",
       "2388    7022200.0  0.0 -0.920215   93.216081   75.896348  47.804786   \n",
       "\n",
       "          cci_30      dx_30  close_30_sma  close_60_sma        vix  \\\n",
       "0      56.041939   4.076954      9.738817      9.566210  17.750000   \n",
       "0      30.865939   6.670857     51.751255     53.392653  17.750000   \n",
       "0      72.930064  45.749416     65.923381     62.360931  17.750000   \n",
       "0     107.259713  53.406336     54.660563     53.596116  17.750000   \n",
       "1     142.930628  25.488753      9.760335      9.586746  17.610001   \n",
       "...          ...        ...           ...           ...        ...   \n",
       "2387 -141.407494  18.869071     84.164340     80.878847  34.730000   \n",
       "2388   92.968125  23.584901     83.104048     76.785886  31.780001   \n",
       "2388   45.363542  14.268369    173.214335    154.108667  31.780001   \n",
       "2388   13.227561   5.712842    118.600579    113.334042  31.780001   \n",
       "2388 -127.197546  18.869071     84.158300     81.069896  31.780001   \n",
       "\n",
       "      turbulence                                           cov_list  \\\n",
       "0       0.440003  [[0.00028413587787510906, 0.000181404842105353...   \n",
       "0       0.440003  [[0.00028413587787510906, 0.000181404842105353...   \n",
       "0       0.440003  [[0.00028413587787510906, 0.000181404842105353...   \n",
       "0       0.440003  [[0.00028413587787510906, 0.000181404842105353...   \n",
       "1       2.341040  [[0.000284961686123903, 0.000180694738134857, ...   \n",
       "...          ...                                                ...   \n",
       "2387    1.877656  [[0.0006521349436256184, 0.0006959985856115124...   \n",
       "2388   12.311248  [[0.0006532268491239941, 0.0007078388987480551...   \n",
       "2388   12.311248  [[0.0006532268491239941, 0.0007078388987480551...   \n",
       "2388   12.311248  [[0.0006532268491239941, 0.0007078388987480551...   \n",
       "2388   12.311248  [[0.0006532268491239941, 0.0007078388987480551...   \n",
       "\n",
       "                                            return_list  \n",
       "0     tic             AAPL        BA       CAT      ...  \n",
       "0     tic             AAPL        BA       CAT      ...  \n",
       "0     tic             AAPL        BA       CAT      ...  \n",
       "0     tic             AAPL        BA       CAT      ...  \n",
       "1     tic             AAPL        BA       CAT      ...  \n",
       "...                                                 ...  \n",
       "2387  tic             AAPL        BA       CAT      ...  \n",
       "2388  tic             AAPL        BA       CAT      ...  \n",
       "2388  tic             AAPL        BA       CAT      ...  \n",
       "2388  tic             AAPL        BA       CAT      ...  \n",
       "2388  tic             AAPL        BA       CAT      ...  \n",
       "\n",
       "[9556 rows x 20 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.19067902e-02,  9.97360130e+00,  9.68613152e+00, ...,\n",
       "         4.07695431e+00,  9.73881721e+00,  9.56621019e+00],\n",
       "       [-1.63485791e-01,  5.31589609e+01,  5.04596289e+01, ...,\n",
       "         6.67085680e+00,  5.17512548e+01,  5.33926531e+01],\n",
       "       [ 1.74287340e+00,  7.06431694e+01,  6.49497292e+01, ...,\n",
       "         4.57494162e+01,  6.59233814e+01,  6.23609313e+01],\n",
       "       ...,\n",
       "       [ 6.21086146e+00,  2.25250598e+02,  1.48378403e+02, ...,\n",
       "         3.13989830e+00,  1.70731334e+02,  1.52921667e+02],\n",
       "       [ 1.42691395e+00,  1.30893338e+02,  1.12423668e+02, ...,\n",
       "         1.42987333e+00,  1.18047696e+02,  1.13181352e+02],\n",
       "       [-7.52701013e-01,  9.31124476e+01,  7.64638853e+01, ...,\n",
       "         1.88690712e+01,  8.41643400e+01,  8.08788469e+01]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare conventional data\n",
    "X, y = data_processor.prepare_ml_data(train)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'degree': 3, 'gamma': 'scale', 'coef0': 0, 'tol': 0.001, 'epsilon': 0.1, 'shrinking': True, 'cache_size': 200, 'verbose': False, 'max_iter': -1}\n"
     ]
    }
   ],
   "source": [
    "policy_params[\"SVR_PARAMS\"].pop('C', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_params = policy_params[\"SVR_PARAMS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = BlockingTimeSeriesSplitter(n_splits = 5)\n",
    "for i,j in cv.split(X,y):\n",
    "    print(i)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained succesfully\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'tic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer/model_structure.ipynb Cell 26'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer/model_structure.ipynb#ch0000033?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m train_idx,test_idx \u001b[39min\u001b[39;00m btss\u001b[39m.\u001b[39msplit(X,y):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer/model_structure.ipynb#ch0000033?line=7'>8</a>\u001b[0m    svr\u001b[39m.\u001b[39mtrain_model(X[train_idx], y[train_idx], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrain_params[\u001b[39m\"\u001b[39m\u001b[39mSVR_PARAMS\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer/model_structure.ipynb#ch0000033?line=8'>9</a>\u001b[0m    temp_portfolio,_,_ \u001b[39m=\u001b[39m svr\u001b[39m.\u001b[39;49mpredict(X[test_idx], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtest_params[\u001b[39m\"\u001b[39;49m\u001b[39mSVR_PARAMS\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer/model_structure.ipynb#ch0000033?line=9'>10</a>\u001b[0m    scores\u001b[39m.\u001b[39mappend(temp_portfolio\u001b[39m.\u001b[39mtail(\u001b[39m1\u001b[39m)[\u001b[39m\"\u001b[39m\u001b[39maccount_value\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer/model_structure.ipynb#ch0000033?line=11'>12</a>\u001b[0m scores_mean \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(scores) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(scores)\n",
      "\u001b[1;32m/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer/model_structure.ipynb Cell 9'\u001b[0m in \u001b[0;36mSVRAgent.predict\u001b[0;34m(self, test_data, initial_capital, tech_indicator_list)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer/model_structure.ipynb#ch0000008?line=43'>44</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer/model_structure.ipynb#ch0000008?line=44'>45</a>\u001b[0m            test_data, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer/model_structure.ipynb#ch0000008?line=45'>46</a>\u001b[0m            initial_capital \u001b[39m=\u001b[39m \u001b[39m1000000\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer/model_structure.ipynb#ch0000008?line=54'>55</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mclose_60_sma\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer/model_structure.ipynb#ch0000008?line=55'>56</a>\u001b[0m             ]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer/model_structure.ipynb#ch0000008?line=57'>58</a>\u001b[0m     meta_coefficient \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m: []}\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer/model_structure.ipynb#ch0000008?line=58'>59</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m test_data\u001b[39m.\u001b[39;49mtic:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer/model_structure.ipynb#ch0000008?line=59'>60</a>\u001b[0m         meta_coefficient[i] \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer/model_structure.ipynb#ch0000008?line=60'>61</a>\u001b[0m     unique_trade_date \u001b[39m=\u001b[39m test_data\u001b[39m.\u001b[39mdate\u001b[39m.\u001b[39munique()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'tic'"
     ]
    }
   ],
   "source": [
    "CC= [0.01, 1, 100]\n",
    "svr_scores = []\n",
    "for c in CC:\n",
    "    btss = BlockingTimeSeriesSplitter(n_splits = 5)\n",
    "    svr = SVRAgent(C =c, **svr_params)\n",
    "    scores = []\n",
    "    for train_idx,test_idx in btss.split(X,y):\n",
    "       svr.train_model(X[train_idx], y[train_idx], **train_params[\"SVR_PARAMS\"])\n",
    "       temp_portfolio,_,_ = svr.predict(X[test_idx], **test_params[\"SVR_PARAMS\"])\n",
    "       scores.append(temp_portfolio.tail(1)[\"account_value\"][0])\n",
    "       \n",
    "    scores_mean = sum(scores) / len(scores)\n",
    "    print(scores_mean)\n",
    "    svr_scores.append(scores_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create agent\n",
    "lr = LRAgent(**policy_params[\"LR_PARAMS\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train agent\n",
    "lr.train_model(train_x, train_y, **train_params[\"LR_PARAMS\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict \n",
    "portfolio, portfolio_cumprod, meta_coefficient = lr.predict(trade, **test_params[\"LR_PARAMS\"])\n",
    "print(portfolio)\n",
    "print(\"--------\\n\")\n",
    "print(meta_coefficient)\n",
    "print(\"--------\\n\")\n",
    "print(portfolio_cumprod)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ee38ef4a5a9feb55287fd749643f13d043cb0a7addaab2a9c224cbe137c0062"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
