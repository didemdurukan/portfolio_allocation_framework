{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi/AgentLayer', '/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python38.zip', '/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8', '/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/lib-dynload', '', '/usr/local/lib/python3.8/site-packages', '/usr/local/lib/python3.8/site-packages/selenium-3.141.0-py3.8.egg', '/usr/local/lib/python3.8/site-packages/urllib3-1.26.4-py3.8.egg', '/usr/local/lib/python3.8/site-packages/IPython/extensions', '/Users/doganparlak/.ipython', '/Users/doganparlak/Library/Python/3.8/lib/python/site-packages', '/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi', '/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi', '/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi', '/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi', '/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi', '/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi', '/Users/doganparlak/Desktop/Master_2.2/Master_Project/uniFi_github/uniFi']\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from sys import path\n",
    "from os.path import dirname as dir\n",
    "\n",
    "path.append(dir(path[0]))\n",
    "print(path)\n",
    "#__package__ = \"examples\"\n",
    "\n",
    "from FinancialEnvLayer.datacollector import CustomDatasetImporter\n",
    "from FinancialEnvLayer.datacollector import DataDownloader\n",
    "from FinancialEnvLayer.dataprocessor import FeatureEngineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self, data, params):\n",
    "        self.data = data\n",
    "        self.params = params\n",
    "        self.portfilio_env = PortfolioEnvironmentClass(self.data, **self.params)\n",
    "\n",
    "    def environment(self):\n",
    "        e = DummyVecEnv([lambda: self.portfilio_env])\n",
    "        obs = e.reset()\n",
    "        return e, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioEnvironmentClass(Environment):\n",
    "    def __init__(self, \n",
    "                df,\n",
    "                stock_dim,\n",
    "                hmax,\n",
    "                initial_amount,\n",
    "                transaction_cost_pct,\n",
    "                reward_scaling,\n",
    "                state_space,\n",
    "                action_space,\n",
    "                tech_indicator_list,\n",
    "                turbulence_threshold=None,\n",
    "                lookback=252,\n",
    "                day = 0):\n",
    "\n",
    "        self.day = day\n",
    "        self.lookback=lookback\n",
    "        self.df = df\n",
    "        self.stock_dim = stock_dim\n",
    "        self.hmax = hmax\n",
    "        self.initial_amount = initial_amount\n",
    "        self.transaction_cost_pct =transaction_cost_pct\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "    \n",
    "        # action_space normalization and shape is self.stock_dim\n",
    "        self.action_space = spaces.Box(low = 0, high = 1,shape = (self.action_space,)) \n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape = (self.state_space+len(self.tech_indicator_list),self.state_space))\n",
    "\n",
    "        #print(self.df.head(3))\n",
    "        # load data from a pandas dataframe\n",
    "        self.data = self.df.loc[self.day,:]\n",
    "        print(self.data.head(3))\n",
    "        self.covs = self.data['cov_list'][0]\n",
    "        self.state =  np.append(np.array(self.covs), [self.data[tech].tolist() for tech in self.tech_indicator_list ], axis=0)\n",
    "        self.terminal = False     \n",
    "        self.turbulence_threshold = turbulence_threshold        \n",
    "        # initalize state: inital portfolio return + individual stock return + individual weights\n",
    "        self.portfolio_value = self.initial_amount\n",
    "\n",
    "        # memorize portfolio value each step\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        # memorize portfolio return each step\n",
    "        self.portfolio_return_memory = [0]\n",
    "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
    "        #print(self.data.head(3))\n",
    "        self.date_memory=[self.data.date.unique()[0]]\n",
    "\n",
    "    def step(self, actions):\n",
    "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
    "\n",
    "        if self.terminal:\n",
    "            df = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df.columns = ['daily_return']\n",
    "            plt.plot(df.daily_return.cumsum(),'r')\n",
    "            plt.savefig('results/cumulative_reward.png')\n",
    "            plt.close()\n",
    "            \n",
    "            plt.plot(self.portfolio_return_memory,'r')\n",
    "            plt.savefig('results/rewards.png')\n",
    "            plt.close()\n",
    "\n",
    "            print(\"=================================\")\n",
    "            print(\"begin_total_asset:{}\".format(self.asset_memory[0]))           \n",
    "            print(\"end_total_asset:{}\".format(self.portfolio_value))\n",
    "\n",
    "            df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df_daily_return.columns = ['daily_return']\n",
    "            if df_daily_return['daily_return'].std() !=0:\n",
    "              sharpe = (252**0.5)*df_daily_return['daily_return'].mean()/ \\\n",
    "                       df_daily_return['daily_return'].std()\n",
    "              print(\"Sharpe: \",sharpe)\n",
    "            print(\"=================================\")\n",
    "            \n",
    "            return self.state, self.reward, self.terminal,{}\n",
    "\n",
    "        else:\n",
    "            weights = self.softmax_normalization(actions) \n",
    "            self.actions_memory.append(weights)\n",
    "            last_day_memory = self.data\n",
    "\n",
    "            #load next state\n",
    "            self.day += 1\n",
    "            self.data = self.df.loc[self.day,:]\n",
    "            self.covs = self.data['cov_list'][0]\n",
    "            self.state =  np.append(np.array(self.covs), [self.data[tech].tolist() for tech in self.tech_indicator_list ], axis=0)\n",
    "            portfolio_return = sum(((self.data.close.values / last_day_memory.close.values)-1)*weights)\n",
    "            log_portfolio_return = np.log(sum((self.data.close.values / last_day_memory.close.values)*weights))\n",
    "            # update portfolio value\n",
    "            new_portfolio_value = self.portfolio_value*(1+portfolio_return)\n",
    "            self.portfolio_value = new_portfolio_value\n",
    "\n",
    "            # save into memory\n",
    "            self.portfolio_return_memory.append(portfolio_return)\n",
    "            self.date_memory.append(self.data[\"date\"].unique()[0])            \n",
    "            self.asset_memory.append(new_portfolio_value)\n",
    "\n",
    "            # the reward is the new portfolio value or end portfolo value\n",
    "            self.reward = new_portfolio_value\n",
    "            \n",
    "\n",
    "        return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        return self.state\n",
    "\n",
    "    def softmax_normalization(self, actions):\n",
    "        numerator = np.exp(actions)\n",
    "        denominator = np.sum(np.exp(actions))\n",
    "        softmax_output = numerator/denominator\n",
    "        return softmax_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def train_model():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_model():\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def load_model():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConventionalAgent(Agent, ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def train_model():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_model():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_model():\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _return_predict():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _weight_optimization():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLAgent(Agent, ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def train_model():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict():\n",
    "        \n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_model():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_model():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A2C(RLAgent):\n",
    "\n",
    "    def __init__(self, model_params):\n",
    "        self.model_params = model_params\n",
    "        self.model = A2C(self.model_params[\"policy\"], self.model_params[\"environment\"], self.model_params[\"verbose\"])\n",
    "        #self.model = A2C(self.model_params[\"policy\"], self.model_params[\"environment\"], self.model_params[\"verbose\"], self.model_params[\"n_steps\"],\n",
    "        #                 self.model_params[\"gamma\"], self.model_params[\"vf_coef\"], self.model_params[\"alpha\"], self.model_params[\"momentum\"], \n",
    "        #                self.model_params[\"lr_schedule\"], self.model_params[\"epsilon\"]) \n",
    "\n",
    "    def train_model(self, train_params):\n",
    "        self.model =  self.model.learn(total_timesteps = train_params[\"total_timesteps\"], log_interval = train_params[\"log_interval\"])\n",
    "        return self.model\n",
    "        \n",
    "    def predict(self, test_params):\n",
    "\n",
    "        test_env, test_obs = test_params[\"environment\"].environment()\n",
    "        \"\"\"make a prediction\"\"\"\n",
    "        account_memory = []\n",
    "        actions_memory = []\n",
    "\n",
    "        test_env.reset()\n",
    "        for i in range(len(test_params[\"environment\"].df.index.unique())):\n",
    "            action, _states = self.model.predict(test_obs, deterministic = test_params[\"deterministic\"])\n",
    "            test_obs, rewards, dones, info = test_env.step(action)\n",
    "            if i == (len(test_params[\"environment\"].df.index.unique()) - 2):\n",
    "                account_memory = test_env.env_method(method_name=\"save_asset_memory\")\n",
    "                actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n",
    "            if dones[0]:\n",
    "                print(\"hit end!\")\n",
    "                break\n",
    "\n",
    "        return account_memory[0], actions_memory[0]\n",
    "\n",
    "    def save_model(self, model_name):\n",
    "        self.model.save(model_name)\n",
    "\n",
    "    def load_model(self, model_name):\n",
    "        self.model = self.model.load(model_name)\n",
    "        return self.model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TECHNICAL_INDICATORS_LIST = [\n",
    "    \"macd\",\n",
    "    \"boll_ub\",\n",
    "    \"boll_lb\",\n",
    "    \"rsi_30\",\n",
    "    \"cci_30\",\n",
    "    \"dx_30\",\n",
    "    \"close_30_sma\",\n",
    "    \"close_60_sma\",\n",
    "]\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100, #maximum number of shares to trade\n",
    "    \"initial_amount\": 1000000, # initial cash\n",
    "    \"transaction_cost_pct\": 0.001, # transaction cost percentage\n",
    "    \"state_space\": 29, # number of unique stocks \n",
    "    \"stock_dim\": 29, # number of unique stocks\n",
    "    \"tech_indicator_list\": TECHNICAL_INDICATORS_LIST, # technical indicators\n",
    "    \"action_space\": 29, # number of stocks in training data\n",
    "    \"reward_scaling\": 1e-1  #hyperparameter\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"download.yaml\", \"r\") as stream:\n",
    "    try:\n",
    "        download_config = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "tickers = download_config[\"tickers\"]\n",
    "\n",
    "print(\"\\nTest 3: Downloading from Yahoo.........\")\n",
    "downloaded_df = DataDownloader.download_data(start_date='2009-01-01',\n",
    "                                                end_date='2021-10-31',\n",
    "                                                ticker_list=tickers)\n",
    "print(downloaded_df.head())\n",
    "\n",
    "print(\"\\nTest 4: Feature engineer.........\")\n",
    "df_processed = FeatureEngineer.add_features(df=downloaded_df,\n",
    "                                            use_default=True,\n",
    "                                            tech_indicator_list=TECHNICAL_INDICATORS_LIST,\n",
    "                                            use_vix=True,\n",
    "                                            use_turbulence=True,\n",
    "                                            user_defined_feature=True)  # included technical indicators as features\n",
    "\n",
    "print(df_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BU VE ALTTAKI CELLI FEATURE ENGINEERINGE ENTEGRE ETTIKTEN SONRA MODEL KISMINI TEST EDEBILIRIM\n",
    "#include covariance of stocks as feature depending on 1 year data \n",
    "cov_list = []\n",
    "return_list = []\n",
    "\n",
    "# look back is one year\n",
    "lookback=252\n",
    "for i in range(lookback,len(df_processed.index.unique())):\n",
    "  data_lookback = df_processed.loc[i-lookback:i,:]\n",
    "  price_lookback=data_lookback.pivot_table(index = 'date',columns = 'tic', values = 'close')\n",
    "  return_lookback = price_lookback.pct_change().dropna()\n",
    "  return_list.append(return_lookback)\n",
    "\n",
    "  covs = return_lookback.cov().values \n",
    "  cov_list.append(covs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-9fee887ecdb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdf_processed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlookback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cov_list'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcov_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'return_list'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mreturn_list\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_processed_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_processed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_processed_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_processed_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "df_cov = pd.DataFrame({'date':df_processed.date.unique()[lookback:],'cov_list':cov_list,'return_list':return_list}) #burda error aliyor unique date uzunlugu cov list ve return list uzunlugu ile turmuyor\n",
    "df_processed_full = df_processed.merge(df_cov, on='date')\n",
    "df_processed_full = df_processed_full.sort_values(['date','tic']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_full.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_train_gym = Environment(data = df_processed_full, params = env_kwargs) #train parametresi training data olucak (dataframe) daha koyulmadi \n",
    "env_train, _ = e_train_gym.environment()\n",
    "\n",
    "e_trade_gym = Environment(data = df_processed_full, params = env_kwargs) #trade parametresi test data olucak (dataframe) daha koyulmadi\n",
    "env_train, _ = e_train_gym.environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2c_params = {\"policy\" : \"MlpPolicy\", \n",
    "                \"environment\" : e_train_gym,\n",
    "                \"verbose\" : 1}\n",
    "\n",
    "train_params = {\"total_timesteps\": 25000,\n",
    "                \"log_interval\": 100}\n",
    "\n",
    "test_params = {\"environment\" : e_train_gym,\n",
    "               \"deterministic\" : True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#object creation\n",
    "a2c = A2C(a2c_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "a2c.train_model(train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting\n",
    "a2c.predict(test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving \n",
    "a2c.save_model(\"a2c_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading\n",
    "loaded_a2c_model = a2c.load_model(\"a2c_model\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ee38ef4a5a9feb55287fd749643f13d043cb0a7addaab2a9c224cbe137c0062"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
